[{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"emmeans","dir":"Articles","previous_headings":"","what":"emmeans","title":"Alternative Software","text":"emmeans package developed Russell V. Lenth colleagues. emmeans truly incredible piece software, trailblazer R ecosystem. extremely powerful package whose functionality overlaps marginaleffects significant degree: marginal means, contrasts, slopes. Even two packages can compute many quantities, emmeans marginaleffects pretty different philosophies respect user interface computation. emmeans analysis typically starts computing “marginal means” holding numeric covariates means, averaging across balanced grid categorical predictors. , users can use contrast() function estimate difference marginal means. marginaleffects package supplies marginal_means function can also compute marginal means. However, typical analysis squarely centered predicted/fitted values. useful starting point , many cases, analysts find easy intuitive express scientific queries terms changes predicted values. example, average predicted probability survival differ treatment control group? difference predicted wage college high school graduates? Let’s say estimate linear regression model two continuous regressors multiplicative interaction: \\[y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x \\cdot z + \\varepsilon\\] model, effect \\(x\\) \\(y\\) depend value covariate \\(z\\). Let’s say user wants estimate happens predicted value \\(y\\) \\(x\\) increases 1 unit, \\(z \\\\{-1, 0, 1\\}\\). , use comparisons() function. variables argument determines scientific query interest, newdata argument determines grid covariate values want evaluate query: vignettes show, marginaleffects can also compute contrasts marginal means. can also compute various quantities interest like raw fitted values, slopes (partial derivatives), contrasts marginal means. also offers flexible mechanism run (non-)linear hypothesis tests using delta method, offers fully customizable strategy compute quantities like odds ratios (completely arbitrary functions predicted outcome). Thus, (Vincent’s) biased opinion, main benefits marginaleffects emmeans : Support model types. Simpler, intuitive, highly consistent user interface. Easier compute average marginal effects unit-level marginal effects whole datasets. Easier compute marginal effects (slopes) custom grids continuous regressors. Easier implement causal inference strategies like parametric g-formula regression adjustement experiments (see vignettes). Allows computation arbitrary quantities interest via user-supplied functions automatic delta method inference. Common plots easy plot_predictions(), plot_comparisons(), plot_slopes() functions. fair, many marginaleffects advantages listed come subjective preferences user interface. Readers thus encouraged try packages see interface prefer. AFAICT, main advantages emmeans marginaleffects : Omnibus tests. Equivalence noninferiority tests. Multiplicity adjustments. Please let know find features emmeans can add list. Marginal Means Vignette includes side--side comparisons emmeans marginaleffects compute marginal means. rest section compares syntax contrasts marginaleffects.","code":"model <- lm(y ~ x * z, data)  comparisons(   model,   variables = list(x = 1), # what is the effect of 1-unit change in x?   newdata = datagrid(z = -1:1) # when z is held at values -1, 0, or 1 )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"contrasts","dir":"Articles","previous_headings":"emmeans","what":"Contrasts","title":"Alternative Software","text":"far can tell, emmeans provide easy way compute unit-level contrasts every row dataset used fit model. Therefore, side--side syntax shown always include newdata=datagrid() specify want compute one contrast: mean values regressors. day--day practice slopes(), however, extra argument necessary. Fit model: Link scale, pairwise contrasts: Response scale, reference groups:","code":"library(emmeans) library(marginaleffects)  mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\", adjust = \"none\", df = Inf) #>  contrast    estimate      SE  df z.ratio p.value #>  cyl6 - cyl4   -0.905    1.63 Inf  -0.555  0.5789 #>  cyl8 - cyl4  -19.542 4367.17 Inf  -0.004  0.9964 #>  cyl8 - cyl6  -18.637 4367.16 Inf  -0.004  0.9966 #>  #> Degrees-of-freedom method: user-specified  #> Results are given on the log odds ratio (not the response) scale.  comparisons(mod,             type = \"link\",             newdata = \"mean\",             variables = list(cyl = \"pairwise\")) #>  #>  Term Contrast Estimate Std. Error         z Pr(>|z|)   2.5 %  97.5 % #>   cyl    6 - 4  -0.9049       1.63 -0.555059  0.57885    -4.1    2.29 #>   cyl    8 - 4 -19.5418    4367.17 -0.004475  0.99643 -8579.0 8539.95 #>   cyl    8 - 6 -18.6369    4367.17 -0.004268  0.99660 -8578.1 8540.85 #>  #> Prediction type:  link  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl emm <- emmeans(mod, specs = \"cyl\", regrid = \"response\") contrast(emm, method = \"trt.vs.ctrl1\", adjust = \"none\", df = Inf, ratios = FALSE) #>  contrast    estimate    SE  df z.ratio p.value #>  cyl6 - cyl4   -0.222 0.394 Inf  -0.564  0.5727 #>  cyl8 - cyl4   -0.595 0.511 Inf  -1.163  0.2447 #>  #> Degrees-of-freedom method: user-specified  comparisons(mod, newdata = \"mean\") #>  #>  Term Contrast   Estimate Std. Error         z Pr(>|z|)      2.5 %    97.5 % #>    hp       +1 -1.558e-10  6.804e-07 -0.000229  0.99982 -1.334e-06 1.333e-06 #>   cyl    6 - 4 -2.222e-01  3.916e-01 -0.567315  0.57050 -9.898e-01 5.454e-01 #>   cyl    8 - 4 -5.947e-01  5.097e-01 -1.166640  0.24336 -1.594e+00 4.044e-01 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"contrasts-by-group","dir":"Articles","previous_headings":"emmeans","what":"Contrasts by group","title":"Alternative Software","text":"slightly complicated example contrasts estimated subgroup lme4 mixed effects model. First estimate model compute pairwise contrasts subgroup using emmeans: emmeans obtain results? Roughly speaking: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. short, emmeans computes pairwise contrasts marginal means, averages adjusted predictions. different default types contrasts produced comparisons(), reports contrasts adjusted predictions, without averaging across pre-specified grid predictors. comparisons() instead? Let newdata data frame supplied user (original data frame used fit model), : Create new data frame called newdata2, identical newdata except focal variable incremented one level. predict(model, newdata = newdata2) - predict(model, newdata = newdata) Although idiomatic, can use still use comparisons() emulate emmeans results. First, create prediction grid one cell combination categorical predictor model: grid 18 rows, one combination levels resp (3), situ (2), btype (3) variables (3 * 2 * 3 = 18). compute pairwise contrasts grid: 3 pairwise contrasts, corresponding 3 pairwise comparisons possible 3 levels focal variable btype: scold-curse, shout-scold, shout-curse. comparisons() function estimates 3 contrasts row newdata, get \\(18 \\times 3 = 54\\) rows. Finally, wanted contrasts averaged subgroup resp variable, can use avg_comparisons() function argument: results identical produced emmeans (except \\(t\\) vs. \\(z\\)).","code":"library(dplyr) library(lme4) library(emmeans)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv\") dat$woman <- as.numeric(dat$Gender == \"F\")  mod <- glmer(     woman ~ btype * resp + situ + (1 + Anger | item),     family = binomial,     data = dat)  emmeans(mod, specs = \"btype\", by = \"resp\") |>     contrast(method = \"revpairwise\", adjust = \"none\") #> resp = no: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.0152 0.1097 Inf  -0.139  0.8898 #>  shout - curse  -0.2533 0.1022 Inf  -2.479  0.0132 #>  shout - scold  -0.2381 0.0886 Inf  -2.686  0.0072 #>  #> resp = perhaps: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.2393 0.1178 Inf  -2.031  0.0422 #>  shout - curse  -0.0834 0.1330 Inf  -0.627  0.5309 #>  shout - scold   0.1559 0.1358 Inf   1.148  0.2510 #>  #> resp = yes: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse   0.0391 0.1292 Inf   0.302  0.7624 #>  shout - curse   0.5802 0.1784 Inf   3.252  0.0011 #>  shout - scold   0.5411 0.1888 Inf   2.866  0.0042 #>  #> Results are averaged over the levels of: situ  #> Results are given on the log odds ratio (not the response) scale. nd <- datagrid(     model = mod,     resp = dat$resp,     situ = dat$situ,     btype = dat$btype) nrow(nd) #> [1] 18 cmp <- comparisons(mod,     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") nrow(cmp) #> [1] 54 avg_comparisons(mod,     by = \"resp\",     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") #>  #>   Term                  Contrast    resp Estimate Std. Error       z  Pr(>|z|)   2.5 %    97.5 % #>  btype mean(scold) - mean(curse)      no -0.01520    0.10965 -0.1386 0.8897581 -0.2301  0.199715 #>  btype mean(scold) - mean(curse) perhaps -0.23928    0.11779 -2.0314 0.0422130 -0.4701 -0.008416 #>  btype mean(scold) - mean(curse)     yes  0.03907    0.12922  0.3023 0.7623876 -0.2142  0.292344 #>  btype mean(shout) - mean(curse)      no -0.25330    0.10219 -2.4786 0.0131889 -0.4536 -0.053004 #>  btype mean(shout) - mean(curse) perhaps -0.08336    0.13303 -0.6266 0.5309040 -0.3441  0.177372 #>  btype mean(shout) - mean(curse)     yes  0.58018    0.17842  3.2518 0.0011468  0.2305  0.929873 #>  btype mean(shout) - mean(scold)      no -0.23810    0.08864 -2.6860 0.0072316 -0.4118 -0.064358 #>  btype mean(shout) - mean(scold) perhaps  0.15592    0.13583  1.1479 0.2510250 -0.1103  0.422149 #>  btype mean(shout) - mean(scold)     yes  0.54111    0.18881  2.8660 0.0041574  0.1711  0.911161 #>  #> Prediction type:  link  #> Columns: type, term, contrast, resp, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects","dir":"Articles","previous_headings":"emmeans","what":"Marginal Effects","title":"Alternative Software","text":"far can tell, emmeans::emtrends makes easier compute marginal effects user-specified values large grids full original dataset. Response scale, user-specified values: Link scale, user-specified values:","code":"mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)  emtrends(mod, ~hp, \"hp\", regrid = \"response\", at = list(cyl = 4)) #>   hp hp.trend    SE  df asymp.LCL asymp.UCL #>  147 -0.00786 0.011 Inf   -0.0294    0.0137 #>  #> Confidence level used: 0.95  slopes(mod, newdata = datagrid(cyl = 4)) #>  #>  Term Contrast  Estimate Std. Error       z Pr(>|z|)    2.5 %  97.5 % cyl #>    hp    dY/dX -0.007852    0.01111 -0.7069  0.47964 -0.02962 0.01392   4 #>   cyl    6 - 4 -0.222185    0.39164 -0.5673  0.57050 -0.98979 0.54542   4 #>   cyl    8 - 4 -0.594685    0.50974 -1.1666  0.24336 -1.59376 0.40439   4 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl, eps emtrends(mod, ~hp, \"hp\", at = list(cyl = 4)) #>   hp hp.trend     SE  df asymp.LCL asymp.UCL #>  147  -0.0326 0.0339 Inf    -0.099    0.0338 #>  #> Confidence level used: 0.95  slopes(mod, type = \"link\", newdata = datagrid(cyl = 4)) #>  #>  Term Contrast  Estimate Std. Error         z Pr(>|z|)      2.5 %    97.5 % cyl #>    hp    dY/dX  -0.03257  3.388e-02 -0.961445  0.33633 -9.898e-02 3.383e-02   4 #>   cyl    6 - 4  -0.90487  1.630e+00 -0.555059  0.57885 -4.100e+00 2.290e+00   4 #>   cyl    8 - 4 -19.54176  4.367e+03 -0.004475  0.99643 -8.579e+03 8.540e+03   4 #>  #> Prediction type:  link  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"more-examples","dir":"Articles","previous_headings":"emmeans","what":"More examples","title":"Alternative Software","text":"emmeans vs. marginaleffects comparisons:","code":"# Example of examining a continuous x categorical interaction using emmeans and marginaleffects # Authors: Cameron Patrick and Vincent Arel-Bundock  library(tidyverse) library(emmeans) library(marginaleffects)  # use the mtcars data, set up am as a factor data(mtcars) mc <- mtcars |> mutate(am = factor(am))  # fit a linear model to mpg with wt x am interaction m <- lm(mpg ~ wt*am, data = mc) summary(m)  # 1. means for each level of am at mean wt. emmeans(m, \"am\") marginal_means(m, variables = \"am\") predictions(m, newdata = datagrid(am = 0:1))  # 2. means for each level of am at wt = 2.5, 3, 3.5. emmeans(m, c(\"am\", \"wt\"), at = list(wt = c(2.5, 3, 3.5))) predictions(m, newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5))  # 3. means for wt = 2.5, 3, 3.5, averaged over levels of am (implicitly!). emmeans(m, \"wt\", at = list(wt = c(2.5, 3, 3.5)))  # same thing, but the averaging is more explicit, using the `by` argument predictions(   m,   newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5)),   by = \"wt\")  # 4. graphical version of 2. emmip(m, am ~ wt, at = list(wt = c(2.5, 3, 3.5)), CIs = TRUE) plot_predictions(m, condition = c(\"wt\", \"am\"))  # 5. compare levels of am at specific values of wt. # this is a bit ugly because the emmeans defaults for pairs() are silly. # infer = TRUE: enable confidence intervals. # adjust = \"none\": begone, Tukey. # reverse = TRUE: contrasts as (later level) - (earlier level) pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE)  comparisons(   m,   variables = \"am\",   newdata = datagrid(wt = c(2.5, 3, 3.5)))  # 6. plot of pairswise comparisons plot(pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE))  # Since `wt` is numeric, the default is to plot it as a continuous variable on # the x-axis.  But not that this is the **exact same info** as in the emmeans plot. plot_comparisons(m, effect = \"am\", condition = \"wt\")  # You of course customize everything, set draw=FALSE, and feed the raw data to feed to ggplot2 p <- plot_comparisons(   m,   effect = \"am\",   condition = list(wt = c(2.5, 3, 3.5)),   draw = FALSE)  ggplot(p, aes(y = wt, x = comparison, xmin = conf.low, xmax = conf.high)) +   geom_pointrange()  # 7. slope of wt for each level of am emtrends(m, \"am\", \"wt\") slopes(m, newdata = datagrid(am = 0:1))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"margins-and-prediction","dir":"Articles","previous_headings":"","what":"margins and prediction","title":"Alternative Software","text":"margins prediction packages R designed Thomas Leeper emulate behavior margins command Stata. packages trailblazers strongly influenced development marginaleffects. main benefits marginaleffects packages : Support model types Faster Memory efficient Plots using ggplot2 instead Base R extensive test suite Active development syntax two packages similar.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Average Marginal Effects","title":"Alternative Software","text":"","code":"library(margins) library(marginaleffects)  mod <- lm(mpg ~ cyl + hp + wt, data = mtcars)  mar <- margins(mod) summary(mar) #>  factor     AME     SE       z      p   lower   upper #>     cyl -0.9416 0.5509 -1.7092 0.0874 -2.0214  0.1382 #>      hp -0.0180 0.0119 -1.5188 0.1288 -0.0413  0.0052 #>      wt -3.1670 0.7406 -4.2764 0.0000 -4.6185 -1.7155  mfx <- slopes(mod)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"individual-level-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Individual-Level Marginal Effects","title":"Alternative Software","text":"Marginal effects user-specified data frame:","code":"head(data.frame(mar)) #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt X_weights X_at_number #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 22.82043 0.6876212 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 22.01285 0.6056817 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.96040 0.7349593 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.93608 0.5800910 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.16780 0.8322986 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 20.25036 0.6638322 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1  head(mfx) #>  #>  Term Estimate Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>   cyl  -0.9416     0.5509 -1.709 0.087417 -2.021 0.1382 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, cyl, hp, wt, eps nd <- data.frame(cyl = 4, hp = 110, wt = 3)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects-at-the-mean","dir":"Articles","previous_headings":"margins and prediction","what":"Marginal Effects at the Mean","title":"Alternative Software","text":"","code":"mar <- margins(mod, data = data.frame(prediction::mean_or_mode(mtcars)), unit_ses = TRUE) data.frame(mar) #>        mpg    cyl     disp       hp     drat      wt     qsec     vs      am   gear   carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt SE_dydx_cyl SE_dydx_hp SE_dydx_wt X_weights X_at_number #> 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 20.09062 0.4439832 -0.9416168 -0.0180381 -3.166973    0.3035082 0.0001410452   0.5484409   0.5509157 0.01187625  0.7405679        NA           1  slopes(mod, newdata = \"mean\") #>  #>  Term Estimate Std. Error      z   Pr(>|z|)    2.5 %    97.5 % #>   cyl -0.94162    0.55092 -1.709   0.087417 -2.02139  0.138160 #>    hp -0.01804    0.01188 -1.519   0.128803 -0.04132  0.005239 #>    wt -3.16697    0.74058 -4.276 1.8997e-05 -4.61848 -1.715471 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, cyl, hp, wt, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"counterfactual-average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Counterfactual Average Marginal Effects","title":"Alternative Software","text":"argument margins package emulates Stata fixing values variables user-specified values, replicating full dataset several times combination supplied values (see Stata section ). example, dataset includes 32 rows user calls =list(cyl=c(4, 6)), margins compute 64 unit-level marginal effects estimates:","code":"dat <- mtcars dat$cyl <- factor(dat$cyl) mod <- lm(mpg ~ cyl * hp + wt, data = mtcars)  mar <- margins(mod, at = list(cyl = c(4, 6, 8))) summary(mar) #>  factor    cyl     AME     SE       z      p   lower   upper #>     cyl 4.0000  0.0381 0.5998  0.0636 0.9493 -1.1374  1.2137 #>     cyl 6.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>     cyl 8.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>      hp 4.0000 -0.0878 0.0267 -3.2937 0.0010 -0.1400 -0.0355 #>      hp 6.0000 -0.0499 0.0154 -3.2397 0.0012 -0.0800 -0.0197 #>      hp 8.0000 -0.0120 0.0108 -1.1065 0.2685 -0.0332  0.0092 #>      wt 4.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236 #>      wt 6.0000 -3.1198 0.6613 -4.7176 0.0000 -4.4160 -1.8236 #>      wt 8.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236  avg_slopes(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  Term    Contrast Estimate Std. Error        z   Pr(>|z|)    2.5 %    97.5 % cyl #>   cyl mean(dY/dX)  0.03814    0.59989  0.06357 0.94930949 -1.13762  1.213899   4 #>   cyl mean(dY/dX)  0.03814    0.59989  0.06357 0.94930949 -1.13762  1.213899   6 #>   cyl mean(dY/dX)  0.03814    0.59989  0.06357 0.94930949 -1.13762  1.213899   8 #>    hp mean(dY/dX) -0.08778    0.02665 -3.29366 0.00098892 -0.14002 -0.035545   4 #>    hp mean(dY/dX) -0.04987    0.01539 -3.23974 0.00119639 -0.08004 -0.019701   6 #>    hp mean(dY/dX) -0.01197    0.01081 -1.10649 0.26851517 -0.03316  0.009229   8 #>    wt mean(dY/dX) -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 -1.823648   4 #>    wt mean(dY/dX) -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 -1.823648   6 #>    wt mean(dY/dX) -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 -1.823648   8 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, cyl, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"margins and prediction","what":"Adjusted Predictions","title":"Alternative Software","text":"syntax compute adjusted predictions using predictions package marginaleffects similar:","code":"prediction::prediction(mod) |> head() #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 21.90488 0.6927034 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 21.10933 0.6266557 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.64753 0.6652076 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.04859 0.6041400 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.25445 0.7436172 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 19.53360 0.6436862  marginaleffects::predictions(mod) |> head() #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     21.90     0.6927 31.62 < 2.22e-16 20.55  23.26 #>     21.11     0.6267 33.69 < 2.22e-16 19.88  22.34 #>     25.65     0.6652 38.56 < 2.22e-16 24.34  26.95 #>     20.05     0.6041 33.19 < 2.22e-16 18.86  21.23 #>     17.25     0.7436 23.20 < 2.22e-16 15.80  18.71 #>     19.53     0.6437 30.35 < 2.22e-16 18.27  20.80 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, cyl, hp, wt"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata","dir":"Articles","previous_headings":"","what":"Stata","title":"Alternative Software","text":"Stata good expensive software package statistical analysis. published StataCorp LLC. section compares Stata’s margins command marginaleffects. results produced marginaleffects extensively tested Stata. See test suite list dozens models compared estimates standard errors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"average-marginal-effect-ames","dir":"Articles","previous_headings":"Stata","what":"Average Marginal Effect (AMEs)","title":"Alternative Software","text":"Marginal effects unit-level quantities. compute “average marginal effects”, first calculate marginal effects observation dataset. , take mean unit-level marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-1","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"Stata","title":"Alternative Software","text":"Stata’s margins command slopes function can calculate average marginal effects (AMEs). example showing estimate AMEs Stata:","code":"quietly reg mpg cyl hp wt margins, dydx(*)  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS   Expression   : Linear prediction, predict() dy/dx w.r.t. : cyl hp wt   ------------------------------------------------------------------------------     |            Delta-method     |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] ------------------------------------------------------------------------------ cyl |  -.9416168   .5509164    -1.71   0.098    -2.070118    .1868842  hp |  -.0180381   .0118762    -1.52   0.140    -.0423655    .0062893  wt |  -3.166973   .7405759    -4.28   0.000    -4.683974   -1.649972 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"marginaleffects","title":"Alternative Software","text":"results can obtained slopes() summary() like : Note Stata reports t statistics marginaleffects reports Z. produces slightly different p-values model low degrees freedom: mtcars 32 rows","code":"library(\"marginaleffects\") mod <- lm(mpg ~ cyl + hp + wt, data = mtcars) avg_slopes(mod) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)    2.5 %    97.5 % #>   cyl -0.94162    0.55092 -1.709   0.087417 -2.02139  0.138159 #>    hp -0.01804    0.01188 -1.519   0.128803 -0.04132  0.005239 #>    wt -3.16697    0.74058 -4.276 1.8997e-05 -4.61848 -1.715471 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"Stata","what":"Counterfactual Marginal Effects","title":"Alternative Software","text":"“counterfactual marginal effect” special quantity obtained replicating dataset fixing regressor user-defined values. Concretely, Stata computes counterfactual marginal effects 3 steps: Duplicate whole dataset 3 times sets values cyl three specified values subsets. Calculate marginal effects observation large grid. Take average marginal effects value variable interest.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-2","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"Stata","title":"Alternative Software","text":"argument, Stata’s margins command estimates average counterfactual marginal effects. example:","code":"quietly reg mpg i.cyl##c.hp wt margins, dydx(hp) at(cyl = (4 6 8))  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict() dy/dx w.r.t. : hp  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+---------------------------------------------------------------- hp           |          _at |           1  |   -.099466   .0348665    -2.85   0.009    -.1712749   -.0276571           2  |  -.0213768    .038822    -0.55   0.587    -.1013323    .0585787           3  |   -.013441   .0125138    -1.07   0.293    -.0392137    .0123317 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects-1","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"marginaleffects","title":"Alternative Software","text":"can estimate average counterfactual marginal effects slopes() using datagridcf() create counterfactual dataset full original dataset replicated potential value cyl variable. , tell argument average within groups: equivalent taking group-wise mean observation-level marginal effects (without argument): Note following Stata, standard errors group-averaged marginal effects computed taking “Jacobian mean:”","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  avg_slopes(     mod,     variables = \"hp\",     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  Term    Contrast Estimate Std. Error       z Pr(>|z|)    2.5 %   97.5 % cyl #>    hp mean(dY/dX) -0.09947    0.03487 -2.8528 0.004334 -0.16780 -0.03113   4 #>    hp mean(dY/dX) -0.02138    0.03882 -0.5506 0.581884 -0.09747  0.05471   6 #>    hp mean(dY/dX) -0.01344    0.01251 -1.0741 0.282780 -0.03797  0.01109   8 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, cyl, predicted, predicted_hi, predicted_lo mfx <- slopes(     mod,     variables = \"hp\",     newdata = datagridcf(cyl = c(4, 6, 8))) aggregate(estimate ~ term + cyl, data = mfx, FUN = mean) #>   term cyl    estimate #> 1   hp   4 -0.09946598 #> 2   hp   6 -0.02137679 #> 3   hp   8 -0.01344103 J <- attr(mfx, \"jacobian\") J_mean <- aggregate(J, by = list(mfx$cyl), FUN = mean) J_mean <- as.matrix(J_mean[, 2:ncol(J_mean)]) sqrt(diag(J_mean %*% vcov(mod) %*% t(J_mean))) #> [1] 0.03486650 0.03882204 0.01251382"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-3","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"Stata","title":"Alternative Software","text":"Just like Stata’s margins command computes average counterfactual marginal effects, can also estimate average counterfactual adjusted predictions. example: , Stata background: duplicates whole dataset 3 times sets values cyl three specified values subsets. calculates predictions large grid. takes average prediction value cyl. words, average counterfactual adjusted predictions implemented Stata hybrid predictions observed values (default marginaleffects::predictions) predictions representative values.","code":"quietly reg mpg i.cyl##c.hp wt margins, at(cyl = (4 6 8))  Predictive margins                              Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict()  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |     Margin   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+----------------------------------------------------------------          _at |           1  |   17.44233   2.372914     7.35   0.000     12.55522    22.32944           2  |    18.9149   1.291483    14.65   0.000     16.25505    21.57476           3  |   18.33318   1.123874    16.31   0.000     16.01852    20.64785 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects-2","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"marginaleffects","title":"Alternative Software","text":"can estimate average counterfactual adjusted predictions predictions() , first, setting grid_type argument datagrid() \"counterfactual\" , second, averaging predictions using argument summary(), manual function like dplyr::summarise().","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  predictions(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  cyl Estimate Std. Error      z   Pr(>|z|) 2.5 % 97.5 % #>    4    17.44      2.373  7.351 1.9733e-13 12.79  22.09 #>    6    18.91      1.291 14.646 < 2.22e-16 16.38  21.45 #>    8    18.33      1.124 16.312 < 2.22e-16 16.13  20.54 #>  #> Prediction type:  response  #> Columns: type, cyl, estimate, std.error, statistic, p.value, conf.low, conf.high  predictions(     mod,     newdata = datagridcf(cyl = c(4, 6, 8))) |>     group_by(cyl) |>     summarize(AAP = mean(estimate)) #> # A tibble: 3 × 2 #>   cyl     AAP #>   <fct> <dbl> #> 1 4      17.4 #> 2 6      18.9 #> 3 8      18.3"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"brmsmargins","dir":"Articles","previous_headings":"","what":"brmsmargins","title":"Alternative Software","text":"brmsmargins package developed Joshua Wiley: package functions calculate marginal effects brms models ( http://paul-buerkner.github.io/brms/ ). central motivator calculate average marginal effects (AMEs) continuous discrete predictors fixed effects mixed effects regression models including location scale models. main advantage brmsmargins marginaleffects ability compute “Marginal Coefficients” following method described Hedeker et al (2012). main advantages marginaleffects brmsmargins : Support 60+ model types, rather just brms package. Simpler user interface (subjective). time writing (2022-05-25) brmsmargins support certain brms models multivariate multinomial outcomes. also support custom outcome transformations. rest section presents side--side replications analyses brmsmargins vignettes order show highlight parallels differences syntax.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ames-for-logistic-regression","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Fixed Effects Models","what":"AMEs for Logistic Regression","title":"Alternative Software","text":"Estimate logistic regression model brms: Compute AMEs manually: Compute AMEs brmsmargins: Compute AMEs using marginaleffects: mpg element Effect column marginaleffects matches M column output brmsmargins.","code":"library(brms) library(brmsmargins) library(marginaleffects) library(data.table) library(withr) h <- 1e-4  void <- capture.output(     bayes.logistic <- brm(       vs ~ am + mpg, data = mtcars,       family = \"bernoulli\", seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) d1 <- d2 <- mtcars d2$mpg <- d2$mpg + h p1 <- posterior_epred(bayes.logistic, newdata = d1) p2 <- posterior_epred(bayes.logistic, newdata = d2) m <- (p2 - p1) / h quantile(rowMeans(m), c(.5, .025, .975)) #>        50%       2.5%      97.5%  #> 0.07014014 0.05437810 0.09159280 bm <- brmsmargins(   bayes.logistic,   add = data.frame(mpg = c(0, 0 + h)),   contrasts = cbind(\"AME MPG\" = c(-1 / h, 1 / h)),   CI = 0.95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>            M        Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID   Label #> 1 0.07118446 0.07014014 0.0543781 0.0915928          NA         NA 0.95    ETI <NA> <NA> AME MPG avg_slopes(bayes.logistic)  #>  #>  Term Estimate    2.5 %   97.5 % #>    am -0.31810 -0.52182 -0.07808 #>   mpg  0.07015  0.05439  0.09158 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects-for-mixed-effects-models","dir":"Articles","previous_headings":"brmsmargins","what":"Marginal Effects for Mixed Effects Models","title":"Alternative Software","text":"Estimate mixed effects logistic regression model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nGroups <- 100     nObs <- 20     theta.location <- matrix(rnorm(nGroups * 2), nrow = nGroups, ncol = 2)     theta.location[, 1] <- theta.location[, 1] - mean(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] - mean(theta.location[, 2])     theta.location[, 1] <- theta.location[, 1] / sd(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] / sd(theta.location[, 2])     theta.location <- theta.location %*% chol(matrix(c(1.5, -.25, -.25, .5^2), 2))     theta.location[, 1] <- theta.location[, 1] - 2.5     theta.location[, 2] <- theta.location[, 2] + 1     d <- data.table(       x = rep(rep(0:1, each = nObs / 2), times = nGroups))     d[, ID := rep(seq_len(nGroups), each = nObs)]      for (i in seq_len(nGroups)) {       d[ID == i, y := rbinom(         n = nObs,         size = 1,         prob = plogis(theta.location[i, 1] + theta.location[i, 2] * x))         ]     }     copy(d)   })  void <- capture.output(     mlogit <- brms::brm(       y ~ 1 + x + (1 + x | ID), family = \"bernoulli\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) #> Warning: There were 61 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ame-including-random-effects","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Including Random Effects","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"includeRE\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.1113512 0.1114643 0.08037199 0.1419889          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(mlogit) #>  #>  Term Estimate   2.5 % 97.5 % #>     x   0.1115 0.08037  0.142 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ame-fixed-effects-only-grand-mean","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Fixed Effects Only (Grand Mean)","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"fixedonly\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.1038071 0.1032705 0.06328158 0.1485747          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(mlogit, re_formula = NA) #>  #>  Term Estimate   2.5 % 97.5 % #>     x   0.1033 0.06328 0.1486 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ames-for-fixed-effects-location-scale-models","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"AMEs for Fixed Effects Location Scale Models","title":"Alternative Software","text":"Estimate fixed effects location scale model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nObs <- 1000L     d <- data.table(       grp = rep(0:1, each = nObs / 2L),       x = rnorm(nObs, mean = 0, sd = 0.25))     d[, y := rnorm(nObs,                    mean = x + grp,                    sd = exp(1 + x + grp))]     copy(d)   })  void <- capture.output(     ls.fe <- brm(bf(       y ~ 1 + x + grp,       sigma ~ 1 + x + grp),       family = \"gaussian\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"fixed-effects-only","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Fixed effects only","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M     Mdn        LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 1.625042 1.63264 0.7558805 2.497346          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(ls.fe, re_formula = NA) #>  #>  Term Estimate  2.5 % 97.5 % #>   grp    1.012 0.3482  1.678 #>     x    1.633 0.7559  2.497 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"discrete-change-and-distributional-parameter-dpar","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Discrete change and distributional parameter (dpar)","title":"Alternative Software","text":"Compute contrast adjusted predictions sigma parameter, grp=0 grp=1: marginaleffects use comparisons() function variables argument:","code":"bm <- brmsmargins(   ls.fe,   at = data.frame(grp = c(0, 1)),   contrasts = cbind(\"AME grp\" = c(-1, 1)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID   Label #> 1 4.901384 4.895236 4.404996 5.417512          NA         NA 0.95    ETI <NA> <NA> AME grp avg_comparisons(   ls.fe,   variables = list(grp = 0:1),   dpar = \"sigma\") #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   grp    1 - 0    4.895 4.405  5.418 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effect-continuous-on-sigma","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Marginal effect (continuous) on sigma","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 4.455297 4.443977 3.500513 5.449401          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(ls.fe, dpar = \"sigma\", re_formula = NA) #>  #>  Term Estimate 2.5 % 97.5 % #>   grp    5.287 4.694  5.926 #>     x    4.444 3.501  5.450 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"effects","dir":"Articles","previous_headings":"","what":"effects","title":"Alternative Software","text":"effects package created John Fox colleagues. marginaleffects supports 30+ model types effects. effects focuses computation “adjusted predictions.” plots produces roughly equivalent ones produced plot_predictions predictions functions marginaleffects. effects appear support marginal effects (slopes), marginal means, contrasts effects uses Base graphics whereas marginaleffects uses ggplot2 effects includes lot powerful options customize plots. contrast, marginaleffects produces objects can customized chaining ggplot2 functions. Users can also call plot_predictions(model, draw=FALSE) create prediction grid, work raw data directly create plot need effects offers several options currently available marginaleffects, including: Partial residuals plots Many types ways plot adjusted predictions: package vignette","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"modelbased","dir":"Articles","previous_headings":"","what":"modelbased","title":"Alternative Software","text":"modelbased package developed easystats team. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means marginal effects. Powerful functions create beautiful plots.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ggeffects","dir":"Articles","previous_headings":"","what":"ggeffects","title":"Alternative Software","text":"ggeffects package developed Daniel Lüdecke. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta method","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"default strategy compute standard errors confidence intervals delta method. obtain calling: Since default method, obtain results add inferences() call chain:","code":"avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") #>  #>         Term Contrast    Species Estimate Std. Error       z Pr(>|z|)   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11025     0.2852 -0.3866  0.69903 -0.6692 0.4487 #>  Petal.Width mean(+1) versicolor -0.02006     0.1600 -0.1254  0.90020 -0.3336 0.2935 #>  Petal.Width mean(+1)  virginica  0.02159     0.1689  0.1278  0.89830 -0.3095 0.3526 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"delta\") #>  #>         Term Contrast    Species Estimate Std. Error       z Pr(>|z|)   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11025     0.2852 -0.3866  0.69903 -0.6692 0.4487 #>  Petal.Width mean(+1) versicolor -0.02006     0.1600 -0.1254  0.90020 -0.3336 0.2935 #>  Petal.Width mean(+1)  virginica  0.02159     0.1689  0.1278  0.89830 -0.3095 0.3526 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"bootstrap","dir":"Articles","previous_headings":"","what":"Bootstrap","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"marginaleffects supports two bootstrap frameworks R: well-established boot package newer rsample package.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"boot","dir":"Articles","previous_headings":"Bootstrap","what":"boot","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"unknown arguments feed inferences() pushed forward boot::boot(): can extract original boot object attribute: can extract individual draws posterior_draws() function:","code":"avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"boot\") #>  #>         Term Contrast    Species Estimate Std. Error   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11025     0.2181 -0.5037 0.3767 #>  Petal.Width mean(+1) versicolor -0.02006     0.2105 -0.5198 0.3426 #>  Petal.Width mean(+1)  virginica  0.02159     0.2132 -0.4547 0.3839 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, std.error, conf.low, conf.high est <- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"boot\", sim = \"balanced\", R = 500, conf_type = \"bca\") est #>  #>         Term Contrast    Species Estimate Std. Error   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11025     0.2031 -0.8193 0.1839 #>  Petal.Width mean(+1) versicolor -0.02006     0.2117 -0.4516 0.3922 #>  Petal.Width mean(+1)  virginica  0.02159     0.2076 -0.3556 0.4664 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, std.error, conf.low, conf.high attr(est, \"inferences\") #>  #> BALANCED BOOTSTRAP #>  #>  #> Call: #> bootstrap_boot(model = model, FUN = FUN, newdata = ..1, vcov = ..2,  #>     variables = ..3, type = ..4, by = ..5, conf_level = ..6,  #>     transform_pre = ..7, transform_post = ..8, wts = ..9, hypothesis = ..10,  #>     eps = ..11) #>  #>  #> Bootstrap Statistics : #>        original      bias    std. error #> t1* -0.11025325  0.08145124   0.2031020 #> t2* -0.02006005 -0.01556682   0.2117018 #> t3*  0.02158742 -0.05832215   0.2076338 posterior_draws(est) |> head() #>   drawid         draw     type        term contrast    Species    estimate predicted predicted_hi predicted_lo std.error   conf.low conf.high #> 1      1  0.088355898 response Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 0.2031020 -0.8192714 0.1838868 #> 2      1  0.148208862 response Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 0.2117018 -0.4516199 0.3922270 #> 3      1  0.107308251 response Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 0.2076338 -0.3555986 0.4663712 #> 4      2 -0.198365447 response Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 0.2031020 -0.8192714 0.1838868 #> 5      2 -0.005503732 response Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 0.2117018 -0.4516199 0.3922270 #> 6      2 -0.598391493 response Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 0.2076338 -0.3555986 0.4663712  posterior_draws(est, shape = \"DxP\") |> dim() #> [1] 500   3"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"rsample","dir":"Articles","previous_headings":"Bootstrap","what":"rsample","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":", can pass arguments rsample::bootstraps() inferences(). example, stratified resampling: can extract individual draws posterior_draws() function:","code":"est <- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"rsample\", R = 100, strata = \"Species\") est #>  #>         Term Contrast    Species Estimate   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11025 -0.5655 0.3992 #>  Petal.Width mean(+1) versicolor -0.02006 -0.3331 0.3123 #>  Petal.Width mean(+1)  virginica  0.02159 -0.3551 0.3162 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, conf.low, conf.high  attr(est, \"inferences\") #> # Bootstrap sampling using stratification with apparent sample  #> # A tibble: 101 × 3 #>    splits           id           estimates        #>    <list>           <chr>        <list>           #>  1 <split [150/51]> Bootstrap001 <tibble [3 × 8]> #>  2 <split [150/59]> Bootstrap002 <tibble [3 × 8]> #>  3 <split [150/48]> Bootstrap003 <tibble [3 × 8]> #>  4 <split [150/54]> Bootstrap004 <tibble [3 × 8]> #>  5 <split [150/52]> Bootstrap005 <tibble [3 × 8]> #>  6 <split [150/50]> Bootstrap006 <tibble [3 × 8]> #>  7 <split [150/55]> Bootstrap007 <tibble [3 × 8]> #>  8 <split [150/47]> Bootstrap008 <tibble [3 × 8]> #>  9 <split [150/56]> Bootstrap009 <tibble [3 × 8]> #> 10 <split [150/54]> Bootstrap010 <tibble [3 × 8]> #> # … with 91 more rows posterior_draws(est) |> head() #>   drawid        draw     type        term contrast    Species    estimate predicted predicted_hi predicted_lo   conf.low conf.high #> 1      1 -0.44406864 response Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 -0.5654854 0.3992197 #> 2      1 -0.26145047 response Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 -0.3331141 0.3122893 #> 3      1 -0.17415204 response Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 -0.3551387 0.3162376 #> 4      2  0.01002854 response Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 -0.5654854 0.3992197 #> 5      2 -0.05854871 response Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 -0.3331141 0.3122893 #> 6      2 -0.09278661 response Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 -0.3551387 0.3162376  posterior_draws(est, shape = \"PxD\") |> dim() #> [1]   3 100"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"simulation-based-inference","dir":"Articles","previous_headings":"","what":"Simulation-based inference","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"simulation-based strategy compute confidence intervals described Krinsky & Robb (1986) popularized King, Tomz, Wittenberg (2000). proceed 3 steps: Draw R sets simulated coefficients multivariate normal distribution mean equal original model’s estimated coefficients variance equal model’s variance-covariance matrix (classical, “HC3”, ). Use R sets coefficients compute R sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error. examples: Since simulation based inference generates R estimates quantities interest, can treat similarly draws posterior distribution bayesian models. example, can extract draws using posterior_draws() function, plot distributions using packages likeggplot2 ggdist:","code":"library(ggplot2) library(ggdist)  avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"simulation\") #>  #>         Term Contrast    Species Estimate Std. Error   2.5 % 97.5 % #>  Petal.Width mean(+1)     setosa -0.11390      0.280 -0.6523 0.4382 #>  Petal.Width mean(+1) versicolor -0.02550      0.164 -0.3715 0.2796 #>  Petal.Width mean(+1)  virginica  0.01034      0.171 -0.3362 0.3295 #>  #> Prediction type:  response  #> Columns: type, term, contrast, Species, estimate, std.error, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"simulation\") |>   posterior_draws(\"rvar\") |>   ggplot(aes(y = Species, xdist = rvar)) +   stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"logistic-regression-with-multiplicative-interactions","dir":"Articles","previous_headings":"","what":"Logistic regression with multiplicative interactions","title":"Bayesian analysis with brms","text":"Load libraries download data passengers Titanic Rdatasets archive: Fit logit model multiplicative interaction:","code":"library(marginaleffects) library(brms) library(ggplot2) library(ggdist)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv\") dat$survived <- ifelse(dat$survived == \"yes\", 1, 0) dat$woman <- ifelse(dat$sex == \"female\", 1, 0) mod <- brm(survived ~ woman * age + passengerClass,            family = bernoulli(link = \"logit\"),            data = dat)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"can compute adjusted predicted values outcome variable (.e., probability survival aboard Titanic) using predictions function. default, function calculates predictions row dataset: visualize relationship outcome one regressors, can plot conditional adjusted predictions plot_predictions function:  Compute adjusted predictions user-specified values regressors, using newdata argument datagrid function: posterior_draws function samples posterior distribution model, produces data frame drawid draw columns. “long” format makes easy plots results:","code":"pred <- predictions(mod) head(pred) #>  #>  Estimate  2.5 % 97.5 % #>    0.9367 0.9070 0.9590 #>    0.8493 0.7453 0.9187 #>    0.9433 0.8949 0.9704 #>    0.5131 0.4302 0.6000 #>    0.9375 0.9080 0.9601 #>    0.2731 0.2029 0.3518 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, survived, woman, age, passengerClass plot_predictions(mod, condition = \"age\") pred <- predictions(mod,                     newdata = datagrid(woman = 0:1,                                        passengerClass = c(\"1st\", \"2nd\", \"3rd\"))) pred #>  #>  Estimate   2.5 % 97.5 % woman passengerClass #>    0.5149 0.43192 0.6019     0            1st #>    0.2013 0.15362 0.2613     0            2nd #>    0.0875 0.06556 0.1141     0            3rd #>    0.9364 0.90661 0.9588     1            1st #>    0.7783 0.70897 0.8346     1            2nd #>    0.5701 0.49378 0.6442     1            3rd #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, survived, age, woman, passengerClass pred <- posterior_draws(pred) head(pred) #>   drawid       draw rowid     type   estimate   conf.low conf.high  survived      age woman passengerClass #> 1      1 0.46566713     1 response 0.51492993 0.43192231 0.6018749 0.4082218 29.88113     0            1st #> 2      1 0.16658900     2 response 0.20128833 0.15362308 0.2613351 0.4082218 29.88113     0            2nd #> 3      1 0.08750961     3 response 0.08750369 0.06555724 0.1141134 0.4082218 29.88113     0            3rd #> 4      1 0.93735755     4 response 0.93641346 0.90660921 0.9587589 0.4082218 29.88113     1            1st #> 5      1 0.77437334     5 response 0.77829290 0.70896643 0.8346419 0.4082218 29.88113     1            2nd #> 6      1 0.62216334     6 response 0.57010265 0.49377997 0.6441967 0.4082218 29.88113     1            3rd ggplot(pred, aes(x = draw, fill = factor(woman))) +     geom_density() +     facet_grid(~ passengerClass, labeller = label_both) +     labs(x = \"Predicted probability of survival\", y = \"\", fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Marginal effects","title":"Bayesian analysis with brms","text":"Use slopes() compute marginal effects (slopes regression equation) row dataset, use ) compute “Average Marginal Effects”, , average observation-level marginal effects: Compute marginal effects regressors fixed user-specified values, regressors held means: Compute plot conditional marginal effects:  posterior_draws produces dataset drawid draw columns: can use dataset plot results. example, plot posterior density marginal effect age woman variable equal 0 1:","code":"mfx <- slopes(mod) mfx #>  #>   Term Contrast   Estimate      2.5 %     97.5 % #>  woman    dY/dX  0.1529810  0.1088301  0.2051898 #>  woman    dY/dX  0.1354646  0.0360765  0.2970409 #>  woman    dY/dX  0.0587891  0.0287561  0.1009453 #>  woman    dY/dX  0.6545371  0.5669930  0.7442501 #>  woman    dY/dX  0.1382874  0.0972243  0.1863969 #> --- 4174 rows omitted. See ?avg_slopes and ?print.marginaleffects ---  #>  passengerClass 3rd - 1st -0.2642843 -0.3397125 -0.1986620 #>  passengerClass 3rd - 1st -0.3527451 -0.4262574 -0.2823186 #>  passengerClass 3rd - 1st -0.4593140 -0.5506994 -0.3695048 #>  passengerClass 3rd - 1st -0.4549515 -0.5463443 -0.3652652 #>  passengerClass 3rd - 1st -0.4364994 -0.5260837 -0.3497621  #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, survived, woman, age, passengerClass, eps slopes(     mod,     newdata = datagrid(         woman = 1,         passengerClass = \"1st\")) #>  #>            Term  Contrast   Estimate     2.5 %    97.5 % woman passengerClass #>           woman     dY/dX  0.1562784  0.111359  0.208756     1            1st #>             age     dY/dX -0.0002383 -0.001355  0.000871     1            1st #>  passengerClass 2nd - 1st -0.1574416 -0.223275 -0.102890     1            1st #>  passengerClass 3rd - 1st -0.3653764 -0.438319 -0.294769     1            1st #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, survived, age, woman, passengerClass, eps plot_slopes(mod, effect = \"woman\", condition = \"age\") draws <- posterior_draws(mfx)  dim(draws) #> [1] 16736000       17  head(draws) #>   drawid      draw rowid     type  term contrast   estimate   conf.low conf.high predicted predicted_hi predicted_lo survived woman     age passengerClass   eps #> 1      1 0.1633609     1 response woman    dY/dX 0.15298096 0.10883007 0.2051898 0.9366604    0.9366751    0.9366604        1     1 29.0000            1st 1e-04 #> 2      1 0.1359009     2 response woman    dY/dX 0.13546458 0.03607654 0.2970409 0.8493050    0.8493174    0.8493050        1     0  0.9167            1st 1e-04 #> 3      1 0.0615405     3 response woman    dY/dX 0.05878909 0.02875607 0.1009453 0.9433293    0.9433358    0.9433293        0     1  2.0000            1st 1e-04 #> 4      1 0.7088821     4 response woman    dY/dX 0.65453708 0.56699300 0.7442501 0.5131011    0.5131652    0.5131011        0     0 30.0000            1st 1e-04 #> 5      1 0.1473759     5 response woman    dY/dX 0.13828737 0.09722433 0.1863969 0.9374937    0.9375085    0.9374937        0     1 25.0000            1st 1e-04 #> 6      1 0.6635099     6 response woman    dY/dX 0.70740470 0.58935737 0.8406470 0.2730542    0.2731252    0.2730542        1     0 48.0000            1st 1e-04 mfx <- slopes(mod,     variables = \"age\",     newdata = datagrid(woman = 0:1)) |>     posterior_draws()  ggplot(mfx, aes(x = draw, fill = factor(woman))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal Effect of Age on Survival\",          y = \"Posterior density\",          fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"random-effects-model","dir":"Articles","previous_headings":"","what":"Random effects model","title":"Bayesian analysis with brms","text":"section replicates analyses random effects model published Andrew Heiss’ blog post: “guide correctly calculating posterior predictions average marginal effects multilevel Bayesian models.” objective mainly illustrate use marginaleffects. Please refer original post detailed discussion quantities computed . Load libraries download data: Fit basic model:","code":"library(brms) library(ggdist) library(patchwork) library(marginaleffects)  vdem_2015 <- read.csv(\"https://github.com/vincentarelbundock/marginaleffects/raw/main/data-raw/vdem_2015.csv\")  head(vdem_2015) #>   country_name country_text_id year                           region media_index party_autonomy_ord polyarchy civil_liberties party_autonomy #> 1       Mexico             MEX 2015  Latin America and the Caribbean       0.837                  3     0.631           0.704           TRUE #> 2     Suriname             SUR 2015  Latin America and the Caribbean       0.883                  4     0.777           0.887           TRUE #> 3       Sweden             SWE 2015 Western Europe and North America       0.956                  4     0.915           0.968           TRUE #> 4  Switzerland             CHE 2015 Western Europe and North America       0.939                  4     0.901           0.960           TRUE #> 5        Ghana             GHA 2015               Sub-Saharan Africa       0.858                  4     0.724           0.921           TRUE #> 6 South Africa             ZAF 2015               Sub-Saharan Africa       0.898                  4     0.752           0.869           TRUE mod <- brm(   bf(media_index ~ party_autonomy + civil_liberties + (1 | region),      phi ~ (1 | region)),   data = vdem_2015,   family = Beta(),   control = list(adapt_delta = 0.9))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Random effects model","what":"Posterior predictions","title":"Bayesian analysis with brms","text":"compute posterior predictions specific values regressors, use newdata argument datagrid function. also use type argument compute two types predictions: accounting residual (observation-level) residual variance (prediction) ignoring (response). Extract posterior draws plot :","code":"nd = datagrid(model = mod,               party_autonomy = c(TRUE, FALSE),               civil_liberties = .5,               region = \"Middle East and North Africa\") p1 <- predictions(mod, type = \"response\", newdata = nd) |>     posterior_draws() p2 <- predictions(mod, type = \"prediction\", newdata = nd) |>     posterior_draws() pred <- rbind(p1, p2) ggplot(pred, aes(x = draw, fill = party_autonomy)) +     stat_halfeye(alpha = .5) +     facet_wrap(~ type) +     labs(x = \"Media index (predicted)\",           y = \"Posterior density\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Marginal effects and contrasts","title":"Bayesian analysis with brms","text":"noted Marginal Effects vignette, one distinct marginal effect combination regressor values. , consider one combination regressor values, region “Middle East North Africa”, civil_liberties 0.5. , calculate mean posterior distribution marginal effects: Use posterior_draws() extract draws posterior distribution marginal effects, plot :  Plot marginal effects, conditional regressor:","code":"mfx <- slopes(mod,                        newdata = datagrid(civil_liberties = .5,                                           region = \"Middle East and North Africa\")) mfx #>  #>             Term     Contrast Estimate  2.5 % 97.5 % civil_liberties                       region #>   party_autonomy TRUE - FALSE   0.2517 0.1663 0.3356             0.5 Middle East and North Africa #>  civil_liberties        dY/dX   0.8160 0.6214 1.0066             0.5 Middle East and North Africa #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, media_index, party_autonomy, civil_liberties, region, eps mfx <- posterior_draws(mfx)  ggplot(mfx, aes(x = draw, y = term)) +   stat_halfeye() +   labs(x = \"Marginal effect\", y = \"\") plot_slopes(mod,          effect = \"civil_liberties\",          condition = \"party_autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"continuous-predictors","dir":"Articles","previous_headings":"Random effects model","what":"Continuous predictors","title":"Bayesian analysis with brms","text":"slope line different values civil liberties can obtained : plotted:  slopes function can use ellipsis (...) push argument forward posterior_predict function. can alter types predictions returned. example, re_formula=NA argument posterior_predict.brmsfit method compute marginaleffects without including group-level effects:","code":"pred <- predictions(mod,                     newdata = datagrid(party_autonomy = FALSE,                                        region = \"Middle East and North Africa\",                                        civil_liberties = seq(0, 1, by = 0.05))) |>         posterior_draws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") mfx <- slopes(mod,     newdata = datagrid(         civil_liberties = c(.2, .5, .8),         party_autonomy = FALSE,         region = \"Middle East and North Africa\"),     variables = \"civil_liberties\") mfx #>  #>             Term Estimate  2.5 % 97.5 % civil_liberties party_autonomy                       region #>  civil_liberties   0.4900 0.3609 0.6388             0.2          FALSE Middle East and North Africa #>  civil_liberties   0.8071 0.6122 0.9927             0.5          FALSE Middle East and North Africa #>  civil_liberties   0.8069 0.6745 0.9337             0.8          FALSE Middle East and North Africa #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, media_index, civil_liberties, party_autonomy, region, eps mfx <- posterior_draws(mfx)  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\") mfx <- slopes(     mod,     newdata = datagrid(         civil_liberties = c(.2, .5, .8),         party_autonomy = FALSE,         region = \"Middle East and North Africa\"),     variables = \"civil_liberties\",     re_formula = NA) |>     posterior_draws()  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"global-grand-mean","dir":"Articles","previous_headings":"Random effects model","what":"Global grand mean","title":"Bayesian analysis with brms","text":"","code":"pred <- predictions(     mod,     re_formula = NA,     newdata = datagrid(party_autonomy = c(TRUE, FALSE))) |>     posterior_draws()  mfx <- slopes(     mod,     re_formula = NA,     variables = \"party_autonomy\") |>     posterior_draws()  plot1 <- ggplot(pred, aes(x = draw, fill = party_autonomy)) +          stat_halfeye(slab_alpha = .5) +          labs(x = \"Media index (Predicted)\",               y = \"Posterior density\",               fill = \"Party autonomy\")  plot2 <- ggplot(mfx, aes(x = draw)) +          stat_halfeye(slab_alpha = .5)  +          labs(x = \"Contrast: Party autonomy TRUE - FALSE\",               y = \"\",               fill = \"Party autonomy\")  # combine plots using the `patchwork` package plot1 + plot2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"region-specific-predictions-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Region-specific predictions and contrasts","title":"Bayesian analysis with brms","text":"Predicted media index region level civil liberties:  Predicted media index region level civil liberties:  Predicted media index region party autonomy:  TRUE/FALSE contrasts (marginal effects) party autonomy region:","code":"pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = FALSE,                                         civil_liberties = seq(0, 1, length.out = 100))) |>          posterior_draws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     facet_wrap(~ region) +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        civil_liberties = c(.2, .8),                                       party_autonomy = FALSE)) |>         posterior_draws()  ggplot(pred, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     facet_wrap(~ region) +     labs(x = \"Media index (predicted)\",          y = \"Posterior density\",          fill = \"Civil liberties\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = c(TRUE, FALSE),                                        civil_liberties = .5)) |>         posterior_draws()  ggplot(pred, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\") mfx <- slopes(     mod,     variables = \"party_autonomy\",     newdata = datagrid(         region = vdem_2015$region,         civil_liberties = .5)) |>     posterior_draws()  ggplot(mfx, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"hypothetical-groups","dir":"Articles","previous_headings":"Random effects model","what":"Hypothetical groups","title":"Bayesian analysis with brms","text":"can also obtain predictions marginal effects hypothetical group instead one observed regions. achieve , create dataset NA region column. call marginaleffects predictions functions allow_new_levels argument. argument pushed via ellipsis (...) posterior_epred function brms package:","code":"dat <- data.frame(civil_liberties = .5,                   party_autonomy = FALSE,                   region = \"New Region\")  mfx <- slopes(     mod,     variables = \"party_autonomy\",     allow_new_levels = TRUE,     newdata = dat)  draws <- posterior_draws(mfx)  ggplot(draws, aes(x = draw)) +      stat_halfeye() +      labs(x = \"Marginal effect of party autonomy in a generic world region\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"averaging-marginalizing-integrating-random-effects","dir":"Articles","previous_headings":"Random effects model","what":"Averaging, marginalizing, integrating random effects","title":"Bayesian analysis with brms","text":"Consider logistic regression model random effects: can compute adjusted predictions given value x firm (random effects) follows: can average/marginalize/integrate across random effects avg_predictions() function argument: can also draw (assumed gaussian) population distribution random effects, asking predictions() make predictions new “levels” random effects. take average predictions using avg_predictions() argument, “integrated random effects”, described brmsmargins package vignette. code , make predictions 100 firm identifiers original dataset. also ask predictions() push forward allow_new_levels sample_new_levels arguments brms::posterior_epred function: can “integrate ” random effects slopes functions . instance, nearly equivalent brmsmargins command output (slight variations due different random seeds): See alternative software vignette information brmsmargins.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv\") dat$x <- as.numeric(dat$output > median(dat$output)) dat$y <- as.numeric(dat$emp > median(dat$emp)) mod <- brm(y ~ x + (1 | firm), data = dat, backend = \"cmdstanr\", family = \"bernoulli\") p <- predictions(mod, newdata = datagrid(x = 0, firm = unique)) head(p) #>  #>   Estimate     2.5 %   97.5 % x firm #>  1.000e+00 9.012e-01 1.000000 0    1 #>  1.000e+00 8.947e-01 1.000000 0    2 #>  1.000e+00 9.121e-01 1.000000 0    3 #>  1.000e+00 7.971e-01 1.000000 0    4 #>  1.000e+00 9.090e-01 1.000000 0    5 #>  4.899e-08 8.418e-21 0.001898 0    6 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, y, x, firm avg_predictions(mod, newdata = datagrid(x = 0, firm = unique)) #>  #>  Estimate  2.5 % 97.5 % #>    0.4539 0.4396 0.4683 #>  #> Prediction type:  response  #> Columns: type, estimate, conf.low, conf.high  predictions(mod, newdata = datagrid(x = 0:1, firm = unique), by = \"x\") #>  #>  x Estimate  2.5 % 97.5 % #>  0   0.4539 0.4396 0.4683 #>  1   0.5572 0.5456 0.5696 #>  #> Prediction type:  response  #> Columns: type, x, estimate, conf.low, conf.high predictions(     mod,     newdata = datagrid(x = 0:1, firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\",     by = \"x\") #>  #>  x Estimate  2.5 % 97.5 % #>  0   0.4519 0.3436  0.567 #>  1   0.5524 0.4376  0.663 #>  #> Prediction type:  response  #> Columns: type, x, estimate, conf.low, conf.high avg_comparisons(     mod,     newdata = datagrid(firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\") #>  #>  Term Contrast Estimate   2.5 % 97.5 % #>     x    1 - 0   0.0969 0.04778 0.1639 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high library(brmsmargins) bm <- brmsmargins(   k = 100,   object = mod,   at = data.frame(x = c(0, 1)),   CI = .95,   CIType = \"ETI\",   contrasts = cbind(\"AME x\" = c(-1, 1)),   effects = \"integrateoutRE\") bm$ContrastSummary |> data.frame() #>            M        Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.09887903 0.09630984 0.0477415 0.1620762          NA         NA 0.95    ETI <NA> <NA> AME x"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"multinomial-logit","dir":"Articles","previous_headings":"","what":"Multinomial logit","title":"Bayesian analysis with brms","text":"Fit model categorical outcome (heating system choice California houses) logit link:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv\" dat <- read.csv(dat) mod <- brm(depvar ~ ic.gc + oc.gc,            data = dat,            family = categorical(link = \"logit\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"Compute predicted probabilities level outcome variable: Extract posterior draws plot :  Use plot_predictions function plot conditional adjusted predictions level outcome variable gear, conditional value mpg regressor:","code":"pred <- predictions(mod)  head(pred) #>  #>  Group Estimate   2.5 %  97.5 % #>     ec  0.06627 0.04472 0.09305 #>     ec  0.07682 0.05896 0.09740 #>     ec  0.10300 0.06181 0.15850 #>     ec  0.06335 0.04590 0.08379 #>     ec  0.07453 0.05740 0.09468 #>     ec  0.07086 0.04546 0.10360 #>  #> Prediction type:  response  #> Columns: rowid, type, group, estimate, conf.low, conf.high, depvar, ic.gc, oc.gc draws <- posterior_draws(pred)  ggplot(draws, aes(x = draw, fill = group)) +     geom_density(alpha = .2, color = \"white\") +     labs(x = \"Predicted probability\",          y = \"Density\",          fill = \"Heating system\") plot_predictions(mod, condition = \"oc.gc\") +     facet_wrap(~ group) +     labs(y = \"Predicted probability\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Marginal effects","title":"Bayesian analysis with brms","text":"","code":"avg_slopes(mod) #>  #>  Group  Term Estimate   2.5 %   97.5 % #>     ec ic.gc   4.3839   4.007   4.7376 #>     er ic.gc   0.0928  -0.270   0.4149 #>     gc ic.gc  -7.9963  -8.498  -7.4477 #>     ec oc.gc  19.3866  17.717  20.9493 #>     er oc.gc   0.4105  -1.194   1.8349 #>     gc oc.gc -35.3623 -37.581 -32.9363 #>  #> Prediction type:  response  #> Columns: type, group, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"hurdle-models","dir":"Articles","previous_headings":"","what":"Hurdle models","title":"Bayesian analysis with brms","text":"section replicates analyses yet another amazing blog post Andrew Heiss. begin, estimate hurdle model brms random effects, using data gapminder package: 704G","code":"library(gapminder) library(brms) library(dplyr) library(ggplot2) library(ggdist) library(cmdstanr) library(patchwork) library(marginaleffects)  set.seed(1024)  CHAINS <- 4 ITER <- 2000 WARMUP <- 1000 BAYES_SEED <- 1234  gapminder <- gapminder::gapminder |>    filter(continent != \"Oceania\") |>    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap = ifelse(will_be_zero, 0, gdpPercap)) |>    select(-prob_zero, -will_be_zero) |>    # Make a logged version of GDP per capita   mutate(log_gdpPercap = log1p(gdpPercap)) |>    mutate(is_zero = gdpPercap == 0)  mod <- brm(   bf(gdpPercap ~ lifeExp + year + (1 + lifeExp + year | continent),      hu ~ lifeExp),   data = gapminder,   backend = \"cmdstanr\",   family = hurdle_lognormal(),   cores = 2,   chains = CHAINS, iter = ITER, warmup = WARMUP, seed = BAYES_SEED,   silent = 2)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions-2","dir":"Articles","previous_headings":"Hurdle models","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"Adjusted predictions every observation original data: Adjusted predictions hu parameter: Predictions different scale: Plot adjusted predictions function lifeExp:  Predictions one condition re_formula argument brms:","code":"predictions(mod) |> head() #>  #>  Estimate 2.5 % 97.5 % #>     142.5 103.1  218.8 #>     168.3 124.9  255.8 #>     201.7 152.9  303.7 #>     251.5 196.6  372.8 #>     312.2 249.5  454.2 #>     397.5 324.6  566.7 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent predictions(mod, dpar = \"hu\") |> head() #>  #>  Estimate  2.5 % 97.5 % #>    0.5739 0.4747 0.6516 #>    0.5365 0.4416 0.6113 #>    0.4956 0.4069 0.5664 #>    0.4455 0.3656 0.5106 #>    0.3957 0.3252 0.4537 #>    0.3413 0.2824 0.3907 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent predictions(mod, type = \"link\", dpar = \"hu\") |> head() #>  #>  Estimate   2.5 %   97.5 % #>   0.29798 -0.1014  0.62593 #>   0.14627 -0.2347  0.45274 #>  -0.01776 -0.3767  0.26728 #>  -0.21885 -0.5510  0.04244 #>  -0.42336 -0.7301 -0.18572 #>  -0.65730 -0.9326 -0.44428 #>  #> Prediction type:  link  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent plot_predictions(     mod,     condition = \"lifeExp\") +     labs(y = \"mu\") + plot_predictions(     mod,     dpar = \"hu\",     condition = \"lifeExp\") +     labs(y = \"hu\") plot_predictions(     mod,     re_formula = NULL,     condition = c(\"lifeExp\", \"continent\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"extract-draws-with-posterior_draws","dir":"Articles","previous_headings":"Hurdle models","what":"Extract draws with posterior_draws()","title":"Bayesian analysis with brms","text":"posterior_draws() function extract raw samples posterior objects produced marginaleffects. allows us use richer geoms summaries, ggdist package:","code":"predictions(     mod,     re_formula = NULL,     newdata = datagrid(model = mod,                        continent = gapminder$continent,                        year = c(1952, 2007),                        lifeExp = seq(30, 80, 1))) |>     posterior_draws() |>     ggplot(aes(lifeExp, draw, fill = continent, color = continent)) +     stat_lineribbon(alpha = .25) +     facet_grid(year ~ continent)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"average-contrasts","dir":"Articles","previous_headings":"Hurdle models","what":"Average Contrasts","title":"Bayesian analysis with brms","text":"happens gdpPercap lifeExp increases one? happens gdpPercap lifeExp increases one standard deviation? happens gdpPercap lifeExp increases 50 60 year simultaneously increases min max? Plot draws posterior distribution average contrasts (thing draws posterior distribution contrasts):","code":"avg_comparisons(mod) #>  #>     Term Contrast Estimate  2.5 % 97.5 % #>  lifeExp       +1   718.87 515.58 811.96 #>     year       +1   -63.82 -84.44 -41.05 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high avg_comparisons(mod, variables = list(lifeExp = \"sd\")) #>  #>     Term                Contrast Estimate 2.5 % 97.5 % #>  lifeExp (x + sd/2) - (x - sd/2)     4050  3718   4741 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high avg_comparisons(     mod,     variables = list(lifeExp = c(50, 60), year = \"minmax\"),     cross = TRUE) #>  #>  C: lifeExp   C: year Estimate 2.5 % 97.5 % #>     60 - 50 Max - Min   1001.5 522.5   1330 #>     60 - 50 Max - Min   1001.5 522.5   1330 #>     60 - 50 Max - Min   1001.5 522.5   1330 #>     60 - 50 Max - Min   1001.5 522.5   1330 #>     60 - 50 Max - Min   1001.5 522.5   1330 #> --- 1670 rows omitted. See ?print.marginaleffects ---  #>     60 - 50 Max - Min    466.9 112.6   1299 #>     60 - 50 Max - Min    466.9 112.6   1299 #>     60 - 50 Max - Min    466.9 112.6   1299 #>     60 - 50 Max - Min    466.9 112.6   1299 #>     60 - 50 Max - Min    466.9 112.6   1299  #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast_lifeExp, contrast_year, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(mod) |>     posterior_draws() |>     ggplot(aes(estimate, term)) +     stat_dotsinterval() +     labs(x = \"Posterior distribution of average contrasts\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-slopes","dir":"Articles","previous_headings":"Hurdle models","what":"Marginal effects (slopes)","title":"Bayesian analysis with brms","text":"Average Marginal Effect lifeExp different scales different parameters: Plot Conditional Marginal Effects  can call slopes() comparisons() posterior_draws() function even control:","code":"avg_slopes(mod) #>  #>     Term Estimate  2.5 % 97.5 % #>  lifeExp   718.71 515.56 811.70 #>     year   -63.82 -84.44 -41.05 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high  avg_slopes(mod, type = \"link\") #>  #>     Term Estimate    2.5 %    97.5 % #>  lifeExp  0.08249  0.07419  0.088564 #>     year -0.00937 -0.01201 -0.006316 #>  #> Prediction type:  link  #> Columns: type, term, estimate, conf.low, conf.high  avg_slopes(mod, dpar = \"hu\") #>  #>     Term  Estimate     2.5 %    97.5 % #>  lifeExp -0.008171 -0.009367 -0.006687 #>     year  0.000000  0.000000  0.000000 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high  avg_slopes(mod, dpar = \"hu\", type = \"link\") #>  #>     Term Estimate   2.5 %   97.5 % #>  lifeExp -0.09934 -0.1132 -0.08382 #>     year  0.00000  0.0000  0.00000 #>  #> Prediction type:  link  #> Columns: type, term, estimate, conf.low, conf.high plot_slopes(     mod,     effect = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"mu\") +  plot_slopes(     mod,     dpar = \"hu\",     effect = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"hu\") comparisons(     mod,     type = \"link\",     variables = \"lifeExp\",     newdata = datagrid(lifeExp = c(40, 70), continent = gapminder$continent)) |>     posterior_draws() |>     ggplot(aes(draw, continent, fill = continent)) +     stat_dotsinterval() +     facet_grid(lifeExp ~ .) +     labs(x = \"Effect of a 1 unit change in Life Expectancy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Bayesian analysis with brms","text":"bayesian models like produced brms rstanarm packages, marginaleffects package functions report median posterior distribution main estimates. default credible intervals equal-tailed intervals (quantiles), default function identify center distribution median. Users can customize type intervals reported setting global options. Note reported estimate intervals change slightly:","code":"library(insight) library(marginaleffects)  mod <- insight::download_model(\"brms_1\")  options(marginaleffects_posterior_interval = \"hdi\") options(marginaleffects_posterior_center = mean) avg_comparisons(mod) #>  #>  Term Contrast Estimate  2.5 %  97.5 % #>   cyl       +1   -1.500 -2.385 -0.6771 #>    wt       +1   -3.206 -4.704 -1.5704 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high  options(marginaleffects_posterior_interval = \"eti\") options(marginaleffects_posterior_center = stats::median) avg_comparisons(mod) #>  #>  Term Contrast Estimate  2.5 %  97.5 % #>   cyl       +1   -1.494 -2.361 -0.6361 #>    wt       +1   -3.195 -4.792 -1.6450 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"random-variables-posterior-and-ggdist","dir":"Articles","previous_headings":"","what":"Random variables: posterior and ggdist","title":"Bayesian analysis with brms","text":"Recent versions posterior, brms, ggdist packages make easy draw, summarize plot random variables. posterior_draws() can produce objects class rvar make easy use features returning data frame column type rvar:","code":"library(brms) library(ggdist) library(ggplot2) library(marginaleffects) mod <- brm(mpg ~ am, data = mtcars) p <- predictions(mod, by = \"am\") rvar <- posterior_draws(p, shape = \"rvar\")  rvar #>  #>  am Estimate 2.5 % 97.5 % #>   0    17.12 14.75  19.43 #>   1    24.34 21.58  26.97 #>  #> Prediction type:  response  #> Columns: type, am, estimate, conf.low, conf.high, rvar  ggplot(rvar, aes(y = am, xdist = rvar)) +    stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"non-linear-hypothesis-testing","dir":"Articles","previous_headings":"","what":"Non-linear hypothesis testing","title":"Bayesian analysis with brms","text":"begin estimating model: Notice can compute average contrasts two different ways, using avg_comparisons() function transform_pre argument: Now, use hypothesis argument compare first second rows comparisons() output: hypotheses function brms package can also perform non-linear hypothesis testing, generates convenient statistics summaries. function accepts D--P matrix draws posterior distribution, D number draws N number parameters. can obtain matrix using posterior_draws(x, shape = \"DxP\"), can simply add couple calls chain operations:","code":"mod <- brm(am ~ mpg + hp, data = mtcars, family = bernoulli(),            seed = 1024, silent = 2, chains = 4, iter = 1000) avg_comparisons(mod) #>  #>  Term Contrast Estimate    2.5 %  97.5 % #>    hp       +1 0.005987 0.002884 0.00886 #>   mpg       +1 0.135474 0.078713 0.17472 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high  comparisons(mod, transform_pre = \"differenceavg\") #>  #>  Term Contrast Estimate    2.5 %  97.5 % #>   mpg mean(+1) 0.135474 0.078713 0.17472 #>    hp mean(+1) 0.005987 0.002884 0.00886 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo comparisons(     mod,     transform_pre = \"differenceavg\",     hypothesis = \"b2 - b1 = 0.2\") #>  #>       Term Estimate   2.5 %  97.5 % #>  b2-b1=0.2  -0.3298 -0.3666 -0.2748 #>  #> Prediction type:  response  #> Columns: type, term, estimate, conf.low, conf.high avg_comparisons(mod) |>     posterior_draws(shape = \"DxP\") |>     brms::hypothesis(\"b2 - b1 > .2\") #> Hypothesis Tests for class : #>         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star #> 1 (b2-b1)-(.2) > 0    -0.07      0.02    -0.12    -0.04          0         0      #> --- #> 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses. #> '*': For one-sided hypotheses, the posterior probability exceeds 95%; #> for two-sided hypotheses, the value tested against lies outside the 95%-CI. #> Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"simple-example-titanic","dir":"Articles","previous_headings":"","what":"Simple example: Titanic","title":"Comparisons","text":"Consider logistic regression model estimated using Titanic mortality data: question interests us : probability survival (outcome) change passenger travels 1st class vs. 3rd class? answer question straightforward , non-linear models interactions, effect change one variable depends values covariates model. Therefore, need refine question: probability survival (outcome) change 25 year old man travels 1st class vs. 3rd class? , estimand difference probabilities PClass=\"1st\" PClass=\"3rd\", estimand conditional values covariates Age=25 SexCode=1. comparisons() function, variables argument determines scientific query (estimand comparison), newdata argument determines estimate query (conditional covariate values). example: can compute contrast different “kinds” individuals, changing datagrid() call. function accepts functions vectors. , compute contrast probabilities survival 1st 3rd class oldest men women passengers: specify newdata argument, comparisons() calculate contrast every single combination covariate values original data. means obtain data frame results number rows original data. makes sense, non-linear models models interactions, individual can different contrast: big dataset contrasts like one can unwieldy. common strategy summarize unit-level contrasts taking average. can achieved using avg_comparisons() function argument: Note average contrasts often nice interpretation causal inference context, outcome parametric g-formula estimation. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html rest vignette highlights features flexible powerful comparisons() function.","code":"library(marginaleffects)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) mod <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial) comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")),   newdata = datagrid(Age = 25, SexCode = 0)) #>  #>    Term  Contrast Estimate Std. Error    z   Pr(>|z|) 2.5 % 97.5 % Age SexCode #>  PClass 1st - 3rd   0.3918    0.07491 5.23 1.6947e-07 0.245 0.5386  25       0 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, PClass, Age, SexCode comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")),   newdata = datagrid(Age = range, SexCode = 0:1)) #>  #>    Term  Contrast Estimate Std. Error     z   Pr(>|z|)    2.5 % 97.5 %   Age SexCode #>  PClass 1st - 3rd  0.44260    0.14818 2.987 0.00281726  0.15218 0.7330  0.17       0 #>  PClass 1st - 3rd  0.47018    0.13297 3.536 0.00040642  0.20956 0.7308  0.17       1 #>  PClass 1st - 3rd  0.07107    0.04533 1.568 0.11690206 -0.01777 0.1599 71.00       0 #>  PClass 1st - 3rd  0.52411    0.20599 2.544 0.01094812  0.12038 0.9278 71.00       1 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, PClass, Age, SexCode cmp <- comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")))  # number of contrast estimates nrow(cmp) #> [1] 756  # number of observations in the model nobs(mod) #> [1] 756 avg_comparisons(mod, by = \"PClass\") #>  #>     Term              Contrast PClass  Estimate Std. Error      z   Pr(>|z|)     2.5 %    97.5 % #>   PClass mean(2nd) - mean(1st)    1st -0.200686   0.036485 -5.500 3.7873e-08 -0.272195 -0.129176 #>   PClass mean(2nd) - mean(1st)    2nd -0.217672   0.041560 -5.238 1.6276e-07 -0.299128 -0.136215 #>   PClass mean(2nd) - mean(1st)    3rd -0.246775   0.050681 -4.869 1.1207e-06 -0.346108 -0.147442 #>   PClass mean(3rd) - mean(1st)    1st -0.367209   0.044051 -8.336 < 2.22e-16 -0.453548 -0.280871 #>   PClass mean(3rd) - mean(1st)    2nd -0.406367   0.043521 -9.337 < 2.22e-16 -0.491667 -0.321068 #>   PClass mean(3rd) - mean(1st)    3rd -0.408779   0.049654 -8.233 < 2.22e-16 -0.506099 -0.311459 #>  SexCode     mean(1) - mean(0)    1st  0.589466   0.045990 12.817 < 2.22e-16  0.499327  0.679606 #>  SexCode     mean(1) - mean(0)    2nd  0.704701   0.045534 15.476 < 2.22e-16  0.615456  0.793946 #>  SexCode     mean(1) - mean(0)    3rd  0.293547   0.056171  5.226 1.7325e-07  0.183454  0.403639 #>      Age              mean(+1)    1st -0.005706   0.001476 -3.865 0.00011097 -0.008599 -0.002813 #>      Age              mean(+1)    2nd -0.009270   0.001734 -5.346 8.9948e-08 -0.012669 -0.005871 #>      Age              mean(+1)    3rd -0.004256   0.002113 -2.014 0.04401973 -0.008399 -0.000114 #>  #> Prediction type:  response  #> Columns: type, term, contrast, PClass, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  avg_comparisons(mod, variables = \"SexCode\", by = \"PClass\") #>  #>     Term          Contrast PClass Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  SexCode mean(1) - mean(0)    1st   0.5895    0.04599 12.817 < 2.22e-16 0.4993 0.6796 #>  SexCode mean(1) - mean(0)    2nd   0.7047    0.04553 15.476 < 2.22e-16 0.6155 0.7939 #>  SexCode mean(1) - mean(0)    3rd   0.2935    0.05617  5.226 1.7325e-07 0.1835 0.4036 #>  #> Prediction type:  response  #> Columns: type, term, contrast, PClass, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"logical-and-factor-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Logical and factor predictors","title":"Comparisons","text":"Consider simple model logical factor variable: comparisons function automatically computes contrasts level categorical variables, relative baseline category (FALSE logicals, reference level factors), holding values observed values. avg_comparisons() , marginalizes taking average unit-level estimates: summary printed says moving reference category 4 level 6 cyl factor variable associated change -6.156 adjusted prediction. Similarly, contrast FALSE TRUE variable equal 2.560. can obtain different contrasts using comparisons() function. example: comparison, code produces results using emmeans package: Note commands also work types models, GLMs, different scales:","code":"library(marginaleffects)  tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) cmp <- avg_comparisons(mod) cmp #>  #>  Term     Contrast Estimate Std. Error      z   Pr(>|z|)     2.5 % 97.5 % #>    am TRUE - FALSE    2.560      1.298  1.973    0.04851   0.01675  5.103 #>   cyl        6 - 4   -6.156      1.536 -4.009 6.1077e-05  -9.16608 -3.146 #>   cyl        8 - 4  -10.068      1.452 -6.933 4.1146e-12 -12.91359 -7.222 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(mod, variables = list(cyl = \"sequential\")) #>  #>  Term Contrast Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>   cyl    6 - 4   -6.156      1.536 -4.009 6.1077e-05 -9.166 -3.146 #>   cyl    8 - 6   -3.911      1.470 -2.660  0.0078051 -6.793 -1.030 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(cyl = \"pairwise\")) #>  #>  Term Contrast Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 % #>   cyl    6 - 4   -6.156      1.536 -4.009 6.1077e-05  -9.166 -3.146 #>   cyl    8 - 4  -10.068      1.452 -6.933 4.1146e-12 -12.914 -7.222 #>   cyl    8 - 6   -3.911      1.470 -2.660  0.0078051  -6.793 -1.030 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(cyl = \"reference\")) #>  #>  Term Contrast Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 % #>   cyl    6 - 4   -6.156      1.536 -4.009 6.1077e-05  -9.166 -3.146 #>   cyl    8 - 4  -10.068      1.452 -6.933 4.1146e-12 -12.914 -7.222 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high library(emmeans) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\") #>  contrast    estimate   SE df t.ratio p.value #>  cyl6 - cyl4    -6.16 1.54 28  -4.009  0.0012 #>  cyl8 - cyl4   -10.07 1.45 28  -6.933  <.0001 #>  cyl8 - cyl6    -3.91 1.47 28  -2.660  0.0331 #>  #> Results are averaged over the levels of: am  #> P value adjustment: tukey method for comparing a family of 3 estimates  emm <- emmeans(mod, specs = \"am\") contrast(emm, method = \"revpairwise\") #>  contrast     estimate  SE df t.ratio p.value #>  TRUE - FALSE     2.56 1.3 28   1.973  0.0585 #>  #> Results are averaged over the levels of: cyl mod_logit <- glm(am ~ factor(gear), data = mtcars, family = binomial)  avg_comparisons(mod_logit) #>  #>  Term Contrast Estimate Std. Error         z   Pr(>|z|) 2.5 % 97.5 % #>  gear    4 - 3   0.6667  1.361e-01     4.899 9.6296e-07   0.4 0.9334 #>  gear    5 - 3   1.0000  1.071e-05 93335.529 < 2.22e-16   1.0 1.0000 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod_logit, type = \"link\") #>  #>  Term Contrast Estimate Std. Error        z Pr(>|z|)  2.5 % 97.5 % #>  gear    4 - 3    21.26       4578 0.004644  0.99629  -8951   8994 #>  gear    5 - 3    41.13       9156 0.004492  0.99642 -17904  17986 #>  #> Prediction type:  link  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"character-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Character predictors","title":"Comparisons","text":"functions marginaleffects package attempt treat character predictors factor predictors. However, using factors instead characters modeling strongly encouraged, much safer faster. factors hold useful information full list levels, makes easier track handle internally marginaleffects. Users strongly encouraged convert character variables factor fitting models using slopes functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"numeric-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Numeric predictors","title":"Comparisons","text":"can also compute contrasts differences numeric variables. example, can see happens adjusted predictions increment hp variable 1 unit (default) 5 units: Compare adjusted predictions change regressor two arbitrary values: Compare adjusted predictions regressor changes across interquartile range, across one two standard deviations mean, across full range:","code":"mod <- lm(mpg ~ hp, data = mtcars)  avg_comparisons(mod) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)    2.5 %   97.5 % #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = 5)) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)   2.5 % 97.5 % #>    hp       +5  -0.3411     0.0506 -6.742 1.558e-11 -0.4403 -0.242 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(mod, variables = list(hp = c(90, 110))) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 %  97.5 % #>    hp 110 - 90   -1.365     0.2024 -6.742 1.558e-11 -1.761 -0.9679 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(mod, variables = list(hp = \"iqr\")) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 % 97.5 % #>    hp  Q3 - Q1   -5.697      0.845 -6.742 1.558e-11 -7.353 -4.041 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"sd\")) #>  #>  Term                Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 % 97.5 % #>    hp (x + sd/2) - (x - sd/2)   -4.678     0.6938 -6.742 1.558e-11 -6.038 -3.318 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"2sd\")) #>  #>  Term            Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 % 97.5 % #>    hp (x - sd) - (x + sd)   -9.356      1.388 -6.742 1.558e-11 -12.08 -6.636 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"minmax\")) #>  #>  Term  Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 % 97.5 % #>    hp Max - Min   -19.31      2.864 -6.742 1.558e-11 -24.92  -13.7 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"interactions","dir":"Articles","previous_headings":"","what":"Interactions","title":"Comparisons","text":"contexts like know happens two () predictors change time. marginaleffects package terminology, “interaction contrasts.” example, consider model two factor variables: happens increases 1 unit cyl changes baseline reference another level? variables argument used model formula includes interactions, “cross-contrasts” automatically displayed. can also force comparisons() setting interactions=TRUE using variables argument specify variables manipulated simultaneously.","code":"mod <- lm(mpg ~ am * factor(cyl), data = mtcars) avg_comparisons(mod, variables = c(\"cyl\", \"am\")) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)    2.5 % 97.5 % #>   cyl    6 - 4   -5.292      1.608 -3.290 0.0010004  -8.4437 -2.140 #>   cyl    8 - 4   -9.810      1.516 -6.470   9.8e-11 -12.7820 -6.838 #>    am    1 - 0    2.247      1.335  1.684 0.0921982  -0.3684  4.863 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"quantities-of-interest","dir":"Articles","previous_headings":"","what":"Quantities of interest","title":"Comparisons","text":"section compares 4 quantities: Unit-Level Contrasts Average Contrast Contrast Mean Contrast Marginal Means ideas discussed section focus contrasts, carry directly analogous types marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"unit-level-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Unit-level contrasts","title":"Comparisons","text":"models interactions non-linear components (e.g., link function), value contrast marginal effect can depend value predictors model. result, contrasts marginal effects fundamentally unit-level quantities. effect 1 unit increase \\(X\\) can different Mary John. Every row dataset different contrast marginal effect. mtcars dataset 32 rows, comparisons() function produces 32 contrast estimates:","code":"library(marginaleffects) mod <- glm(vs ~ factor(gear) + mpg, family = binomial, data = mtcars) cmp <- comparisons(mod, variables = \"mpg\") nrow(cmp) #> [1] 32"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"average-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Average contrasts","title":"Comparisons","text":"default, slopes() comparisons() functions compute marginal effects contrasts every row original dataset. unit-level estimates can great interest, discussed another vignette. Nevertheless, one may want focus one-number summaries: avg_*() functions argument compute “Average Marginal Effect” “Average Contrast,” taking mean unit-level estimates. equivalent : also show full distribution contrasts across dataset histogram:  graph display effect change 1 unit mpg variable, individual observed data.","code":"avg_comparisons(mod, variables = \"mpg\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>   mpg       +1  0.06081    0.01284 4.737 2.1714e-06 0.03565 0.08597 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  comparisons(mod, variables = \"mpg\", by = TRUE) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>   mpg       +1  0.06081    0.01284 4.737 2.1714e-06 0.03565 0.08597 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high mean(cmp$estimate) #> [1] 0.06080995 library(ggplot2)  cmp <- comparisons(mod, variables = \"gear\")  ggplot(cmp, aes(estimate)) +     geom_histogram(bins = 30) +     facet_wrap(~contrast, scale = \"free_x\") +     labs(x = \"Distribution of unit-level contrasts\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"contrasts-at-the-mean","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts at the mean","title":"Comparisons","text":"alternative used common now fallen bit disfavor compute “Contrasts mean.” idea create “synthetic” “hypothetical” individual (row dataset) whose characteristics completely average. , compute report contrast specific hypothetical individual. can achieved setting newdata=\"mean\" newdata=datagrid(), fix variables means modes: Contrasts mean can differ substantially average contrasts. advantage approach cheap fast computationally. disadvantage interpretation somewhat ambiguous. Often times, simply exist individual perfectly average across dimensions dataset. also clear analyst particularly interested contrast one, synthetic, perfectly average individual.","code":"comparisons(mod, variables = \"mpg\", newdata = \"mean\") #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)   2.5 % 97.5 % #>   mpg       +1   0.1665    0.06246 2.666 0.007686 0.04407 0.2889 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, gear, mpg, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"contrasts-between-marginal-means","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts between marginal means","title":"Comparisons","text":"Yet another type contrast “Contrast marginal means.” type contrast closely related “Contrast mean”, wrinkles. default approach used emmeans package R. Roughly speaking, procedure follows: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. contrast obtained approach two critical characteristics: contrast synthetic individual perfectly average qualities every (numeric) predictor. weighted average unit-level contrasts, weights assume perfectly balanced dataset across every categorical predictor. respect (), analyst ask : quantity interest contrast perfectly average hypothetical individual? respect (b), analyst ask : quantity interest contrast model estimated using (potentially) unbalanced data, interpreted data perfectly balanced? example, imagine one control variables model variable measuring educational attainment 4 categories: high school, High school, college, Completed college. contrast marginal weighted average contrasts estimated 4 cells, contrasts weighted equally overall estimate. population interest highly unbalanced educational categories, estimate computed way useful. contrasts marginal means really quantity interest, easy use comparisons() estimate contrasts marginal means. newdata determines values predictors want compute contrasts. can set newdata=\"marginalmeans\" emulate emmeans behavior. example, compute contrasts model interaction: equivalent emmeans: emmeans section Alternative Software vignette shows examples. excellent vignette emmeans package discuss issues slightly different (positive) way: point marginal means cell.means give equal weight cell. many situations (especially experimental data), much fairer way compute marginal means, biased imbalances data. , sense, estimating marginal means , experiment balanced. Estimated marginal means (EMMs) serve need. said, certainly situations equal weighting appropriate. Suppose, example, data sales product given different packaging features. data unbalanced customers attracted combinations others. goal understand scientifically packaging features inherently profitable, equally weighted EMMs may appropriate; goal predict maximize profit, ordinary marginal means provide better estimates can expect marketplace.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") mod <- lm(bill_length_mm ~ species * sex + island + body_mass_g, data = dat)  avg_comparisons(     mod,     newdata = \"marginalmeans\",     variables = c(\"species\", \"island\")) #>  #>     Term           Contrast Estimate Std. Error      z Pr(>|z|)   2.5 %  97.5 % #>  species Chinstrap - Adelie 10.26934     0.4067 25.252  < 2e-16  9.4723 11.0664 #>  species    Gentoo - Adelie  5.89568     0.6773  8.705  < 2e-16  4.5683  7.2231 #>   island     Dream - Biscoe -0.45571     0.4533 -1.005  0.31472 -1.3441  0.4327 #>   island Torgersen - Biscoe  0.08507     0.4701  0.181  0.85639 -0.8363  1.0064 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high emm <- emmeans(     mod,     specs = c(\"species\", \"island\")) contrast(emm, method = \"trt.vs.ctrl1\") #>  contrast                            estimate    SE  df t.ratio p.value #>  Chinstrap Biscoe - Adelie Biscoe     10.2693 0.407 324  25.252  <.0001 #>  Gentoo Biscoe - Adelie Biscoe         5.8957 0.677 324   8.705  <.0001 #>  Adelie Dream - Adelie Biscoe         -0.4557 0.453 324  -1.005  0.8274 #>  Chinstrap Dream - Adelie Biscoe       9.8136 0.434 324  22.630  <.0001 #>  Gentoo Dream - Adelie Biscoe          5.4400 0.941 324   5.779  <.0001 #>  Adelie Torgersen - Adelie Biscoe      0.0851 0.470 324   0.181  0.9994 #>  Chinstrap Torgersen - Adelie Biscoe  10.3544 0.622 324  16.656  <.0001 #>  Gentoo Torgersen - Adelie Biscoe      5.9808 0.954 324   6.268  <.0001 #>  #> Results are averaged over the levels of: sex  #> P value adjustment: dunnettx method for 8 tests"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"conditional-contrasts","dir":"Articles","previous_headings":"","what":"Conditional contrasts","title":"Comparisons","text":"Consider model interaction term. happens dependent variable hp variable increases 10 units?","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt, data = mtcars)  plot_comparisons(     mod,     effect = list(hp = 10),     condition = \"wt\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"transformations","dir":"Articles","previous_headings":"","what":"Transformations","title":"Comparisons","text":"far focused simple differences adjusted predictions. Now, show use ratios, back transformations, arbitrary functions estimate slew quantities interest. Powerful transformations custom contrasts made possible using three arguments act different stages computation process: transform_pre transform_post Consider case model single predictor \\(x\\). compute average contrasts, proceed follows: Compute adjusted predictions row dataset observed values \\(x\\): \\(\\hat{y}_x\\) Compute adjusted predictions row dataset observed values \\(x + 1\\): \\(\\hat{y}_{x+1}\\) transform_pre: Compute unit-level contrasts taking difference (function ) adjusted predictions: \\(\\hat{y}_{x+1} - \\hat{y}_x\\) Compute average contrast taking mean unit-level contrasts: \\(1/N \\sum_{=1}^N \\hat{y}_{x+1} - \\hat{y}_x\\) transform_post: Transform average contrast return -. transform_pre argument comparisons() function determines adjusted predictions combined create contrast. default, take simple difference predictions hi value \\(x\\), predictions lo value \\(x\\): function(hi, lo) hi-lo. transform_post argument comparisons() function applies custom transformation unit-level contrasts. transform_post argument applies custom transformation final quantity, returned evaluated call without transform_post.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"differences","dir":"Articles","previous_headings":"","what":"Differences","title":"Comparisons","text":"default contrast calculate comparisons() function (untransformed) difference two adjusted predictions. instance, estimate effect change 1 unit, : can use avg_comparisons() function , argument obtain results:","code":"library(marginaleffects)  mod <- glm(vs ~ mpg, data = mtcars, family = binomial)  # construct data  mtcars_minus <- mtcars_plus <- mtcars mtcars_minus$mpg <- mtcars_minus$mpg - 0.5 mtcars_plus$mpg <- mtcars_plus$mpg + 0.5  # adjusted predictions yhat_minus <- predict(mod, newdata = mtcars_minus, type = \"response\") yhat_plus <- predict(mod, newdata = mtcars_plus, type = \"response\")  # unit-level contrasts con <- yhat_plus - yhat_minus  # average contrasts mean(con) #> [1] 0.05540227 avg_comparisons(mod) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>   mpg       +1   0.0554   0.008327 6.653 2.8699e-11 0.03908 0.07172 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  comparisons(mod, by = TRUE) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>   mpg       +1   0.0554   0.008327 6.653 2.8699e-11 0.03908 0.07172 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"difference-in-differences-in-differences","dir":"Articles","previous_headings":"","what":"Difference-in-Differences(-in-Differences)","title":"Comparisons","text":"Going back Titanic example: case, contrast difference predicted probabilities. can compute contrast different types individuals: One can notice , gap predicted probabilities survival men women larger 1st class 3rd class. woman matters chances survival travel first class. difference contrasts (diff--diff) statistically significant? answer question, can compute difference--difference using hypothesis argument (see Hypothesis vignette details). example, using b1 b2 refer contrasts first second rows output , can test difference two quantities different 0: Now, let’s say consider types individuals: results, compute triple difference:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial) comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>  #>     Term Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % PClass #>  SexCode    1 - 0   0.4828    0.06308 7.653 1.9593e-14 0.3591 0.6064    1st #>  SexCode    1 - 0   0.3351    0.06343 5.283 1.2703e-07 0.2108 0.4594    3rd #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, SexCode, Age, PClass, eps comparisons(   titanic,   hypothesis = \"b1 - b2 = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>  #>     Term Estimate Std. Error     z Pr(>|z|)    2.5 % 97.5 % #>  b1-b2=0   0.1477    0.08945 1.651 0.098742 -0.02764  0.323 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>  #>     Term Contrast Estimate Std. Error       z Pr(>|z|)    2.5 % 97.5 % PClass   Age #>  SexCode    1 - 0  0.10807     0.1224  0.8827 0.377423 -0.13190 0.3480    1st  0.17 #>  SexCode    1 - 0  0.87952     0.0570 15.4293  < 2e-16  0.76780 0.9912    1st 71.00 #>  SexCode    1 - 0  0.08049     0.1570  0.5127 0.608149 -0.22721 0.3882    3rd  0.17 #>  SexCode    1 - 0  0.42648     0.2031  2.1002 0.035714  0.02847 0.8245    3rd 71.00 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, SexCode, PClass, Age, eps comparisons(   titanic,   hypothesis = \"(b1 - b3) - (b2 - b4) = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>  #>               Term Estimate Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  (b1-b3)-(b2-b4)=0  -0.4255     0.3589 -1.185  0.23585 -1.129  0.278 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"ratios","dir":"Articles","previous_headings":"","what":"Ratios","title":"Comparisons","text":"Instead taking simple differences adjusted predictions, can sometimes useful compute ratios functions predictions. example, adjrr function Stata software package can compute “adjusted risk ratios”, ratios adjusted predictions. R, use transform_pre argument: result average adjusted risk ratio, , adjusted predictions mpg incremented 1, divided adjusted predictions mpg original value. transform_pre accepts different values common types contrasts: ‘difference’, ‘ratio’, ‘lnratio’, ‘ratioavg’, ‘lnratioavg’, ‘lnoravg’, ‘differenceavg’. strings shortcuts functions accept two vectors adjusted predictions returns single vector contrasts. example, two commands yield identical results: mechanism powerful, lets users create fully customized contrasts. non-sensical example: arguments work plotting function plot_comparisons() well, allows us plot various custom contrasts. comparison Adjusted Risk Ratio Adjusted Risk Difference model probability survival aboard Titanic:  default, standard errors around contrasts computed using delta method scale determined type argument (e.g., “link” “response”). analysts may prefer proceed differently. example, Stata, adjrr computes adjusted risk ratios (ARR) two steps: Compute natural log ratio mean adjusted predictions \\(x+1\\) mean adjusted predictions \\(x\\). Exponentiate estimate confidence interval bounds. Step 1 easy achieve transform_pre argument described . Step 2 can achieved transform_post argument: Note equivalent results can obtained using shortcut strings transform_pre argument: “ratio”, “lnratio”, “lnratioavg”. arguments apply plotting functions marginaleffects package well. example can plot Adjusted Risk Ratio model quadratic term:","code":"avg_comparisons(mod, transform_pre = \"ratio\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   mpg       +1    1.287     0.1328 9.697 < 2.22e-16 1.027  1.548 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(mod, transform_pre = \"ratio\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   mpg       +1    1.287     0.1328 9.697 < 2.22e-16 1.027  1.548 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(mod, transform_pre = function(hi, lo) hi / lo) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   mpg       +1    1.287     0.1328 9.697 < 2.22e-16 1.027  1.548 #>  #> Prediction type:  response  #> Pre-transformation:  transform_pre  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(mod, transform_pre = function(hi, lo) sqrt(hi) / log(lo + 10)) #>  #>  Term Contrast Estimate Std. Error    z   Pr(>|z|)  2.5 % 97.5 % #>   mpg       +1   0.2641    0.02614 10.1 < 2.22e-16 0.2128 0.3153 #>  #> Prediction type:  response  #> Pre-transformation:  transform_pre  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high library(ggplot2) library(patchwork) titanic <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" titanic <- read.csv(titanic) mod_titanic <- glm(     Survived ~ Sex * PClass + Age + I(Age^2),     family = binomial,     data = titanic)  avg_comparisons(mod_titanic) #>  #>    Term      Contrast  Estimate Std. Error       z   Pr(>|z|)     2.5 %    97.5 % #>     Sex male - female -0.484676   0.030607 -15.835 < 2.22e-16 -0.544665 -0.424687 #>  PClass     2nd - 1st -0.205782   0.039374  -5.226 1.7296e-07 -0.282954 -0.128609 #>  PClass     3rd - 1st -0.404283   0.039839 -10.148 < 2.22e-16 -0.482367 -0.326199 #>     Age            +1 -0.006504   0.001072  -6.069 1.2904e-09 -0.008605 -0.004403 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  p1 <- plot_comparisons(     mod_titanic,     effect = \"Age\",     condition = \"Age\",     transform_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(Survival | Age + 1) / P(Survival | Age)\")  p2 <- plot_comparisons(     mod_titanic,     effect = \"Age\",     condition = \"Age\") +     ylab(\"Adjusted Risk Difference\\nP(Survival | Age + 1) - P(Survival | Age)\")  p1 + p2 avg_comparisons(     mod,     transform_pre = function(hi, lo) log(hi / lo),     transform_post = exp) #>  #>  Term Contrast Estimate  Pr(>|z|) 2.5 % 97.5 % #>   mpg       +1    1.274 0.0093462 1.061  1.529 #>  #> Prediction type:  response  #> Pre-transformation:  transform_pre  #> Post-transformation:  transform_post  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high comparisons(     mod,     transform_pre = \"lnratioavg\",     transform_post = exp) #>  #>  Term Contrast Estimate   Pr(>|z|) 2.5 % 97.5 % #>   mpg mean(+1)    1.135 2.3808e-10 1.091   1.18 #>  #> Prediction type:  response  #> Post-transformation:  exp  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo library(ggplot2)  mod2 <- glm(vs ~ mpg + mpg^2, data = mtcars, family = binomial)  plot_comparisons(     mod2,     effect = list(\"mpg\" = 10),     condition = \"mpg\",     transformation_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(vs = 1 | mpg + 10) / P(vs = 1 | mpg)\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"forward-backward-centered-and-custom-differences","dir":"Articles","previous_headings":"","what":"Forward, Backward, Centered, and Custom Differences","title":"Comparisons","text":"default, comparisons() function computes “centered” difference. example, ask comparisons() estimate effect 10-unit change predictor x outcome y, comparisons() compare predicted values x-5 x+5. Since version 0.7.2 marginaleffects, can supply arbitrary functions create custom differences. functions must accept vector values predictor interest, return data frame number rows length, two columns values compare. example, can : Notice last “centered” difference gives results default comparisons() call.","code":"dat <- mtcars dat$new_hp <- 49 * (mtcars$hp - min(mtcars$hp)) / (max(mtcars$hp) - min(mtcars$hp)) + 1 mod <- lm(mpg ~ log(new_hp), data = dat)  avg_comparisons(   mod,   variables = list(new_hp = 10)) #>  #>    Term Contrast Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  new_hp      +10   -4.056      0.464 -8.742 < 2.22e-16 -4.966 -3.147 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high forward_diff <- \\(x) data.frame(x, x + 10) backward_diff <- \\(x) data.frame(x - 10, x) center_diff <- \\(x) data.frame(x - 5, x + 5)  avg_comparisons(   mod,   variables = list(new_hp = forward_diff)) #>  #>    Term Contrast Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  new_hp   custom   -3.799     0.4346 -8.742 < 2.22e-16 -4.651 -2.948 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(   mod,   variables = list(new_hp = backward_diff)) #>  #>    Term Contrast Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  new_hp   custom   -6.507     0.7443 -8.742 < 2.22e-16 -7.966 -5.048 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_comparisons(   mod,   variables = list(new_hp = center_diff)) #>  #>    Term Contrast Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  new_hp   custom   -4.056      0.464 -8.742 < 2.22e-16 -4.966 -3.147 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"lognormal-hurdle-model","dir":"Articles","previous_headings":"","what":"Lognormal hurdle model","title":"Comparisons","text":"hurdle models, can fit two separate models simultaneously: model predicts outcome zero zero outcome zero, model predicts value outcome can calculate predictions marginal effects hurdle model processes, requires variable transformation since stages models use different link functions. hurdle_lognormal() family brms uses logistic regression (logit link) hurdle part model lognormal regression (outcome logged getting used model) non-hurdled part. Let’s look example predicting GDP per capita (distributed exponentially) using life expectancy. ’ll add artificial zeros can work hurdle stage model. two different sets coefficients two different processes. hurdle part (hu) uses logit link, non-hurdle part (mu) uses identity link. However, ’s slight misnomer—true identity link show coefficients non-logged dollar value scale. ’re using lognormal family, GDP per capita pre-logged, “original” identity scale actually logged dollars. can get predictions hu part model link (logit) scale: …response (percentage point) scale: can also get slopes hu part model link (logit) response (percentage point) scales: Working mu part model trickier. Switching type = \"link\" type = \"response\" doesn’t change anything, since outcome pre-logged: predictions, need exponentiate results scale back dollar amounts. can post-processing results (e.g. dplyr::mutate(predicted = exp(predicted))), can use transform_post argument predictions() pass results exp() getting calculated: can pass transform_post = exp plot_predictions() :  marginal effects, need transform predictions calculating instantaneous slopes. also can’t use slopes() function directly—need use comparisons() compute numerical derivative (.e. predict gdpPercap lifeExp 40 40.001 calculate slope predictions). can use transform_pre argument pass pair predicted values exp() calculating slopes: can visually confirm instantaneous slopes levels life expectancy:","code":"library(dplyr) library(ggplot2) library(patchwork) library(brms) library(marginaleffects) library(gapminder)  # Build some 0s into the GDP column set.seed(1234) gapminder <- gapminder::gapminder |>    filter(continent != \"Oceania\") |>    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap0 = ifelse(will_be_zero, 0, gdpPercap)) |>    select(-prob_zero, -will_be_zero)  mod <- brm(   bf(gdpPercap0 ~ lifeExp,      hu ~ lifeExp),   data = gapminder,   family = hurdle_lognormal(),   chains = 4, cores = 4, seed = 1234) summary(mod) #>  Family: hurdle_lognormal  #>   Links: mu = identity; sigma = identity; hu = logit  #> Formula: gdpPercap0 ~ lifeExp  #>          hu ~ lifeExp #>    Data: gapminder (Number of observations: 1680)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Population-Level Effects:  #>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept        3.47      0.09     3.29     3.65 1.00     4757     3378 #> hu_Intercept     3.16      0.40     2.37     3.96 1.00     2773     2679 #> lifeExp          0.08      0.00     0.08     0.08 1.00     5112     3202 #> hu_lifeExp      -0.10      0.01    -0.12    -0.08 1.00     2385     2652 #> ... predictions(mod, dpar = \"hu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>    -0.817 -1.03 -0.604      40 #>    -2.805 -3.06 -2.555      60 #>    -4.790 -5.34 -4.275      80 #>  #> Prediction type:  link  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"hu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate   2.5 % 97.5 % lifeExp #>   0.30630 0.26231 0.3534      40 #>   0.05703 0.04466 0.0721      60 #>   0.00824 0.00478 0.0137      80 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap0, lifeExp slopes(mod, dpar = \"hu\", type = \"link\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>     Term Estimate  2.5 %  97.5 % lifeExp #>  lifeExp  -0.0993 -0.116 -0.0837      40 #>  lifeExp  -0.0993 -0.116 -0.0837      60 #>  lifeExp  -0.0993 -0.116 -0.0837      80 #>  #> Prediction type:  link  #> Columns: rowid, type, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, gdpPercap0, lifeExp, eps  slopes(mod, dpar = \"hu\", type = \"response\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>     Term  Estimate    2.5 %    97.5 % lifeExp #>  lifeExp -0.021078 -0.02591 -0.016588      40 #>  lifeExp -0.005321 -0.00615 -0.004561      60 #>  lifeExp -0.000812 -0.00115 -0.000543      80 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, gdpPercap0, lifeExp, eps predictions(mod, dpar = \"mu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>      6.61  6.54   6.69      40 #>      8.18  8.15   8.22      60 #>      9.75  9.69   9.82      80 #>  #> Prediction type:  link  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"mu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>      6.61  6.54   6.69      40 #>      8.18  8.15   8.22      60 #>      9.75  9.69   9.82      80 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"mu\",              newdata = datagrid(lifeExp = seq(40, 80, 20)),             transform_post = exp) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>       744   694    801      40 #>      3581  3449   3718      60 #>     17215 16110  18410      80 #>  #> Prediction type:  response  #> Post-transformation:  transform_post  #> Columns: rowid, type, estimate, conf.low, conf.high, gdpPercap0, lifeExp plot_predictions(   mod,   dpar = \"hu\",   type = \"link\",   condition = \"lifeExp\") +   labs(y = \"hu\",        title = \"Hurdle part (hu)\",        subtitle = \"Logit-scale predictions\") + plot_predictions(   mod,   dpar = \"hu\",   type = \"response\",   condition = \"lifeExp\") +   labs(y = \"hu\",        subtitle = \"Percentage point-scale predictions\") + plot_predictions(   mod,   dpar = \"mu\",   condition = \"lifeExp\") +   labs(y = \"mu\",        title = \"Non-hurdle part (mu)\",        subtitle = \"Log-scale predictions\") + plot_predictions(   mod,   dpar = \"mu\",   transform_post = exp,   condition = \"lifeExp\") +   labs(y = \"mu\",        subtitle = \"Dollar-scale predictions\") # step size of the numerical derivative eps <- 0.001  comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   # rescale the elements of the slope   # (exp(40.001) - exp(40)) / exp(0.001)   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps ) #>  #>     Term Contrast Estimate  2.5 % 97.5 % lifeExp #>  lifeExp   +0.001     58.4   55.8     61      40 #>  lifeExp   +0.001    280.9  266.6    296      60 #>  lifeExp   +0.001   1349.4 1222.6   1490      80 #>  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) ((exp(hi) - exp(lo))/exp(eps))/eps  #> Columns: rowid, type, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, gdpPercap0, lifeExp, eps predictions_data <- predictions(   mod,   newdata = datagrid(lifeExp = seq(30, 80, 1)),   dpar = \"mu\",   transform_post = exp) |>   select(lifeExp, prediction = estimate)  slopes_data <- comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps) |>   select(lifeExp, estimate) |>   left_join(predictions_data, by = \"lifeExp\") |>   # Point-slope formula: (y - y1) = m(x - x1)   mutate(intercept = estimate * (-lifeExp) + prediction)  ggplot(predictions_data, aes(x = lifeExp, y = prediction)) +   geom_line(size = 1) +    geom_abline(data = slopes_data, aes(slope = estimate, intercept = intercept),                size = 0.5, color = \"red\") +   geom_point(data = slopes_data) +   geom_label(data = slopes_data, aes(label = paste0(\"Slope: \", round(estimate, 1))),              nudge_x = -1, hjust = 1) +   theme_minimal()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"regression-adjustment-in-experiments","dir":"Articles","previous_headings":"","what":"Regression adjustment in experiments","title":"Experiments","text":"Many analysts conduct analyze experiments wish use regression adjustment linear regression model improve precision estimate treatment effect. Unfortunately, regression adjustment can introduce small-sample bias undesirable properties (Freedman 2008). Lin (2013) proposes simple strategy fix problems sufficiently large samples: Center predictors subtracting means. Estimate linear model treatment interacted covariates. estimatr package includes convenient function implement strategy: can obtain results fitting model standard lm function using comparisons() function: Notice treat coefficient associate standard error lm_lin regression exactly estimates produced comparisons() function.","code":"library(estimatr) library(marginaleffects) lalonde <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\")  mod <- lm_lin(     re78 ~ treat,     covariates = ~ age + educ + race,     data = lalonde,     se_type = \"HC3\") summary(mod) #>  #> Call: #> lm_lin(formula = re78 ~ treat, covariates = ~age + educ + race,  #>     data = lalonde, se_type = \"HC3\") #>  #> Standard error type:  HC3  #>  #> Coefficients: #>                    Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF #> (Intercept)         6488.05     356.71 18.1885 2.809e-59  5787.50   7188.6 604 #> treat                489.73     878.52  0.5574 5.774e-01 -1235.59   2215.0 604 #> age_c                 85.88      35.42  2.4248 1.561e-02    16.32    155.4 604 #> educ_c               464.04     131.51  3.5286 4.495e-04   205.77    722.3 604 #> racehispan_c        2775.47    1155.40  2.4022 1.660e-02   506.38   5044.6 604 #> racewhite_c         2291.67     793.30  2.8888 4.006e-03   733.71   3849.6 604 #> treat:age_c           17.23      76.37  0.2256 8.216e-01  -132.75    167.2 604 #> treat:educ_c         226.71     308.43  0.7350 4.626e-01  -379.02    832.4 604 #> treat:racehispan_c -1057.84    2652.42 -0.3988 6.902e-01 -6266.92   4151.2 604 #> treat:racewhite_c  -1205.68    1805.21 -0.6679 5.045e-01 -4750.92   2339.6 604 #>  #> Multiple R-squared:  0.05722 ,   Adjusted R-squared:  0.04317  #> F-statistic: 4.238 on 9 and 604 DF,  p-value: 2.424e-05 mod <- lm(re78 ~ treat * (age + educ + race), data = lalonde) avg_comparisons(     mod,     variables = \"treat\",     vcov = \"HC3\") #>  #>   Term Contrast Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 % #>  treat    1 - 0    489.7      878.5 0.5574  0.57722 -1232   2212 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"references","dir":"Articles","previous_headings":"Regression adjustment in experiments","what":"References","title":"Experiments","text":"Freedman, David . “Regression Adjustments Experimental Data.” Advances Applied Mathematics 40, . 2 (February 2008): 180–93. Lin, Winston. “Agnostic Notes Regression Adjustments Experimental Data: Reexamining Freedman’s Critique.” Annals Applied Statistics 7, . 1 (March 2013): 295–318. https://doi.org/10.1214/12-AOAS583.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"support-a-new-model-type","dir":"Articles","previous_headings":"","what":"Support a new model type","title":"Extending or Modifying marginaleffects","text":"easy add support new models marginaleffects. need set global option define 4 simple functions. add support class models produced CRAN package, please consider submitting code inclusion package: https://github.com/vincentarelbundock/marginaleffects add support class models produced package hosted elsewhere CRAN, can submit inclusion unsupported user-submitted library extensions: Currently countreg package. Thanks Olivier Beaumais. rest section illustrates add support simple lm_manual model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"fit-function","dir":"Articles","previous_headings":"Support a new model type","what":"Fit function","title":"Extending or Modifying marginaleffects","text":"begin, define function fits model. Normally, function supplied modeling package published CRAN. , create function called lm_manual(), estimates linear regression model using simple linear algebra operates: Important: custom fit function must assign new class name object returns. example , model assigned class lm_manual (see penultimate line code function). new function replicates results lm():","code":"lm_manual <- function(f, data, ...) {     # design matrix     X <- model.matrix(f, data = data)     # response matrix     Y <- data[[as.character(f[2])]]     # coefficients     b <- solve(crossprod(X)) %*% crossprod(X, Y)     Yhat <- X %*% b     # variance-covariance matrix     e <- Y - Yhat     df <- nrow(X) - ncol(X)     s2 <- sum(e^2) / df     V <- s2 * solve(crossprod(X))     # model object     out <- list(         d = data,         f = f,         X = X,         Y = Y,         V = V,         b = b)     # class name: lm_manual     class(out) <- c(\"lm_manual\", \"list\")     return(out) } model <- lm_manual(mpg ~ hp + drat, data = mtcars) model$b #>                    [,1] #> (Intercept) 10.78986122 #> hp          -0.05178665 #> drat         4.69815776  model_lm <- lm(mpg ~ hp + drat, data = mtcars) coef(model_lm) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"marginaleffects-extension","dir":"Articles","previous_headings":"Support a new model type","what":"marginaleffects extension","title":"Extending or Modifying marginaleffects","text":"extend support marginaleffects, first step tell package new class supported. defining global option: , define 4 methods: Mandatory arguments: model, ... Returns: named vector parameters (coefficients). Mandatory arguments: model, coefs (named vector coefficients), ... Returns: new model object original coefficients replaced new vector. Example Mandatory arguments: model, .... Optional arguments: vcov Returns: named square variance-covariance matrix. Mandatory arguments: model, newdata (data frame), ... Option arguments: type model-specific arguments. Returns: data frame two columns: unique rowid column estimate values. Note methods named suffix .lm_manual indicate used whenever marginaleffects needs process object class lm_manual. methods just defined work expected: Now can use avg_slopes function: Note , custom model, typically supply values newdata variables arguments explicitly.","code":"library(marginaleffects)  options(\"marginaleffects_model_classes\" = \"lm_manual\") get_coef.lm_manual <- function(model, ...) {     b <- model$b     b <- setNames(as.vector(b), row.names(b))     return(b) }  set_coef.lm_manual <- function(model, coefs, ...) {     out <- model     out$b <- coefs     return(out) }  get_vcov.lm_manual <- function(model, ...) {     return(model$V) }  get_predict.lm_manual <- function(model, newdata, ...) {     newX <- model.matrix(model$f, data = newdata)     Yhat <- newX %*% model$b     out <- data.frame(         rowid = seq_len(nrow(Yhat)),         estimate = as.vector(Yhat))     return(out) } get_coef(model) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776  get_vcov(model) #>             (Intercept)            hp         drat #> (Intercept) 25.78356135 -3.054007e-02 -5.836030687 #> hp          -0.03054007  8.635615e-05  0.004969385 #> drat        -5.83603069  4.969385e-03  1.419990359  get_predict(model, newdata = head(mtcars)) #>   rowid estimate #> 1     1 23.41614 #> 2     2 23.41614 #> 3     3 24.06161 #> 4     4 19.56366 #> 5     5 16.52639 #> 6     6 18.31918 avg_slopes(model, newdata = mtcars, variables = c(\"hp\", \"drat\")) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)  2.5 %   97.5 % #>    hp -0.05179   0.009293 -5.573 2.5090e-08 -0.070 -0.03357 #>  drat  4.69816   1.191633  3.943 8.0596e-05  2.363  7.03372 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  predictions(model, newdata = mtcars) |>     head() #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     23.42     0.6711 34.89 < 2.22e-16 22.10  24.73 #>     23.42     0.6711 34.89 < 2.22e-16 22.10  24.73 #>     24.06     0.7204 33.40 < 2.22e-16 22.65  25.47 #>     19.56     0.9988 19.59 < 2.22e-16 17.61  21.52 #>     16.53     0.7354 22.47 < 2.22e-16 15.09  17.97 #>     18.32     1.3433 13.64 < 2.22e-16 15.69  20.95 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"modify-or-extend-supported-models","dir":"Articles","previous_headings":"","what":"Modify or extend supported models","title":"Extending or Modifying marginaleffects","text":"Let’s say want estimate model using mclogit::mblogit function. package already supported marginaleffects, want use type (scale) predictions currently supported: “centered link scale.” achieve , need override get_predict.mblogit() method. However, can unsafe reassign methods supplied package loaded library. safe, assign new model class object (“customclass”) inherit mblogit. , define get_predict.customclass method make new kinds preditions. Load libraries, estimate model: Tell marginaleffects adding support new class model models, assign new inherited class name duplicate model object: Define new get_predict.customclass method. use default predict() function obtain predictions. Since multinomial model, predict() returns matrix predictions one column per level response variable. new get_predict.customclass method takes matrix predictions, modifies , reshapes return data frame three columns: rowid, group, estimate: Finally, can call slopes function obtain results. Notice object class customclass now produces different results default mblogit object:","code":"library(mclogit) library(data.table)  model <- mblogit(     factor(gear) ~ am + mpg,     data = mtcars,     trace = FALSE) options(\"marginaleffects_model_classes\" = \"customclass\")  model_custom <- model  class(model_custom) <- c(\"customclass\", class(model)) get_predict.customclass <- function(model, newdata, ...) {     out <- predict(model, newdata = newdata, type = \"link\")     out <- cbind(0, out)     colnames(out)[1] <- dimnames(model$D)[[1]][[1]]     out <- out - rowMeans(out)     out <- as.data.frame(out)     out$rowid <- seq_len(nrow(out))     out <- data.table(out)     out <- melt(         out,         id.vars = \"rowid\",         value.name = \"estimate\",         variable.name = \"group\") } avg_predictions(model) #>  #>  Group Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 % #>      3   0.4688    0.04440 10.558 < 2.22e-16 0.38173 0.5558 #>      4   0.3750    0.06764  5.544 2.9505e-08 0.24244 0.5076 #>      5   0.1563    0.05103  3.062  0.0021976 0.05624 0.2563 #>  #> Prediction type:  response  #> Columns: type, group, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_predictions(model_custom) #>  #>  Group Estimate Std. Error          z Pr(>|z|) 2.5 % 97.5 % #>      3   -1.418       2525 -0.0005614  0.99955 -4950   4947 #>      4    6.365       1779  0.0035776  0.99715 -3480   3493 #>      5   -4.947       3074 -0.0016094  0.99872 -6030   6020 #>  #> Prediction type:  response  #> Columns: type, group, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/faq.html","id":"stack-overflow-questions","dir":"Articles","previous_headings":"","what":"Stack Overflow questions","title":"FAQ","text":"plot_predictions() range unobserved values Plot marginal effects plm package model Models demeaned, polynomials, transformed variables","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/faq.html","id":"calling-marginaleffects-in-functions-loops-environments-or-after-re-assigning-variables","dir":"Articles","previous_headings":"","what":"Calling marginaleffects in functions, loops, environments, or after re-assigning variables","title":"FAQ","text":"Functions marginaleffects package can sometimes fail called inside function, loop, environments. see , important know marginaleffects often needs operate original data used fit model. extract original data, use get_data() function insight package. cases, get_data() can extract data stored inside model object created modeling package. However, modeling packages save original data model object (order save memory). cases, get_data() parse call find name data object, search data object global environment. users fit models different environment (e.g., function calls), get_data() may able retrieve original data. related problem can arise users fit model, assign new value variable used store dataset. Recommendations: Supply dataset explicitly newdata argument slopes functions. Avoid assigning new value variable use store dataset model fitting.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"estimate-a-gam-model","dir":"Articles","previous_headings":"","what":"Estimate a GAM model","title":"Generalized Additive Models","text":"estimate GAM model using mgcv package simdat dataset distributed itsadug package: Fit model random effect group-time smooths:","code":"library(marginaleffects) library(itsadug) library(mgcv)  simdat$Subject <- as.factor(simdat$Subject)  dim(simdat) #> [1] 75600     6 head(simdat) #>    Group      Time Trial Condition Subject         Y #> 1 Adults   0.00000   -10        -1     a01 0.7554469 #> 2 Adults  20.20202   -10        -1     a01 2.7834759 #> 3 Adults  40.40404   -10        -1     a01 1.9696963 #> 4 Adults  60.60606   -10        -1     a01 0.6814298 #> 5 Adults  80.80808   -10        -1     a01 1.6939195 #> 6 Adults 101.01010   -10        -1     a01 2.3651969 model <- bam(Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\"),              data = simdat)  summary(model) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\") #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)    #> (Intercept)   2.0574     0.6903   2.980  0.00288 ** #> GroupAdults   3.1265     0.9763   3.202  0.00136 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>                         edf Ref.df    F p-value     #> s(Time):GroupChildren  8.26  8.850 3649  <2e-16 *** #> s(Time):GroupAdults    8.66  8.966 6730  <2e-16 *** #> s(Subject)            33.94 34.000  569  <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.609   Deviance explained =   61% #> fREML = 2.3795e+05  Scale est. = 31.601    n = 75600"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"adjusted-predictions-predictions-and-plot_predictions","dir":"Articles","previous_headings":"","what":"Adjusted Predictions: predictions() and plot_predictions()","title":"Generalized Additive Models","text":"Compute adjusted predictions observed combination regressor dataset used fit model. gives us dataset number rows original data, new columns predicted values uncertainty estimates: can easily plot adjusted predictions different values regressor using plot_predictions() function:","code":"pred <- predictions(model) dim(pred) #> [1] 75600    12 head(pred) #>  #>  Estimate Std. Error      z   Pr(>|z|)    2.5 %   97.5 % #>   -1.8739     0.1992 -9.406 < 2.22e-16 -2.26432 -1.48339 #>   -1.3463     0.1817 -7.407 1.2879e-13 -1.70252 -0.99006 #>   -0.8191     0.1671 -4.901 9.5203e-07 -1.14669 -0.49156 #>   -0.2930     0.1561 -1.877   0.060455 -0.59884  0.01288 #>    0.2313     0.1489  1.553   0.120383 -0.06058  0.52316 #>    0.7527     0.1455  5.172 2.3113e-07  0.46745  1.03787 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, Y, Group, Time, Subject plot_predictions(model, condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"marginal-effects-slopes-and-plot_slopes","dir":"Articles","previous_headings":"","what":"Marginal Effects: slopes() and plot_slopes()","title":"Generalized Additive Models","text":"Marginal effects slopes prediction equation. observation-level quantity. slopes() function produces dataset number rows original data, new columns slop uncertainty estimates: can plot marginal effects different values regressor using plot_slopes() function. next plot shows slope prediction equation, , slope previous plot, every value Time variable.  marginal effects plot can interpreted measuring change Y associated small increase Time, different baseline values Time.","code":"mfx <- slopes(model, variables = \"Time\") head(mfx) #>  #>  Term Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>  Time  0.02612   0.001367 19.10 < 2.22e-16 0.02344 0.02880 #>  Time  0.02611   0.001360 19.19 < 2.22e-16 0.02344 0.02877 #>  Time  0.02608   0.001334 19.54 < 2.22e-16 0.02346 0.02869 #>  Time  0.02601   0.001282 20.28 < 2.22e-16 0.02349 0.02852 #>  Time  0.02589   0.001201 21.55 < 2.22e-16 0.02353 0.02824 #>  Time  0.02572   0.001092 23.54 < 2.22e-16 0.02358 0.02786 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Y, Group, Time, Subject, eps plot_slopes(model, effect = \"Time\", condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"excluding-terms","dir":"Articles","previous_headings":"","what":"Excluding terms","title":"Generalized Additive Models","text":"predict() method mgcv package allows users “exclude” smoothing terms, using exclude argument. can pass argument function marginaleffects package: See documentation ?mgcv:::predict.bam details.","code":"predictions(model, newdata = \"mean\", exclude = \"s(Subject)\") #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     11.75     0.6947 16.91 < 2.22e-16 10.39  13.11 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, Y, Group, Time, Subject"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"what-is-the-parametric-g-formula","dir":"Articles","previous_headings":"","what":"What is the parametric g-formula?","title":"Causal Inference with the Parametric g-Formula","text":"parametric g-formula method standardization can used address confounding problems causal inference observational data. relies identification assumptions Inverse Probability Weighting (IPW), uses different modeling assumptions. Whereas IPW models treatment equation, standardization models mean outcome equation. Hernán Robins note: “IP weighting standardization estimators g-formula, general method causal inference first described 1986. … say standardization ”plug-g-formula estimator” simply replaces conditional mean outcome g-formula estimates. , like Chapter 13, estimates come parametric models, refer method parametric g-formula.”","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"how-does-it-work","dir":"Articles","previous_headings":"","what":"How does it work?","title":"Causal Inference with the Parametric g-Formula","text":"Imagine causal model like :  want estimate effect binary treatment \\(X\\) outcome \\(Y\\), confounding variable \\(W\\). can use standardization parametric g-formula handle . Roughly speaking, procedure follows: Use observed data fit regression model \\(Y\\) outcome, \\(X\\) treatment, \\(W\\) control variable (perhaps polynomials /interactions multiple control variables). Create new dataset exactly identical original data, \\(X=1\\) every row. Create new dataset exactly identical original data, \\(X=0\\) every row. Use model Step 1 compute adjusted predictions two counterfactual datasets Steps 2 3. quantity interest difference means adjusted predictions two counterfactual datasets. equivalent computing “Average Contrast”, value \\(X\\) moves 0 1. Thanks equivalence, can apply parametric g-formula method using single line code marginaleffects, obtain delta method standard errors automatically.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"example-with-real-world-data","dir":"Articles","previous_headings":"","what":"Example with real-world data","title":"Causal Inference with the Parametric g-Formula","text":"Let’s illustrate method replicating example Chapter 13 Hernán Robins. data come National Health Nutrition Examination Survey Data Epidemiologic Follow-Study (NHEFS). outcome wt82_71, measure weight gain. treatment qsmk, binary measure smoking cessation. many confounders. Step 1 fit regression model outcome treatment control variables: Steps 2 3 require us replicate full dataset setting qsmk treatment counterfactual values. can automatically calling comparisons().","code":"library(boot) library(marginaleffects)  f <- wt82_71 ~ qsmk + sex + race + age + I(age * age) + factor(education) +      smokeintensity + I(smokeintensity * smokeintensity) + smokeyrs +      I(smokeyrs * smokeyrs) + factor(exercise) + factor(active) + wt71 +      I(wt71 * wt71) + I(qsmk * smokeintensity)  url <- \"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\" nhefs <- read.csv(url) nhefs <- na.omit(nhefs[, all.vars(f)])  fit <- glm(f, data = nhefs)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"tldr","dir":"Articles","previous_headings":"Example with real-world data","what":"TLDR","title":"Causal Inference with the Parametric g-Formula","text":"simple commands everything need apply parametric g-formula: rest vignette walks process bit detail compares replication code Hernán Robins.","code":"avg_comparisons(fit, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##  qsmk    1 - 0    3.517     0.4403 7.989 1.3613e-15 2.654   4.38 ##  ## Prediction type:  response  ## Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Example with real-world data","what":"Adjusted Predictions","title":"Causal Inference with the Parametric g-Formula","text":"can compute average predictions original data, average predictions two counterfactual datasets like : R code accompanies book, Hernán Robins compute quantities manually, follows: may useful note datagrid() function provided marginaleffects can create counterfactual datasets automatically. equivalent onesample dataset:","code":"# average predicted outcome in the original data p <- predictions(fit) mean(p$estimate) ## [1] 2.6383 # average predicted outcome in the two counterfactual datasets p <- predictions(fit, newdata = datagrid(qsmk = 0:1, grid_type = \"counterfactual\")) aggregate(estimate ~ qsmk, data = p, FUN = mean) ##   qsmk estimate ## 1    0 1.756213 ## 2    1 5.273587 # create a dataset with 3 copies of each subject nhefs$interv <- -1 # 1st copy: equal to original one  interv0 <- nhefs # 2nd copy: treatment set to 0, outcome to missing interv0$interv <- 0 interv0$qsmk <- 0 interv0$wt82_71 <- NA  interv1 <- nhefs # 3rd copy: treatment set to 1, outcome to missing interv1$interv <- 1 interv1$qsmk <- 1 interv1$wt82_71 <- NA  onesample <- rbind(nhefs, interv0, interv1) # combining datasets  # linear model to estimate mean outcome conditional on treatment and confounders # parameters are estimated using original observations only (nhefs) # parameter estimates are used to predict mean outcome for observations with  # treatment set to 0 (interv=0) and to 1 (interv=1)  std <- glm(f, data = onesample) onesample$predicted_meanY <- predict(std, onesample)  # estimate mean outcome in each of the groups interv=0, and interv=1 # this mean outcome is a weighted average of the mean outcomes in each combination  # of values of treatment and confounders, that is, the standardized outcome mean(onesample[which(onesample$interv == -1), ]$predicted_meanY) ## [1] 2.6383 mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 1.756213 mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) ## [1] 5.273587 nd <- datagrid(     model = fit,     qsmk = c(0, 1),     grid_type = \"counterfactual\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"contrast","dir":"Articles","previous_headings":"Example with real-world data","what":"Contrast","title":"Causal Inference with the Parametric g-Formula","text":"Now want compute treatment effect parametric g-formula, difference average predicted outcomes two counterfactual datasets. equivalent taking average contrast comparisons() function. three important things note command follows: variables argument used indicate want estimate “contrast” adjusted predictions qsmk equal 1 0. comparisons() automatically produces estimates uncertainty. hood, comparisons() exactly described g-formula steps : can obtain result manually computing quantities, using replication code Hernán Robins: Although manual computation simple, provide uncertainty estimates. contrast, comparisons() already computed standard error confidence interval using delta method. Instead delta method, analysts rely bootstrapping. example, replication code Hernán Robins : results close obtained comparisons(), confidence interval differs slightly difference bootstrapping delta method.","code":"avg_comparisons(std, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##  qsmk    1 - 0    3.517     0.4403 7.989 1.3613e-15 2.654   4.38 ##  ## Prediction type:  response  ## Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) - mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 3.517374 # function to calculate difference in means standardization <- function(data, indices) {     # create a dataset with 3 copies of each subject     d <- data[indices, ] # 1st copy: equal to original one`     d$interv <- -1     d0 <- d # 2nd copy: treatment set to 0, outcome to missing     d0$interv <- 0     d0$qsmk <- 0     d0$wt82_71 <- NA     d1 <- d # 3rd copy: treatment set to 1, outcome to missing     d1$interv <- 1     d1$qsmk <- 1     d1$wt82_71 <- NA     d.onesample <- rbind(d, d0, d1) # combining datasets      # linear model to estimate mean outcome conditional on treatment and confounders     # parameters are estimated using original observations only (interv= -1)     # parameter estimates are used to predict mean outcome for observations with set     # treatment (interv=0 and interv=1)     fit <- glm(f, data = d.onesample)      d.onesample$predicted_meanY <- predict(fit, d.onesample)      # estimate mean outcome in each of the groups interv=-1, interv=0, and interv=1     return(mean(d.onesample$predicted_meanY[d.onesample$interv == 1]) -            mean(d.onesample$predicted_meanY[d.onesample$interv == 0])) }  # bootstrap results <- boot(data = nhefs, statistic = standardization, R = 1000)  # generating confidence intervals se <- sd(results$t[, 1]) meant0 <- results$t0 ll <- meant0 - qnorm(0.975) * se ul <- meant0 + qnorm(0.975) * se  bootstrap <- data.frame(     \" \" = \"Treatment - No Treatment\",     estimate = meant0,     std.error = se,     conf.low = ll,     conf.high = ul,     check.names = FALSE) bootstrap ##                            estimate std.error conf.low conf.high ## 1 Treatment - No Treatment 3.517374 0.4720851 2.592104  4.442644 avg_comparisons(fit, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##  qsmk    1 - 0    3.517     0.4403 7.989 1.3613e-15 2.654   4.38 ##  ## Prediction type:  response  ## Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"null-hypothesis","dir":"Articles","previous_headings":"","what":"Null hypothesis","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"simplest way modify hypothesis test change null hypothesis. default, functions marginaleffects package assume null 0. can changed changing hypothesis argument. example, consider logistic regression model: can compute predicted outcome hypothetical unit regressors fixed sample means: Z statistic p value reported assume null hypothesis equals zero. can change null hypothesis argument: can obviously useful contexts. instance, compute risk ratios (mean) associated increase 1 unit hp, makes sense test null hypothesis ratio predictions 1 rather 0: Warning: Z statistics p values computed applying functions transform_post.","code":"library(marginaleffects) mod <- glm(am ~ hp + drat, data = mtcars, family = binomial) predictions(mod, newdata = \"mean\") #>  #>  Estimate Std. Error     z Pr(>|z|)   2.5 % 97.5 % #>     0.231     0.1429 1.616  0.10606 0.05842 0.5925 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, am, hp, drat predictions(mod, newdata = \"mean\", hypothesis = .5) #>  #>  Estimate Std. Error      z Pr(>|z|)   2.5 % 97.5 % #>     0.231     0.1429 -1.883 0.059766 0.05842 0.5925 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, am, hp, drat comparisons(     mod,     newdata = \"mean\",     variables = \"hp\",     transform_pre = \"ratio\",     hypothesis = 1) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)  2.5 % 97.5 % #>    hp       +1    1.008   0.007891 1.056  0.29085 0.9929  1.024 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, drat, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypothesis-tests-with-the-delta-method","dir":"Articles","previous_headings":"","what":"Hypothesis tests with the delta method","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Version 0.6.0 marginaleffects includes powerful function called hypotheses(). function emulates behavior well-established car::deltaMethod car::linearHypothesis functions, supports models, requires fewer dependencies, offers convenience features like shortcuts robust standard errors. hypotheses() can used compute estimates standard errors arbitrary functions model parameters. example, can used conduct tests equality coefficients, test value linear non-linear combination quantities interest. hypotheses() can also used conduct hypothesis tests functions model’s parameter, adjusted predictions marginal effects. Let’s start estimating simple model: FUN hypothesis arguments hypotheses() equal NULL (default), function returns data.frame raw estimates: Test equality coefficients: Non-linear function coefficients vcov argument behaves slopes() function. allows us easily compute robust standard errors: can use shortcuts like b1, b2, ... identify position parameter output FUN. example, b2=b3 equivalent hp=wt term names appear 2nd 3rd row call hypotheses(mod). Term names special characters must enclosed backticks: FUN argument can used compute standard errors arbitrary functions model parameters. user-supplied function must accept single model object, return numeric vector data.frame two columns named term estimate. Test equality two predictions (row 2 vs row 3): Note specified newdata argument f function. predict() method associated lm objects automatically original fitted values newdata NULL, instead returning slightly altered fitted values need compute numerical derivatives delta method. can also use numeric vectors specify linear combinations parameters. example, 3 coefficients last model estimated. test null hypothesis sum 2nd 3rd coefficients equal 0, can : See example use string formulas, numeric vectors, matrices calculate custom contrasts, linear combinations, linear non-linear hypothesis tests.","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars) hypotheses(mod) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)    2.5 %     97.5 % #>    b1 35.84600    2.04102 17.563 < 2.22e-16 31.84567 39.8463192 #>    b2 -0.02312    0.01195 -1.934   0.053069 -0.04655  0.0003061 #>    b3 -3.18140    0.71960 -4.421 9.8215e-06 -4.59180 -1.7710120 #>    b4 -3.35902    1.40167 -2.396   0.016555 -6.10625 -0.6118027 #>    b5 -3.18588    2.17048 -1.468   0.142151 -7.43994  1.0681690 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"hp = wt\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  hp = wt    3.158     0.7199 4.387 1.1489e-05 1.747  4.569 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"exp(hp + wt) = 0.1\") #>  #>                Term Estimate Std. Error      z Pr(>|z|)   2.5 %    97.5 % #>  exp(hp + wt) = 0.1 -0.05942     0.0292 -2.035 0.041832 -0.1166 -0.002196 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"hp = wt\", vcov = \"HC3\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  hp = wt    3.158     0.8052 3.922 8.7673e-05  1.58  4.736 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"b2 = b3\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  b2 = b3    3.158     0.7199 4.387 1.1489e-05 1.747  4.569 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"`factor(cyl)6` = `factor(cyl)8`\") #>  #>                             Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  `factor(cyl)6` = `factor(cyl)8`  -0.1731      1.654 -0.1047  0.91663 -3.415  3.068 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error       z Pr(>|z|)  2.5 %  97.5 % #>    b1  -1.0984     0.7160 -1.5339 0.125046 -2.502  0.3051 #>    b2  -1.0984     0.7160 -1.5339 0.125046 -2.502  0.3051 #>    b3   0.2332     0.7808  0.2986 0.765211 -1.297  1.7636 #>    b4  -0.5945     0.6471 -0.9187 0.358234 -1.863  0.6738 #>    b5  -0.4176     0.6475 -0.6449 0.518965 -1.687  0.8514 #>    b6  -5.0265     2.1949 -2.2901 0.022018 -9.328 -0.7245 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high f <- function(x) predict(x, newdata = mtcars) hypotheses(mod, FUN = f, hypothesis = \"b2 = b3\") #>  #>     Term Estimate Std. Error      z Pr(>|z|)  2.5 %  97.5 % #>  b2 = b3   -1.332     0.6156 -2.163 0.030527 -2.538 -0.1251 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, hypothesis = c(0, 1, 1)) #>  #>    Term Estimate Std. Error     z Pr(>|z|) 2.5 % 97.5 % #>  custom    1.315     0.5927 2.218 0.026551 0.153  2.476 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypotheses-formulas","dir":"Articles","previous_headings":"","what":"hypotheses Formulas","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"4 core functions package support hypothesis argument behaves similarly hypotheses() function. argument allows users specify custom hypothesis tests contrasts, order test null hypotheses : coefficients \\(\\beta_1\\) \\(\\beta_2\\) equal. marginal effects \\(X_1\\) \\(X_2\\) equal. marginal effect \\(X\\) \\(W=0\\) equal marginal effect \\(X\\) \\(W=1\\). non-linear function adjusted predictions equal 100. marginal mean control group equal average marginal means 3 treatment arms. Cross-level contrasts: multinomial model, effect \\(X\\) 1st outcome level equal effect \\(X\\) 2nd outcome level.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"marginal-effects","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Marginal effects","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"example, let’s fit model compute marginal effects mean: marginal effect different marginal effect vs? answer question can run linear hypothesis test using hypotheses function: Alternatively, can specify hypothesis directly original call: hypotheses string can include valid R expression, can run silly non-linear tests:","code":"library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  mfx <- slopes(mod, newdata = \"mean\") mfx #>  #>  Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>    am    6.067      1.275 4.759 1.9479e-06 3.568  8.565 #>    vs    6.929      1.262 5.490 4.0146e-08 4.456  9.403 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, am, vs, eps hypotheses(mfx, hypothesis = \"am = vs\") #>  #>   Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  am=vs  -0.8627      1.939 -0.4449  0.65639 -4.663  2.938 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  slopes(     mod,     newdata = \"mean\",     hypothesis = \"am = vs\") #>  #>   Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  am=vs  -0.8627      1.939 -0.4449  0.65639 -4.663  2.938 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high slopes(     mod,     newdata = \"mean\",     hypothesis = \"exp(am) - 2 * vs = -400\") #>  #>               Term Estimate Std. Error     z Pr(>|z|) 2.5 % 97.5 % #>  exp(am)-2*vs=-400    817.4      550.2 1.486   0.1374  -261   1896 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Adjusted Predictions","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now consider case adjusted predictions: Since term column output predictions function, must use parameter identifiers like b1, b2, etc. determine estimates want compare: directly: next section, see can get equivalent results using vector contrast weights, used compute linear combination estimates: many possibilities:","code":"p <- predictions(     mod,     newdata = datagrid(am = 0:1, vs = 0:1)) p #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % am vs #>     14.59     0.9262 15.76 < 2.22e-16 12.78  16.41  0  0 #>     21.52     1.1300 19.05 < 2.22e-16 19.31  23.74  0  1 #>     20.66     1.1830 17.46 < 2.22e-16 18.34  22.98  1  0 #>     27.59     1.1300 24.42 < 2.22e-16 25.38  29.81  1  1 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, am, vs hypotheses(p, hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>  b1=b2   -6.929      1.262 -5.49 4.0146e-08 -9.403 -4.456 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high predictions(     mod,     hypothesis = \"b1 = b2\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>   Term Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>  b1=b2   -6.929      1.262 -5.49 4.0146e-08 -9.403 -4.456 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  p$estimate[1] - p$estimate[2] #> [1] -6.929365 predictions(     mod,     hypothesis = c(1, -1, 0, 0),     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>    Term Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>  custom   -6.929      1.262 -5.49 4.0146e-08 -9.403 -4.456 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high predictions(     mod,     hypothesis = \"b1 + b2 = 30\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>      Term Estimate Std. Error    z   Pr(>|z|) 2.5 % 97.5 % #>  b1+b2=30    6.118      1.636 3.74 0.00018417 2.912  9.325 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  p$estimate[1] + p$estimate[2] - 30 #> [1] 6.118254  predictions(     mod,     hypothesis = \"(b2 - b1) / (b3 - b2) = 0\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>               Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  (b2-b1)/(b3-b2)=0   -8.032      16.97 -0.4734  0.63591 -41.29  25.22 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"average-contrasts-or-marginal-effects","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Average contrasts or marginal effects","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"standard workflow marginaleffects package call function like predictions(), slopes() comparisons() compute unit-level quantities; one cousins avg_predictions(), avg_comparisons(), avg_slopes() aggregate unit-level quantities “Average Marginal Effects” “Average Contrasts.” can also use transform_pre argument emulate behavior avg_*() functions. First, note three commands produce results: See transformations section Contrasts vignette details. results hand, can now conduct linear hypothesis test average marginal effects: Computing contrasts average marginal effects requires little care obtain right scale. particular, need specify variables transform_pre:","code":"comparisons(mod, variables = \"vs\")$estimate |> mean() #> [1] 6.929365  avg_comparisons(mod, variables = \"vs\") #>  #>  Term Contrast Estimate Std. Error    z   Pr(>|z|) 2.5 % 97.5 % #>    vs    1 - 0    6.929      1.262 5.49 4.0146e-08 4.456  9.403 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  comparisons(     mod,     variables = \"vs\",     transform_pre = \"differenceavg\") #>  #>  Term          Contrast Estimate Std. Error    z   Pr(>|z|) 2.5 % 97.5 % #>    vs mean(1) - mean(0)    6.929      1.262 5.49 4.0146e-08 4.456  9.403 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo comparisons(     mod,     hypothesis = \"am = vs\",     transform_pre = \"differenceavg\") #>  #>   Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  am=vs  -0.8627      1.939 -0.4449  0.65639 -4.663  2.938 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high comparisons(     mod,     hypothesis = \"am = vs\",     variables = c(\"am\", \"vs\"),     transform_pre = \"dydxavg\") #>  #>   Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>  am=vs  -0.8627      1.939 -0.4449  0.65639 -4.663  2.938 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypotheses-vectors-and-matrices","dir":"Articles","previous_headings":"","what":"hypotheses Vectors and Matrices","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"marginal_means() function computes estimated marginal means. hypothesis argument function offers powerful mechanism estimate custom contrasts marginal means, way linear combination. Consider simple example: contrast marginal means carb==1 carb==2 : last two commands express contrast interest linear combination marginal means.","code":"library(marginaleffects) library(emmeans) library(nnet)  dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am)  mod <- lm(mpg ~ carb + cyl, dat) mm <- marginal_means(mod, variables = \"carb\") mm #>  #>  Term Value  Mean Std. Error      z   Pr(>|z|) 2.5 % 97.5 % #>  carb     1 21.66      1.438 15.060 < 2.22e-16 18.84  24.48 #>  carb     2 21.34      1.235 17.285 < 2.22e-16 18.92  23.76 #>  carb     3 21.42      2.192  9.772 < 2.22e-16 17.12  25.71 #>  carb     4 18.88      1.211 15.595 < 2.22e-16 16.51  21.26 #>  carb     6 19.76      3.551  5.564 2.6299e-08 12.80  26.72 #>  carb     8 20.12      3.510  5.731 9.9847e-09 13.24  27.00 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, cyl  #> Columns: type, term, value, carb, estimate, std.error, statistic, p.value, conf.low, conf.high 21.66232 - 21.34058  #> [1] 0.32174 21.66232 + -(21.34058) #> [1] 0.32174 sum(c(21.66232, 21.34058) * c(1, -1)) #> [1] 0.32174 c(21.66232, 21.34058) %*% c(1, -1) #>         [,1] #> [1,] 0.32174"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"simple-contrast","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Simple contrast","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"marginal_means() function, can supply hypothesis argument compute linear combinations marginal means. argument must numeric vector length number rows output marginal_means(). example, previous six rows, two marginal means want compare first two positions:","code":"lc <- c(1, -1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term   Mean Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  custom 0.3217      1.774 0.1814  0.85606 -3.155  3.798 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, cyl  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"complex-contrast","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Complex contrast","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"course, can also estimate complex contrasts: emmeans produces similar results:","code":"lc <- c(-2, 1, 1, 0, -1, 1) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term    Mean Std. Error        z Pr(>|z|)  2.5 % 97.5 % #>  custom -0.2109      6.929 -0.03043  0.97572 -13.79  13.37 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, cyl  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high library(emmeans) em <- emmeans(mod, \"carb\") lc <- data.frame(custom_contrast = c(-2, 1, 1, 0, -1, 1)) contrast(em, method = lc) #>  contrast        estimate   SE df t.ratio p.value #>  custom_contrast   -0.211 6.93 24  -0.030  0.9760 #>  #> Results are averaged over the levels of: cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"multiple-contrasts","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Multiple contrasts","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Users can also compute multiple linear combinations simultaneously supplying numeric matrix hypotheses. matrix must number rows output slopes(), column represents distinct set weights different linear combinations. column names matrix become labels output. example:","code":"lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     1, -1, 0, 0, 0, 0     ), ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") lc #>      Contrast A Contrast B #> [1,]         -2          1 #> [2,]          1         -1 #> [3,]          1          0 #> [4,]          0          0 #> [5,]         -1          0 #> [6,]          1          0  marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>        Term    Mean Std. Error        z Pr(>|z|)   2.5 % 97.5 % #>  Contrast A -0.2109      6.929 -0.03043  0.97572 -13.791 13.369 #>  Contrast B  0.3217      1.774  0.18139  0.85606  -3.155  3.798 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, cyl  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"contrasts-across-response-levels","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Contrasts across response levels","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"models multinomial outcomes, one may interested comparing outcomes contrasts across response levels. example, model 18 estimated marginal means, across 6 outcome levels (group column): Let’s contrast marginal means first outcome level cyl equals 4 6. marginal means located rows 1 7 respectively: indeed equal results obtained manually: Now let’s say want calculate “contrast contrasts”, , outcome 3-step process: Contrast cyl=6 cyl=4 1st outcome level Contrast cyl=6 cyl=4 2nd outcome level Contrast contrasts defined steps 1 2. create linear combination weights follows: make sure weights correct, can display side side original marginal_means() output: Compute results:","code":"library(nnet) mod <- multinom(carb ~ mpg + cyl, data = dat, trace = FALSE) mm <- marginal_means(mod, type = \"probs\") mm #>  #>  Group Term Value      Mean Std. Error #>      1  cyl     4 3.679e-01  2.598e-01 #>      2  cyl     4 6.311e-01  2.601e-01 #>      3  cyl     4 6.853e-04  1.192e-02 #>      4  cyl     4 2.119e-04  1.750e-02 #>      6  cyl     4 8.815e-06  8.407e-05 #>      8  cyl     4 1.497e-04  7.970e-03 #>      1  cyl     6 2.829e-01  1.957e-01 #>      2  cyl     6 1.849e-06  2.395e-06 #>      3  cyl     6 1.122e-05  1.323e-03 #>      4  cyl     6 5.563e-01  2.185e-01 #>      6  cyl     6 1.608e-01  1.540e-01 #>      8  cyl     6 9.292e-06  7.982e-04 #>      1  cyl     8 4.625e-04  9.587e-03 #>      2  cyl     8 6.655e-01  3.745e-01 #>      3  cyl     8 3.104e-01  3.715e-01 #>      4  cyl     8 9.582e-03  2.289e-02 #>      6  cyl     8 4.346e-09  9.895e-08 #>      8  cyl     8 1.412e-02  4.673e-02 #>  #> Prediction type:  probs  #> Results averaged over levels of: cyl  #> Columns: type, group, term, value, cyl, estimate, std.error lc <- rep(0, nrow(mm)) lc[1] <- -1 lc[7] <- 1 marginal_means(     mod,     type = \"probs\",     hypothesis = lc) #>  #>    Term     Mean Std. Error #>  custom -0.08498     0.3207 #>  #> Prediction type:  probs  #> Results averaged over levels of: cyl  #> Columns: term, estimate, std.error 2.828726e-01 - 3.678521e-01 #> [1] -0.0849795 lc <- rep(0, nrow(mm)) lc[c(1, 8)] <- -1 lc[c(7, 2)] <- 1 transform(mm[, 1:3], lc = lc) #>     type group term lc #> 1  probs     1  cyl -1 #> 2  probs     2  cyl  1 #> 3  probs     3  cyl  0 #> 4  probs     4  cyl  0 #> 5  probs     6  cyl  0 #> 6  probs     8  cyl  0 #> 7  probs     1  cyl  1 #> 8  probs     2  cyl -1 #> 9  probs     3  cyl  0 #> 10 probs     4  cyl  0 #> 11 probs     6  cyl  0 #> 12 probs     8  cyl  0 #> 13 probs     1  cyl  0 #> 14 probs     2  cyl  0 #> 15 probs     3  cyl  0 #> 16 probs     4  cyl  0 #> 17 probs     6  cyl  0 #> 18 probs     8  cyl  0 marginal_means(mod, type = \"probs\", hypothesis = lc) #>  #>    Term   Mean Std. Error #>  custom 0.5461     0.5498 #>  #> Prediction type:  probs  #> Results averaged over levels of: cyl  #> Columns: term, estimate, std.error"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"pairwise-contrasts-difference-in-differences","dir":"Articles","previous_headings":"","what":"Pairwise contrasts: Difference-in-Differences","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now illustrate use machinery described pairwise comparisons contrasts, type analysis often associated “Difference--Differences” research design. First, simulate data two treatment groups pre/post periods: , estimate linear model multiple interaction time treatment indicators. also compute contrasts mean treatment level: Finally, compute pairwise differences contrasts. Diff--Diff estimate:","code":"library(data.table)  N <- 1000 did <- data.table(     id = 1:N,     pre = rnorm(N),     trt = sample(0:1, N, replace = TRUE)) did$post <- did$pre + did$trt * 0.3 + rnorm(N) did <- melt(     did,     value.name = \"y\",     variable.name = \"time\",     id.vars = c(\"id\", \"trt\")) head(did) #>    id trt time           y #> 1:  1   0  pre -0.44600793 #> 2:  2   1  pre  1.40767758 #> 3:  3   0  pre -0.93069396 #> 4:  4   0  pre  1.42884131 #> 5:  5   0  pre -0.03208054 #> 6:  6   0  pre -1.77270236 did_model <- lm(y ~ time * trt, data = did)  comparisons(     did_model,     newdata = datagrid(trt = 0:1),     variables = \"time\") #>  #>  Term   Contrast  Estimate Std. Error        z   Pr(>|z|)   2.5 % 97.5 % trt #>  time post - pre -0.007816    0.07961 -0.09818 0.92179280 -0.1638 0.1482   0 #>  time post - pre  0.290608    0.07993  3.63580 0.00027712  0.1339 0.4473   1 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, y, time, trt comparisons(     did_model,     variables = \"time\",     newdata = datagrid(trt = 0:1),     hypothesis = \"pairwise\") #>  #>           Term Estimate Std. Error      z  Pr(>|z|)   2.5 %   97.5 % #>  Row 1 - Row 2  -0.2984     0.1128 -2.645 0.0081614 -0.5195 -0.07732 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"equivalence-non-inferiority-and-non-superiority-tests","dir":"Articles","previous_headings":"","what":"Equivalence, non-inferiority, and non-superiority tests","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"many contexts, analysts less interested rejecting null hypothesis, interested testing whether estimate “inferior”, “superior”, “equivalent” given threshold interval. example, medical researchers may wish determine estimated effect new treatment larger effect prior treatments, larger threshold “clinical significance.” Alternatively, researchers may wish support claim estimated parameter “equivalent ” “meaningfully different ” null hypothesis. answer questions, can use non-inferiority, non-superiority, equivalence tests like two-one-sided test (TOST). article gives primer tutorial TOST: Lakens D, Scheel , Isager PM. Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science. 2018;1(2):259-269. doi:10.1177/2515245918770963 hypotheses() function marginaleffects package includes equivalence argument allows users apply tests quantities generated package, well arbitrary functions model’s parameters. illustrate, begin estimating simple linear regression model: rest section considers several quantities estimated marginaleffects.","code":"mod <- lm(mpg ~ hp + factor(gear), data = mtcars)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-1-predictions","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 1: Predictions","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Consider single prediction, predictors held median mode: Now specify equivalence interval (“region”) predictions 17 18: results allow us draw three conclusions: p value non-inferiority test 0.0040. suggests can reject null hypothesis parameter 17. p value non-superiority test 0.9508. suggests reject null hypothesis parameter (19.6589) 18. p value equivalence test 0.9508. suggests reject hypothesis parameter falls outside equivalence interval.","code":"p <- predictions(mod, newdata = \"median\") p #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     19.66      1.004 19.59 < 2.22e-16 17.69  21.63 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, gear hypotheses(p, equivalence = c(17, 18)) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 %     p (Inf)   p (Sup)    p (Eq) #>     19.66      1.004 19.59 < 2.22e-16 17.69  21.63 0.004037228 0.9508009 0.9508009 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, gear, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-2-model-coefficients","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 2: Model coefficients","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"hypotheses function also allows users conduct equivalence, non-inferiority, non-superiority tests model coefficients, arbitrary functions model coefficients. estimate 4th coefficient model : can test parameter likely fall [5,7] interval : p value 0.3979, reject hypothesis factor(gear)5 parameter falls outside [5,7] interval.","code":"coef(mod)[4] #> factor(gear)5  #>      6.574763 hypotheses(mod, equivalence = c(5, 7))[4, ] #>  #>  Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 %   p (Inf)   p (Sup)    p (Eq) #>    b4    6.575      1.643 4.002 6.2689e-05 3.355  9.794 0.1688669 0.3978688 0.3978688 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-3-slopes","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 3: Slopes","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"syntax can used conduct tests quantities produced marginaleffects package. example, imagine , substantive theoretical reasons, average slope -0.1 0.1 uninteresting. can conduct equivalence test check case: p value 0.0013, suggests can reject hypothesis parameter falls outside region “substantive equivalence” defined interval.","code":"avg_slopes(mod, variables = \"hp\") |>     hypotheses(equivalence = c(-.1, .1)) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)   2.5 %  97.5 %    p (Inf)      p (Sup)     p (Eq) #>    hp -0.06685    0.01105 -6.052 1.4269e-09 -0.0885 -0.0452 0.00134666 7.442542e-52 0.00134666 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-4-difference-between-comparisons-contrasts","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 4: Difference between comparisons (contrasts)","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Consider model multiplicative interaction: average contrast change 1 unit hp differs based value gear: contrasts different one another? Let’s look pairwise differences : consider pairwise comparisons “equivalent zero” fall [-.1, .1] interval: p (Eq.) column shows difference average contrasts gear 3 gear 5 can said equivalent specified interval. However, good reasons think two pairwise comparisons may fall outside interval.","code":"int <- lm(mpg ~ hp * factor(gear), data = mtcars) avg_comparisons(int, variables = \"hp\", by = \"gear\") #>  #>  Term Contrast gear Estimate Std. Error      z   Pr(>|z|)    2.5 %   97.5 % #>    hp mean(+1)    4 -0.17919    0.03025 -5.923 3.1628e-09 -0.23848 -0.11989 #>    hp mean(+1)    3 -0.05224    0.01456 -3.588 0.00033337 -0.08078 -0.02370 #>    hp mean(+1)    5 -0.05827    0.01263 -4.613 3.9749e-06 -0.08303 -0.03351 #>  #> Prediction type:  response  #> Columns: type, term, contrast, gear, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(int, variables = \"hp\", by = \"gear\", hypothesis = \"pairwise\") #>  #>                           Term  Estimate Std. Error       z   Pr(>|z|)    2.5 %   97.5 % #>  4,hp,mean(+1) - 3,hp,mean(+1) -0.126946    0.03357 -3.7810 0.00015618 -0.19275 -0.06114 #>  4,hp,mean(+1) - 5,hp,mean(+1) -0.120917    0.03278 -3.6882 0.00022581 -0.18517 -0.05666 #>  3,hp,mean(+1) - 5,hp,mean(+1)  0.006029    0.01928  0.3128 0.75445655 -0.03175  0.04381 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(int, variables = \"hp\", by = \"gear\", hypothesis = \"pairwise\") |>     hypotheses(equivalence = c(-.1, .1)) #>  #>                           Term  Estimate Std. Error       z   Pr(>|z|)    2.5 %   97.5 %      p (Inf)      p (Sup) #>  4,hp,mean(+1) - 3,hp,mean(+1) -0.126946    0.03357 -3.7810 0.00015618 -0.19275 -0.06114 7.888916e-01 6.924196e-12 #>  4,hp,mean(+1) - 5,hp,mean(+1) -0.120917    0.03278 -3.6882 0.00022581 -0.18517 -0.05666 7.382704e-01 8.003657e-12 #>  3,hp,mean(+1) - 5,hp,mean(+1)  0.006029    0.01928  0.3128 0.75445655 -0.03175  0.04381 1.893635e-08 5.441588e-07 #>        p (Eq) #>  7.888916e-01 #>  7.382704e-01 #>  5.441588e-07 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-5-marginal-means-and-emmeans","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 5: Marginal means and emmeans","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"example shows equivalence results produced emmeans package marginal_means() function:","code":"library(emmeans)  mod <- lm(log(conc) ~ source + factor(percent), data = pigs)  # {emmeans} emmeans(mod, specs = \"source\") |>     pairs() |>     test(df = Inf,          null = 0,          delta = log(1.25),          side = \"equivalence\",          adjust = \"none\") #>  contrast    estimate     SE  df z.ratio p.value #>  fish - soy    -0.273 0.0529 Inf   0.937  0.8257 #>  fish - skim   -0.402 0.0542 Inf   3.308  0.9995 #>  soy - skim    -0.130 0.0530 Inf  -1.765  0.0388 #>  #> Results are averaged over the levels of: percent  #> Degrees-of-freedom method: user-specified  #> Results are given on the log (not the response) scale.  #> Statistics are tests of equivalence with a threshold of 0.22314  #> P values are left-tailed  # {marginaleffects} marginal_means(     mod,     variables = \"source\",     hypothesis = \"pairwise\") |>     hypotheses(equivalence = c(-log(1.25), log(1.25))) #>  #>         Term    Mean Std. Error      z   Pr(>|z|)   2.5 %   97.5 %     p (Eq)    p (Inf)      p (Sup) #>   fish - soy -0.2728    0.05293 -5.153 2.5645e-07 -0.3765 -0.16902 0.82574055 0.82574055 3.682126e-21 #>  fish - skim -0.4023    0.05416 -7.428 1.1052e-13 -0.5084 -0.29613 0.99952941 0.99952941 3.786224e-31 #>   soy - skim -0.1295    0.05304 -2.442   0.014622 -0.2335 -0.02555 0.03876101 0.03876101 1.480788e-11 #>  #> Prediction type:  response  #> Results averaged over levels of: source, percent  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, p.value.equiv, p.value.noninf, p.value.nonsup, statistic.noninf, statistic.nonsup"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-6-t-test","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 6: t-test","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now show results produced hypotheses() identical results produced equivalence package case simple t-test:","code":"library(equivalence)  set.seed(1024)  # simulate data data N <- 20 dat <- data.frame(     y = rnorm(N),     x = sample(c(rep(0, N / 2), rep(1, N / 2)), N))  # fit model mod <- lm(y ~ x, data = dat)  # test with the {equivalence} package e <- tost(     x = dat$y[dat$x == 0],     y = dat$y[dat$x == 1],     epsilon = 10) e #>  #>  Welch Two Sample TOST #>  #> data:  dat$y[dat$x == 0] and dat$y[dat$x == 1] #> df = 17.607 #> sample estimates: #>  mean of x  mean of y  #> -0.3788551 -0.2724594  #>  #> Epsilon: 10  #> 95 percent two one-sided confidence interval (TOST interval): #>  -1.058539  0.845747 #> Null hypothesis of statistical difference is: rejected  #> TOST p-value: 4.248528e-13  # test with {marginaleffects} package hypotheses(mod, equivalence = c(-10, 10), df = e$parameter)[2,] #>  #>  Term Estimate Std. Error     z Pr(>|z|)  2.5 % 97.5 %      p (Inf)      p (Sup)       p (Eq) #>    b2   0.1064     0.5484 0.194  0.84839 -1.048   1.26 2.973612e-13 4.248528e-13 4.248528e-13 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, df, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/lme4.html","id":"unit-level-predictions","dir":"Articles","previous_headings":"","what":"Unit-level predictions","title":"Mixed Effects Models with lme4","text":"Predict weight chick time:  Predictions chick, 4 counterfactual worlds different values Diet variable:","code":"pred1 <- predictions(fit1,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p1 <- ggplot(pred1, aes(Time, estimate, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Linear growth model\")  pred2 <- predictions(fit2,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p2 <- ggplot(pred2, aes(Time, estimate, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Quadratic growth model\")  p1 + p2 pred <- predictions(fit2)  ggplot(pred, aes(Time, estimate, level = Chick)) +     geom_line() +     ylab(\"Predicted Weight\") +     facet_wrap(~ Diet, labeller = label_both)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/lme4.html","id":"population-level-predictions","dir":"Articles","previous_headings":"","what":"Population-level predictions","title":"Mixed Effects Models with lme4","text":"make population-level predictions, set Chick variable NA, set include_ranom=FALSE. last argument offered insight::get_predicted function used behind scenes compute predictions:","code":"pred <- predictions(     fit2,     newdata = datagrid(Chick = NA,                        Diet = 1:4,                        Time = 0:21),     include_random = FALSE)  ggplot(pred, aes(x = Time, y = estimate, ymin = conf.low, ymax = conf.high)) +     geom_ribbon(alpha = .1, fill = \"red\") +     geom_line() +     facet_wrap(~ Diet, labeller = label_both) +     labs(title = \"Population-level trajectories\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Logistic Regression","text":"focus subset data GUSTO-study, patients randomly assigned accelerated tissue plasminogen activator (tPA) streptokinase (SK). Load libraries, data fit covariate-adjusted logistic regression model.","code":"library(marginaleffects) library(modelsummary) library(rms)  load(url( \"https://github.com/vincentarelbundock/modelarchive/raw/main/data-raw/gusto.rda\" ))  gusto <- subset(gusto, tx %in% c(\"tPA\", \"SK\")) gusto$tx <- factor(gusto$tx, levels = c(\"tPA\", \"SK\"))  mod <- glm(     day30 ~ tx + rcs(age, 4) + Killip + pmin(sysbp, 120) + lsp(pulse, 50) +     pmi + miloc + sex, family = \"binomial\",     data = gusto)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"one-number-summaries","dir":"Articles","previous_headings":"Data","what":"One-Number Summaries","title":"Logistic Regression","text":"usual, can produce one-number summary relationship interest exponentiating coefficients, yields Odds Ratio (): Unlike ORs, adjusted risk differences vary individual individual based values control variables. comparisons() function can compute adjusted risk differences every individual. , display first 6 : Population-averaged (aka “marginal”) adjusted risk difference (see vignette) can obtained using avg_*() functions using argument: comparisons() function computed predicted probability mortality (day30==1) observed row data two counterfactual cases: tx “SK”, tx “tPA”. , computed differences two sets predictions. Finally, computed population-average risk differences. Instead risk differences, compute population-averaged (marginal) adjusted risk ratios: Population-averaged (marginal) odds ratios:","code":"modelsummary(mod, exponentiate = TRUE, coef_omit = \"^(?!txSK)\") comparisons(     mod,     variables = \"tx\") |>     head() #>  #>  Term Contrast  Estimate Std. Error     z Pr(>|z|)     2.5 %   97.5 % #>    tx SK - tPA 0.0010742  0.0004967 2.163 0.030559 0.0001007 0.002048 #>    tx SK - tPA 0.0008573  0.0003800 2.256 0.024056 0.0001126 0.001602 #>    tx SK - tPA 0.0017798  0.0007784 2.286 0.022234 0.0002541 0.003305 #>    tx SK - tPA 0.0011367  0.0004999 2.274 0.022970 0.0001570 0.002117 #>    tx SK - tPA 0.0013655  0.0005934 2.301 0.021383 0.0002025 0.002529 #>    tx SK - tPA 0.0024016  0.0010127 2.371 0.017720 0.0004167 0.004386 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, day30, tx, Killip, pmi, miloc, sex, age, pulse, sysbp avg_comparisons(mod, variables = \"tx\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)    2.5 % 97.5 % #>    tx SK - tPA  0.01108   0.002766 4.005 6.1955e-05 0.005658 0.0165 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high avg_comparisons(     mod,     variables = \"tx\",     transform_pre = \"lnratioavg\",     transform_post = exp) #>  #>  Term                 Contrast Estimate   Pr(>|z|) 2.5 % 97.5 % #>    tx ln(mean(SK) / mean(tPA))    1.177 9.8075e-05 1.085  1.278 #>  #> Prediction type:  response  #> Post-transformation:  transform_post  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(     mod,     variables = \"tx\",     transform_pre = \"lnoravg\",     transform_post = exp) #>  #>  Term                 Contrast Estimate   Pr(>|z|) 2.5 % 97.5 % #>    tx ln(odds(SK) / odds(tPA))    1.192 9.4701e-05 1.091  1.301 #>  #> Prediction type:  response  #> Post-transformation:  transform_post  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"unit-level-summaries","dir":"Articles","previous_headings":"Data","what":"Unit-level Summaries","title":"Logistic Regression","text":"Instead estimating one-number summaries, can focus unit-level proportion differences using comparisons(). function applies fitted logistic regression model predict outcome probabilities patient, .e., unit-level. Show predicted probability individual patients treatment alternatives.  Lastly, present entire distribution unit-level proportion differences mean median.","code":"cmp <- comparisons(mod, variables = \"tx\")  head(cmp) #>  #>  Term Contrast  Estimate Std. Error     z Pr(>|z|)     2.5 %   97.5 % #>    tx SK - tPA 0.0010742  0.0004967 2.163 0.030559 0.0001007 0.002048 #>    tx SK - tPA 0.0008573  0.0003800 2.256 0.024056 0.0001126 0.001602 #>    tx SK - tPA 0.0017798  0.0007784 2.286 0.022234 0.0002541 0.003305 #>    tx SK - tPA 0.0011367  0.0004999 2.274 0.022970 0.0001570 0.002117 #>    tx SK - tPA 0.0013655  0.0005934 2.301 0.021383 0.0002025 0.002529 #>    tx SK - tPA 0.0024016  0.0010127 2.371 0.017720 0.0004167 0.004386 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, day30, tx, Killip, pmi, miloc, sex, age, pulse, sysbp plot(x = cmp$predicted_hi,      y = cmp$predicted_lo,      main = \"Risk of Mortality\",      xlab = \"SK\",      ylab = \"tPA\")  abline(0, 1) hist(cmp$estimate,      breaks = 100,      main = \"Distribution of unit-level contrasts\",      xlab = \"SK - tPA\") abline(v = mean(cmp$estimate), col = \"red\") abline(v = median(cmp$estimate), col = \"blue\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"appendix","dir":"Articles","previous_headings":"Data","what":"Appendix","title":"Logistic Regression","text":"comparisons() performed following calculations hood: original dataset contains 30510 patients, thus comparisons() generates output amount rows.","code":"d  <- gusto  d$tx = \"SK\" predicted_hi <- predict(mod, newdata = d, type = \"response\")  d$tx = \"tPA\" predicted_lo <- predict(mod, newdata = d, type = \"response\")  comparison <- predicted_hi - predicted_lo nrow(gusto) #> [1] 30510 nrow(cmp) #> [1] 30510"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Get Started","text":"Install latest CRAN release: Install development version: Restart R completely moving .","code":"install.packages(\"marginaleffects\") install.packages(     c(\"marginaleffects\", \"insight\"),     repos = c(\"https://vincentarelbundock.r-universe.dev\", \"https://easystats.r-universe.dev\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"estimands-predictions-comparisons-and-slopes","dir":"Articles","previous_headings":"","what":"Estimands: Predictions, Comparisons, and Slopes","title":"Get Started","text":"marginaleffects package allows R users compute plot three principal quantities interest: (1) predictions, (2) comparisons, (3) slopes. addition, package includes convenience function compute fourth estimand, “marginal means”, special case averaged predictions. marginaleffects can also average (“marginalize”) unit-level (“conditional”) estimates quantities, conduct hypothesis tests . Predictions: outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels. .k.. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions(). Comparisons: Compare predictions made model different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons(). Slopes: Partial derivative regression equation respect regressor interest. .k.. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes(). Marginal Means: Predictions model, averaged across “reference grid” categorical predictors. marginalmeans(). Predictions, comparisons, slopes fundamentally unit-level (“conditional”) quantities. Except simplest linear case, estimates typically vary based values regressors model. observations dataset thus associated prediction, comparison, slope estimates. , see can useful marginalize (“average ”) unit-level estimates report “average prediction”, “average comparison”, “average slope”. One ambiguous aspect definitions word “marginal” comes two different opposite ways: “marginal effects,” refer effect tiny (marginal) change regressor outcome. slope, derivative. “marginal means,” refer process marginalizing across rows prediction grid. average, integral. website package, reserve expression “marginal effect” mean “slope” “partial derivative”. marginaleffects package includes functions estimate, average, plot, summarize estimands described . objects produced marginaleffects “tidy”: produce simple data frames “long” format. also “standards-compliant” work seamlessly standard functions like summary(), plot(), tidy(), glance(), well external packages like modelsummary ggplot2. now apply marginaleffects functions compute estimands described . First, fit linear regression model multiplicative interactions: , call predictions() function. noted , predictions unit-level estimates, one specific prediction per observation. default, predictions() function makes one prediction per observation dataset used fit original model. Since mtcars 32 rows, predictions() outcome also 32 rows: Now, use comparisons() function compute different predicted outcome predictors incremented 1 unit (one predictor time, holding others constant). , comparisons unit-level quantities. since 3 predictors model data 32 rows, obtain 96 comparisons: comparisons() function allows customized queries. example, happens predicted outcome hp variable increases 100 120? happens predicted outcome wt variable increases 1 standard deviation mean? comparisons() function also allows users specify arbitrary functions predictions, transform_pre argument. example, average ratio predicted Miles per Gallon increase 50 units Horsepower? See Comparisons vignette detailed explanations options. slopes() function allows us compute partial derivative outcome equation respect predictors. , obtain data frame 96 rows:","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt * am, data = mtcars) pre <- predictions(mod)  nrow(mtcars) ## [1] 32 nrow(pre) ## [1] 32 pre ##  ##  Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % ##     22.49     0.8841 25.435 < 2.22e-16 20.756  24.22 ##     20.80     1.1942 17.419 < 2.22e-16 18.461  23.14 ##     25.26     0.7085 35.658 < 2.22e-16 23.876  26.65 ##     20.26     0.7045 28.753 < 2.22e-16 18.875  21.64 ##     17.00     0.7119 23.878 < 2.22e-16 15.603  18.39 ## --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  ##     29.59     1.8735 15.795 < 2.22e-16 25.921  33.27 ##     15.90     1.3107 12.128 < 2.22e-16 13.327  18.47 ##     19.41     1.1454 16.947 < 2.22e-16 17.167  21.66 ##     14.79     2.0174  7.330 2.2943e-13 10.834  18.74 ##     21.46     1.0719 20.022 < 2.22e-16 19.361  23.56  ##  ## Prediction type:  response  ## Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, wt, am cmp <- comparisons(mod)  nrow(cmp) ## [1] 96 cmp ##  ##  Term Contrast  Estimate Std. Error       z   Pr(>|z|)     2.5 %     97.5 % ##    hp       +1 -0.036906    0.01850 -1.9947 0.04607449  -0.07317 -0.0006429 ##    hp       +1 -0.028689    0.01563 -1.8357 0.06640282  -0.05932  0.0019422 ##    hp       +1 -0.046572    0.02259 -2.0619 0.03922051  -0.09084 -0.0023017 ##    hp       +1 -0.042271    0.01328 -3.1824 0.00146054  -0.06831 -0.0162375 ##    hp       +1 -0.039018    0.01341 -2.9095 0.00362022  -0.06530 -0.0127338 ## --- 86 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    am    1 - 0  4.080730    3.93510  1.0370 0.29973237  -3.63193 11.7933866 ##    am    1 - 0  2.106353    2.28920  0.9201 0.35750670  -2.38040  6.5931031 ##    am    1 - 0  0.895066    1.64419  0.5444 0.58617945  -2.32749  4.1176203 ##    am    1 - 0  4.027219    3.24024  1.2429 0.21391295  -2.32353 10.3779686 ##    am    1 - 0 -0.236915    1.58642 -0.1493 0.88128622  -3.34625  2.8724165  ##  ## Prediction type:  response  ## Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am, eps comparisons(mod, variables = list(hp = c(120, 100))) ##  ##  Term  Contrast Estimate Std. Error       z  Pr(>|z|)   2.5 %    97.5 % ##    hp 120 - 100  -0.7381     0.3700 -1.9947 0.0460745 -1.4634 -0.012857 ##    hp 120 - 100  -0.5738     0.3126 -1.8357 0.0664028 -1.1864  0.038843 ##    hp 120 - 100  -0.9314     0.4517 -2.0619 0.0392205 -1.8168 -0.046033 ##    hp 120 - 100  -0.8454     0.2657 -3.1824 0.0014605 -1.3661 -0.324750 ##    hp 120 - 100  -0.7804     0.2682 -2.9095 0.0036202 -1.3061 -0.254677 ## --- 22 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    hp 120 - 100  -1.4515     0.7052 -2.0581 0.0395803 -2.8337 -0.069212 ##    hp 120 - 100  -0.3837     0.2698 -1.4221 0.1549843 -0.9125  0.145101 ##    hp 120 - 100  -0.6415     0.3345 -1.9178 0.0551304 -1.2970  0.014087 ##    hp 120 - 100  -0.1259     0.2722 -0.4627 0.6435969 -0.6594  0.407510 ##    hp 120 - 100  -0.6350     0.3323 -1.9112 0.0559829 -1.2862  0.016213  ##  ## Prediction type:  response  ## Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am, eps comparisons(mod, variables = list(hp = \"sd\")) ##  ##  Term                Contrast Estimate Std. Error       z  Pr(>|z|)  2.5 %   97.5 % ##    hp (x + sd/2) - (x - sd/2)  -2.5304     1.2685 -1.9947 0.0460745 -5.017 -0.04408 ##    hp (x + sd/2) - (x - sd/2)  -1.9670     1.0715 -1.8357 0.0664028 -4.067  0.13316 ##    hp (x + sd/2) - (x - sd/2)  -3.1931     1.5486 -2.0619 0.0392205 -6.228 -0.15781 ##    hp (x + sd/2) - (x - sd/2)  -2.8982     0.9107 -3.1824 0.0014605 -4.683 -1.11329 ##    hp (x + sd/2) - (x - sd/2)  -2.6752     0.9195 -2.9095 0.0036202 -4.477 -0.87307 ## --- 22 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    hp (x + sd/2) - (x - sd/2)  -4.9758     2.4177 -2.0581 0.0395803 -9.714 -0.23727 ##    hp (x + sd/2) - (x - sd/2)  -1.3153     0.9249 -1.4221 0.1549843 -3.128  0.49743 ##    hp (x + sd/2) - (x - sd/2)  -2.1990     1.1466 -1.9178 0.0551304 -4.446  0.04829 ##    hp (x + sd/2) - (x - sd/2)  -0.4317     0.9330 -0.4627 0.6435969 -2.260  1.39700 ##    hp (x + sd/2) - (x - sd/2)  -2.1769     1.1390 -1.9112 0.0559829 -4.409  0.05558  ##  ## Prediction type:  response  ## Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am, eps comparisons(   mod,   variables = list(hp = 50),   transform_pre = \"ratioavg\") ##  ##  Term  Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % ##    hp mean(+50)   0.9095    0.02895 31.42 < 2.22e-16 0.8528 0.9663 ##  ## Prediction type:  response  ## Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo mfx <- slopes(mod)  nrow(mfx) ## [1] 96 mfx ##  ##  Term  Estimate Std. Error       z   Pr(>|z|)     2.5 %     97.5 % ##    hp -0.036906    0.01850 -1.9947 0.04607449  -0.07317 -0.0006429 ##    hp -0.028689    0.01563 -1.8357 0.06640282  -0.05932  0.0019422 ##    hp -0.046572    0.02259 -2.0619 0.03922051  -0.09084 -0.0023017 ##    hp -0.042271    0.01328 -3.1824 0.00146054  -0.06831 -0.0162375 ##    hp -0.039018    0.01341 -2.9095 0.00362022  -0.06530 -0.0127338 ## --- 86 rows omitted. See ?avg_slopes and ?print.marginaleffects ---  ##    am  4.080730    3.93509  1.0370 0.29973145  -3.63191 11.7933719 ##    am  2.106353    2.28920  0.9201 0.35750674  -2.38040  6.5931035 ##    am  0.895066    1.64419  0.5444 0.58617947  -2.32749  4.1176205 ##    am  4.027219    3.24024  1.2429 0.21391291  -2.32353 10.3779680 ##    am -0.236915    1.58642 -0.1493 0.88128623  -3.34625  2.8724169  ##  ## Prediction type:  response  ## Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"grid","dir":"Articles","previous_headings":"","what":"Grid","title":"Get Started","text":"Predictions, comparisons, slopes typically “conditional” quantities depend values predictors model. default, marginaleffects functions estimate quantities interest empirical distribution data (.e., row original dataset). However, users can specify exact values predictors want investigate using newdata argument. newdata accepts data frames, shortcut strings, call datagrid() function. example, compute predicted outcome hypothetical car predictors equal sample mean median, can : datagrid function gives us powerful way define grid predictors. variables mentioned explicitly datagrid() fixed mean mode: mechanism available comparisons() slopes(). estimate partial derivative mpg respect wt, equal 0 1, predictors held means: can also plot predictions, comparisons, slopes change across different values predictors using three powerful plotting functions: plot_predictions: Conditional Adjusted Predictions plot_comparisons: Conditional Comparisons plot_slopes: Conditional Marginal Effects example, plot shows outcomes predicted model different values wt variables:  plot shows derivative mpg respect varies function wt hp:  See vignette information: Plots, interactions, predictions, contrasts, slopes","code":"predictions(mod, newdata = \"mean\") ##  ##  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##     18.37     0.6799 27.02 < 2.22e-16 17.04   19.7 ##  ## Prediction type:  response  ## Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, wt, am predictions(mod, newdata = \"median\") ##  ##  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##     19.37     0.6464 29.97 < 2.22e-16 18.11  20.64 ##  ## Prediction type:  response  ## Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, wt, am predictions(   mod,   newdata = datagrid(     am = c(0, 1),     wt = range)) ##  ##  Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % am    wt ##    23.259      2.706 8.596 < 2.22e-16 17.956  28.56  0 1.513 ##    12.793      2.978 4.295 1.7459e-05  6.955  18.63  0 5.424 ##    27.148      2.852 9.520 < 2.22e-16 21.559  32.74  1 1.513 ##     5.902      5.815 1.015    0.31013 -5.495  17.30  1 5.424 ##  ## Prediction type:  response  ## Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, am, wt slopes(   mod,   variables = \"wt\",   newdata = datagrid(am = 0:1)) ##  ##  Term Estimate Std. Error      z Pr(>|z|)  2.5 %  97.5 % am ##    wt   -2.676      1.419 -1.886 0.059355 -5.458  0.1056  0 ##    wt   -5.432      2.152 -2.524 0.011605 -9.651 -1.2139  1 ##  ## Prediction type:  response  ## Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am, eps plot_predictions(mod, condition = list(\"hp\", \"wt\" = \"threenum\", \"am\")) plot_slopes(mod, effect = \"am\", condition = list(\"hp\", \"wt\" = \"minmax\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"averaging","dir":"Articles","previous_headings":"","what":"Averaging","title":"Get Started","text":"Since predictions, comparisons, slopes conditional quantities, can bit unwieldy. Often, can useful report one-number summary instead one estimate per observation. Instead presenting “conditional” estimates, methodologists recommend reporting “marginal” estimates, , average unit-level estimates. (use word “marginal” “averaging” confused term “marginal effect” , econometrics tradition, corresponds partial derivative, effect “small/marginal” change.) marginalize (average ) unit-level estimates, can use argument one convenience functions: avg_predictions(), avg_comparisons(), avg_slopes(). example, commands give us result: average predicted outcome mtcars dataset: equivalent manual computation : main marginaleffects functions include argument, allows us marginalize within sub-groups data. example, Marginal Means special case predictions, marginalized (averaged) across balanced grid categorical predictors. illustrate, estimate new model categorical predictors: can compute marginal means manually using functions already described: convenience, marginaleffects package also includes marginal_means() function: Marginal Means vignette offers detail.","code":"avg_predictions(mod) ##  ##  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##     20.09     0.3904 51.46 < 2.22e-16 19.33  20.86 ##  ## Prediction type:  response  ## Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high mean(predict(mod)) ## [1] 20.09062 avg_comparisons(mod, by = \"am\") ##  ##  Term          Contrast am Estimate Std. Error       z  Pr(>|z|)    2.5 %    97.5 % ##    hp          mean(+1)  1 -0.04364    0.02129 -2.0498 0.0403865 -0.08537 -0.001912 ##    hp          mean(+1)  0 -0.03426    0.01586 -2.1598 0.0307863 -0.06536 -0.003171 ##    wt          mean(+1)  1 -6.07176    1.97621 -3.0724 0.0021233 -9.94506 -2.198458 ##    wt          mean(+1)  0 -2.47990    1.23163 -2.0135 0.0440605 -4.89385 -0.065954 ##    am mean(1) - mean(0)  1  1.90290    2.30863  0.8243 0.4097951 -2.62193  6.427728 ##    am mean(1) - mean(0)  0 -1.38301    2.52499 -0.5477 0.5838789 -6.33191  3.565888 ##  ## Prediction type:  response  ## Columns: type, term, contrast, am, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo dat <- mtcars dat$am <- as.logical(dat$am) dat$cyl <- as.factor(dat$cyl) mod_cat <- lm(mpg ~ am + cyl + hp, data = dat) avg_predictions(   mod_cat,   newdata = datagrid(cyl = unique, am = unique),   by = \"am\") ##  ##     am Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##   TRUE    22.48     0.8343 26.94 < 2.22e-16 20.84  24.11 ##  FALSE    18.32     0.7854 23.33 < 2.22e-16 16.78  19.86 ##  ## Prediction type:  response  ## Columns: type, am, estimate, std.error, statistic, p.value, conf.low, conf.high marginal_means(mod_cat, variables = \"am\") ##  ##  Term Value  Mean Std. Error     z   Pr(>|z|) 2.5 % 97.5 % ##    am FALSE 18.32     0.7854 23.33 < 2.22e-16 16.78  19.86 ##    am  TRUE 22.48     0.8343 26.94 < 2.22e-16 20.84  24.11 ##  ## Prediction type:  response  ## Results averaged over levels of: am, cyl  ## Columns: type, term, value, am, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"hypothesis-and-equivalence-tests","dir":"Articles","previous_headings":"","what":"Hypothesis and equivalence tests","title":"Get Started","text":"hypotheses() function hypothesis argument can used conduct linear non-linear hypothesis tests model coefficients, quantities computed functions introduced . Consider model: Can reject null hypothesis drat coefficient 2 times size qsec coefficient? can ask question refer parameters position, indices b1, b2, b3, etc.: main functions marginaleffects hypothesis argument, means can complex model testing. example, consider two slope estimates: two slopes significantly different one another? test , can use hypothesis argument: Now, imagine theoretical (substantive clinical) reasons, care slopes larger 2. can use hypotheses() function conduct equivalence test: See Hypothesis Tests Custom Contrasts vignette background, details, instructions conduct hypothesis tests complex situations.","code":"mod <- lm(mpg ~ qsec * drat, data = mtcars) coef(mod) ## (Intercept)        qsec        drat   qsec:drat  ##  12.3371987  -1.0241183  -3.4371461   0.5973153 hypotheses(mod, \"drat = 2 * qsec\") ##  ##             Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % ##  drat = 2 * qsec   -1.389      10.78 -0.1289  0.89744 -22.51  19.73 ##  ## Prediction type:   ## Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high hypotheses(mod, \"b3 = 2 * b2\") ##  ##         Term Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % ##  b3 = 2 * b2   -1.389      10.78 -0.1289  0.89744 -22.51  19.73 ##  ## Prediction type:   ## Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high slopes(   mod,   variables = \"drat\",   newdata = datagrid(qsec = range)) ##  ##  Term Estimate Std. Error     z Pr(>|z|)   2.5 % 97.5 % qsec ##  drat    5.224      3.791 1.378 0.168217 -2.2064  12.65 14.5 ##  drat   10.241      5.161 1.984 0.047232  0.1252  20.36 22.9 ##  ## Prediction type:  response  ## Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, drat, qsec, eps slopes(   mod,   hypothesis = \"b1 = b2\",   variables = \"drat\",   newdata = datagrid(qsec = range)) ##  ##   Term Estimate Std. Error      z Pr(>|z|)  2.5 % 97.5 % ##  b1=b2   -5.017      8.519 -0.589  0.55589 -21.71  11.68 ##  ## Prediction type:  response  ## Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high avg_slopes(mod) |> hypotheses(equivalence = c(-2, 2)) ##  ##  Term Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 %      p (Inf)    p (Sup)     p (Eq) ##  qsec    1.124     0.4331 2.595  0.0094487 0.2752  1.973 2.740290e-13 0.02158503 0.02158503 ##  drat    7.224     1.3652 5.292 1.2122e-07 4.5484  9.900 7.062316e-12 0.99993505 0.99993505 ##  ## Prediction type:  response  ## Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"more","dir":"Articles","previous_headings":"","what":"More!","title":"Get Started","text":"much can marginaleffects. Return Table Contents read vignettes, learn report marginal effects nice tables modelsummary package, define prediction “grid”, much . ****","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"interactions","dir":"Articles","previous_headings":"","what":"Interactions","title":"Marginal Means","text":"default, marginal_means() function calculates marginal means categorical predictor one . can also compute marginal means combinations categories setting cross=TRUE: Regardless scale predictions (type argument), marginal_means() always computes standard errors using Delta Method: model linear link scale, also produces confidence intervals: easy transform link-scale marginal means arbitrary functions using transform_post argument: marginal_means() defaults reporting EMMs category individually, without cross-margins: can force cross:","code":"library(lme4)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glmer(     Survived ~ Sex * PClass + Age + (1 | PClass),     family = binomial,     data = dat) marginal_means(     titanic,     type = \"response\",     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value   Mean Std. Error #>     Sex female 0.7383    0.02069 #>     Sex   male 0.2354    0.02025 #>  PClass    1st 0.7076    0.02726 #>  PClass    2nd 0.5113    0.02350 #>  PClass    3rd 0.2417    0.02814 #>  #> Prediction type:  response  #> Results averaged over levels of: Sex, PClass  #> Columns: type, term, value, estimate, std.error marginal_means(     titanic,     type = \"link\",     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value     Mean Std. Error        z   Pr(>|z|)   2.5 %  97.5 % #>     Sex female  1.64069     0.2055   7.9838 1.4190e-15  1.2379  2.0435 #>     Sex   male -1.33991     0.1237 -10.8278 < 2.22e-16 -1.5825 -1.0974 #>  PClass    1st  1.63065     0.2705   6.0279 1.6609e-09  1.1005  2.1609 #>  PClass    2nd  0.09968     0.2110   0.4725    0.63657 -0.3138  0.5132 #>  PClass    3rd -1.27917     0.1550  -8.2553 < 2.22e-16 -1.5829 -0.9755 #>  #> Prediction type:  link  #> Results averaged over levels of: Sex, PClass  #> Columns: type, term, value, estimate, std.error, statistic, p.value, conf.low, conf.high marginal_means(     titanic,     type = \"link\",     transform_post = insight::link_inverse(titanic),     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value   Mean   Pr(>|z|)  2.5 % 97.5 % #>     Sex female 0.8376 1.4190e-15 0.7752 0.8853 #>     Sex   male 0.2075 < 2.22e-16 0.1704 0.2502 #>  PClass    1st 0.8363 1.6609e-09 0.7503 0.8967 #>  PClass    2nd 0.5249    0.63657 0.4222 0.6256 #>  PClass    3rd 0.2177 < 2.22e-16 0.1704 0.2738 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Results averaged over levels of: Sex, PClass  #> Columns: type, term, value, estimate, p.value, conf.low, conf.high titanic2 <- glmer(     Survived ~ Sex + PClass + Age + (1 | PClass),     family = binomial,     data = dat)  marginal_means(     titanic2,     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value   Mean   Pr(>|z|)  2.5 % 97.5 % #>     Sex female 0.7854 < 2.22e-16 0.7308 0.8315 #>     Sex   male 0.2085 < 2.22e-16 0.1709 0.2519 #>  PClass    1st 0.7778 7.4982e-11 0.7060 0.8362 #>  PClass    2nd 0.4903    0.82106 0.4072 0.5740 #>  PClass    3rd 0.2195 4.2475e-14 0.1683 0.2811 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Results averaged over levels of: Sex, PClass  #> Columns: type, term, value, estimate, p.value, conf.low, conf.high marginal_means(     titanic2,     cross = TRUE,     variables = c(\"Sex\", \"PClass\")) #>  #>     Mean   Pr(>|z|)   2.5 % 97.5 % #>  0.92882 < 2.22e-16 0.89008 0.9546 #>  0.78191 1.0121e-09 0.70413 0.8438 #>  0.51183    0.79634 0.42257 0.6003 #>  0.48436    0.73839 0.39415 0.5756 #>  0.20513 7.4629e-13 0.15125 0.2720 #>  0.07017 < 2.22e-16 0.04785 0.1018 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Columns: rowid, type, Sex, PClass, estimate, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"group-averages-with-the-by-argument","dir":"Articles","previous_headings":"","what":"Group averages with the by argument","title":"Marginal Means","text":"can collapse marginal means via averaging using argument: can use hypothesis argument compare new collapsed subgroups:","code":"dat <- mtcars dat$am <- factor(dat$am) dat$vs <- factor(dat$vs) dat$cyl <- factor(dat$cyl)  mod <- glm(gear ~ cyl + vs + am, data = dat, family = poisson)  by <- data.frame(     by = c(\"(4 & 6)\", \"(4 & 6)\", \"(8)\"),     cyl = c(4, 6, 8))  marginal_means(mod, by = by, variables = \"cyl\") #>  #>       By  Mean   Pr(>|z|) 2.5 % 97.5 % #>  (4 & 6) 3.862 < 2.22e-16 2.857  5.221 #>      (8) 3.593 2.6621e-06 2.107  6.128 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Results averaged over levels of: cyl, vs, am  #> Columns: by, estimate, p.value, conf.low, conf.high marginal_means(mod, by = by, variables = \"cyl\", hypothesis = \"pairwise\") #>  #>           Term  Mean Pr(>|z|)  2.5 % 97.5 % #>  (4 & 6) - (8) 1.075  0.84771 0.5149  2.243 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Results averaged over levels of: cyl, vs, am  #> Columns: term, estimate, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"custom-contrasts-and-linear-combinations","dir":"Articles","previous_headings":"","what":"Custom Contrasts and Linear Combinations","title":"Marginal Means","text":"See vignette Custom Contrasts Combinations","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"tidy-summaries","dir":"Articles","previous_headings":"","what":"Tidy summaries","title":"Marginal Means","text":"summary, tidy, glance functions also available summarize manipulate results: Thanks tidiers, can also present results style regression table using modelsummary package. examples, see tables plots vignette.","code":"mm <- marginal_means(mod)  tidy(mm) #> # A tibble: 7 × 7 #>   type  term  value estimate  p.value conf.low conf.high #>   <chr> <chr> <fct>    <dbl>    <dbl>    <dbl>     <dbl> #> 1 link  cyl   4         3.83 2.34e- 8     2.39      6.13 #> 2 link  cyl   6         3.90 1.57e-12     2.67      5.68 #> 3 link  cyl   8         3.59 2.66e- 6     2.11      6.13 #> 4 link  am    0         3.27 3.96e-15     2.43      4.40 #> 5 link  vs    0         3.79 1.88e-12     2.62      5.50 #> 6 link  am    1         4.34 6.83e-19     3.14      6.01 #> 7 link  vs    1         3.75 5.82e-10     2.47      5.69  glance(mm) #> # A tibble: 1 × 7 #>     aic   bic r2.nagelkerke  rmse  nobs     F logLik    #>   <dbl> <dbl>         <dbl> <dbl> <int> <dbl> <logLik>  #> 1  113.  120.         0.672 0.437    32 0.737 -51.50168  summary(mm) #>  #>  Term Value  Mean   Pr(>|z|) 2.5 % 97.5 % #>   cyl     4 3.827 2.3369e-08 2.389  6.128 #>   cyl     6 3.897 1.5730e-12 2.673  5.683 #>   cyl     8 3.593 2.6621e-06 2.107  6.128 #>    am     0 3.272 3.9557e-15 2.434  4.397 #>    vs     0 3.795 1.8821e-12 2.618  5.500 #>    am     1 4.344 < 2.22e-16 3.141  6.008 #>    vs     1 3.745 5.8208e-10 2.466  5.687 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Results averaged over levels of: cyl, vs, am  #> Columns: type, term, value, estimate, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"case-study-multinomial-logit","dir":"Articles","previous_headings":"","what":"Case study: Multinomial Logit","title":"Marginal Means","text":"example requires version 0.2.0 marginaleffects package. begin, generate data estimate large model: Try compute marginal means, realize grid won’t fit memory: Use variables variables_grid arguments compute marginal means reasonably sized grid:","code":"library(nnet) library(marginaleffects)  set.seed(1839) n <- 1200 x <- factor(sample(letters[1:3], n, TRUE)) y <- vector(length = n) y[x == \"a\"] <- sample(letters[4:6], sum(x == \"a\"), TRUE) y[x == \"b\"] <- sample(letters[4:6], sum(x == \"b\"), TRUE, c(1 / 4, 2 / 4, 1 / 4)) y[x == \"c\"] <- sample(letters[4:6], sum(x == \"c\"), TRUE, c(1 / 5, 3 / 5, 2 / 5))  dat <- data.frame(x = x, y = factor(y)) tmp <- as.data.frame(replicate(20, factor(sample(letters[7:9], n, TRUE)))) dat <- cbind(dat, tmp) void <- capture.output({     mod <- multinom(y ~ ., dat) }) marginal_means(mod, type = \"probs\") #> Error: You are trying to create a prediction grid with more than 1 billion rows, which is likely to exceed the memory and computational power available on your local machine. Presumably this is because you are considering many variables with many levels. All of the functions in the `marginaleffects` package include arguments to specify a restricted list of variables over which to create a prediction grid. marginal_means(mod,               type = \"probs\",               variables = c(\"x\", \"V1\"),               variables_grid = paste0(\"V\", 2:3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"plot-conditional-marginal-means","dir":"Articles","previous_headings":"","what":"Plot conditional marginal means","title":"Marginal Means","text":"marginaleffects package offers several functions plot quantities vary function others: plot_predictions: Conditional adjusted predictions – predicted outcome change function regressors? plot_comparisons: Conditional comparisons – contrasts change function regressors? plot_slopes: Conditional marginal effects – slope change function regressors? analogous function marginal means. However, easy achieve similar effect using predictions() function, argument, standard plotting functions. example , take steps: Estimate model one continuous (hp) one categorical regressor (cyl). Create perfectly “balanced” data grid combination hp cyl. specified user datagrid() call. Compute fitted values (aka “adjusted predictions”) cell grid. Use argument take average predicted values value hp, across margins cyl. Compute standard errors around averaged predicted values (.e., marginal means). Create symmetric confidence intervals usual manner. Plot results.","code":"library(ggplot2)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  p <- predictions(mod,     by = \"hp\",     newdata = datagrid(         model = mod,         hp = seq(100, 120, length.out = 10),         cyl = mtcars$cyl))  ggplot(p) +     geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +     geom_line(aes(hp, estimate))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/mlogit.html","id":"nnet-package","dir":"Articles","previous_headings":"","what":"nnet package","title":"Multinomial Logit and Discrete Choice Models","text":"multinom function nnet package allows users fit log-linear models via neural networks. data used function data frame one observation per row, response variable coded factor. marginaleffects package function work seamlessly model. example, can estimate model compute average marginal effects follows: Notice models, get one marginal effect term, level response variable. reason, use \"group\" condition argument (facet_*() function) calling one plotting functions:","code":"library(nnet)  head(mtcars) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1  mod <- multinom(factor(gear) ~ hp + mpg, data = mtcars, trace = FALSE)  avg_slopes(mod, type = \"probs\") #>  #>  Group Term   Estimate Std. Error        z   Pr(>|z|)     2.5 %     97.5 % #>      3   hp -3.438e-05   0.002253 -0.01526 0.98782440 -0.004450  0.0043815 #>      3  mpg -7.131e-02   0.026441 -2.69703 0.00699606 -0.123134 -0.0194886 #>      4   hp -4.667e-03   0.002199 -2.12294 0.03375920 -0.008976 -0.0003583 #>      4  mpg  1.591e-02   0.020003  0.79525 0.42646997 -0.023298  0.0551125 #>      5   hp  4.702e-03   0.001304  3.60439 0.00031289  0.002145  0.0072584 #>      5  mpg  5.540e-02   0.016469  3.36416 0.00076776  0.023126  0.0876827 #>  #> Prediction type:  probs  #> Columns: type, group, term, estimate, std.error, statistic, p.value, conf.low, conf.high library(ggplot2)  plot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\") plot_predictions(mod, condition = \"mpg\", type = \"probs\") + facet_wrap(~group) plot_comparisons(     mod,     effect = list(mpg = c(15, 30)),     condition = \"group\",     type = \"probs\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/mlogit.html","id":"mlogit-package","dir":"Articles","previous_headings":"","what":"mlogit package","title":"Multinomial Logit and Discrete Choice Models","text":"mlogit package uses data slightly different structure, one row per observation-choice combination. example, data choice travel mode includes 4 rows per individual, one mode transportation: Note slopes function always return estimates zero regressors vertical bar formula. predict() function supplied mlogit package produce different predictions different values variables. compute different kinds marginal effects, can construct customized data frames feed newdata argument slopes function. Important: newdata argument mlogit models must “balanced” data frame, , must number rows multiple number choices. want compute slope response function (marginal effects) predictors fixed global mean, can : want compute marginal effects gcost wait fixed mean value, conditional choice transportation mode: can also explore complex alternatives. , example, one alternative affected cost reduction:","code":"library(\"AER\") library(\"mlogit\") library(tidyverse) data(\"TravelMode\", package = \"AER\")  head(TravelMode) #>   individual  mode choice wait vcost travel gcost income size #> 1          1   air     no   69    59    100    70     35    1 #> 2          1 train     no   34    31    372    71     35    1 #> 3          1   bus     no   35    25    417    70     35    1 #> 4          1   car    yes    0    10    180    30     35    1 #> 5          2   air     no   64    58     68    68     30    2 #> 6          2 train     no   44    31    354    84     30    2  mod <- mlogit(choice ~ wait + gcost | income + size, TravelMode)  avg_slopes(mod, variables = c(\"income\", \"size\")) #>  #>  Group   Term   Estimate Std. Error       z   Pr(>|z|)      2.5 %    97.5 % #>    air income  0.0027855   0.001218  2.2876   0.022159  0.0003990  0.005172 #>    bus income -0.0003721   0.001103 -0.3374   0.735811 -0.0025337  0.001790 #>    car income  0.0033731   0.001373  2.4559   0.014052  0.0006812  0.006065 #>  train income -0.0057865   0.001319 -4.3861 1.1540e-05 -0.0083723 -0.003201 #>    air   size -0.1264647   0.028918 -4.3732 1.2245e-05 -0.1831434 -0.069786 #>    bus   size  0.0113450   0.025867  0.4386   0.660962 -0.0393539  0.062044 #>    car   size  0.0458798   0.024755  1.8534   0.063830 -0.0026388  0.094398 #>  train   size  0.0692398   0.024785  2.7936   0.005212  0.0206624  0.117817 #>  #> Prediction type:  response  #> Columns: type, group, term, estimate, std.error, statistic, p.value, conf.low, conf.high nd <- TravelMode |>     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"),               function(x) rep(mean(x), 4))) nd #>       wait    gcost   income     size #> 1 34.58929 110.8798 34.54762 1.742857 #> 2 34.58929 110.8798 34.54762 1.742857 #> 3 34.58929 110.8798 34.54762 1.742857 #> 4 34.58929 110.8798 34.54762 1.742857  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term   Estimate Std. Error      z  Pr(>|z|)      2.5 %     97.5 % #>    air income  6.656e-03  2.426e-03  2.743 0.0060816  1.901e-03  0.0114108 #>    bus income -1.141e-03  9.454e-04 -1.207 0.2273591 -2.994e-03  0.0007117 #>    car income  6.480e-06  2.032e-05  0.319 0.7497346 -3.334e-05  0.0000463 #>  train income -5.521e-03  1.910e-03 -2.890 0.0038527 -9.265e-03 -0.0017767 #>    air   size -1.694e-01  5.877e-02 -2.883 0.0039386 -2.846e-01 -0.0542485 #>    bus   size  4.672e-02  2.723e-02  1.716 0.0862434 -6.656e-03  0.1000991 #>    car   size  1.358e-03  8.808e-04  1.542 0.1230361 -3.680e-04  0.0030845 #>  train   size  1.214e-01  4.447e-02  2.729 0.0063528  3.420e-02  0.2085119 #>  #> Prediction type:  response  #> Columns: type, group, term, estimate, std.error, statistic, p.value, conf.low, conf.high nd <- TravelMode |>     group_by(mode) |>     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"), mean)) nd #> # A tibble: 4 × 5 #>   mode   wait gcost income  size #>   <fct> <dbl> <dbl>  <dbl> <dbl> #> 1 air    61.0 103.    34.5  1.74 #> 2 train  35.7 130.    34.5  1.74 #> 3 bus    41.7 115.    34.5  1.74 #> 4 car     0    95.4   34.5  1.74  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term   Estimate Std. Error       z   Pr(>|z|)      2.5 %    97.5 % #>    air income  0.0060149   0.002332  2.5793  0.0098996  0.0014443  0.010586 #>    bus income -0.0007128   0.001461 -0.4878  0.6256800 -0.0035768  0.002151 #>    car income  0.0054450   0.002288  2.3800  0.0173140  0.0009609  0.009929 #>  train income -0.0107471   0.002563 -4.1925 2.7592e-05 -0.0157713 -0.005723 #>    air   size -0.2329273   0.056622 -4.1137 3.8936e-05 -0.3439050 -0.121950 #>    bus   size  0.0204397   0.034364  0.5948  0.5519797 -0.0469129  0.087792 #>    car   size  0.0678200   0.041226  1.6451  0.0999517 -0.0129810  0.148621 #>  train   size  0.1446676   0.047752  3.0295  0.0024493  0.0510747  0.238261 #>  #> Prediction type:  response  #> Columns: type, group, term, estimate, std.error, statistic, p.value, conf.low, conf.high nd <- datagrid(mode = TravelMode$mode, newdata = TravelMode) nd <- lapply(1:4, function(i) mutate(nd, gcost = ifelse(1:4 == i, 30, gcost))) nd <- bind_rows(nd) nd #>    individual choice wait vcost travel gcost income size  mode #> 1           1     no   35    48    486    30     35    2   air #> 2           1     no   35    48    486   111     35    2 train #> 3           1     no   35    48    486   111     35    2   bus #> 4           1     no   35    48    486   111     35    2   car #> 5           1     no   35    48    486   111     35    2   air #> 6           1     no   35    48    486    30     35    2 train #> 7           1     no   35    48    486   111     35    2   bus #> 8           1     no   35    48    486   111     35    2   car #> 9           1     no   35    48    486   111     35    2   air #> 10          1     no   35    48    486   111     35    2 train #> 11          1     no   35    48    486    30     35    2   bus #> 12          1     no   35    48    486   111     35    2   car #> 13          1     no   35    48    486   111     35    2   air #> 14          1     no   35    48    486   111     35    2 train #> 15          1     no   35    48    486   111     35    2   bus #> 16          1     no   35    48    486    30     35    2   car  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term   Estimate Std. Error       z   Pr(>|z|)      2.5 %     97.5 % #>    air income  8.240e-03  2.463e-03  3.3454 0.00082164  0.0034123  0.0130668 #>    bus income -1.328e-03  1.304e-03 -1.0183 0.30853209 -0.0038827  0.0012276 #>    car income  2.659e-05  4.321e-05  0.6154 0.53832121 -0.0000581  0.0001113 #>  train income -6.939e-03  1.860e-03 -3.7298 0.00019166 -0.0105848 -0.0032924 #>    air   size -2.124e-01  6.027e-02 -3.5247 0.00042400 -0.3305707 -0.0943084 #>    bus   size  6.062e-02  3.791e-02  1.5993 0.10974996 -0.0136709  0.1349205 #>    car   size  2.378e-03  1.571e-03  1.5130 0.13028300 -0.0007024  0.0054575 #>  train   size  1.494e-01  4.286e-02  3.4870 0.00048852  0.0654413  0.2334331 #>  #> Prediction type:  response  #> Columns: type, group, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"linear-regression-with-mice","dir":"Articles","previous_headings":"","what":"Linear Regression with mice","title":"Multiple Imputation","text":"Let’s first set data. next steps use mice create imputed data sets. , asking m = 20 imputations. Importantly, mice creates multiple imputation, creates list data sets. , dat_mice 20 nearly identical versions data list missing values imputed. work list data sets, ’ll create function (case called fit_reg) fits model computes marginal effects. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. can compare model looked like without missing data. estimates similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"library(mice) library(marginaleffects) library(modelsummary)  dat <- mtcars dat$am[c(2, 5, 9, 12)] <- NA dat$mpg[c(3, 1, 8, 16)] <- NA dat$hp[c(1, 10, 13, 18)] <- NA dat_mice <- mice(dat, m = 20, printFlag = FALSE, .Random.seed = 1024) dat_mice <- complete(dat_mice, \"all\") fit_reg <- function(dat) {     mod <- lm(mpg ~ hp, data = dat)     out <- slopes(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term    contrast    estimate  std.error statistic       df      p.value #> 1   hp mean(dY/dX) -0.06543494 0.01133922 -5.770672 7633.486 8.204392e-09 mod_missing <- lm(mpg ~ hp, data = dat) mod_missing <- slopes(mod_missing) mod_complete <- lm(mpg ~ hp, data = mtcars) mod_complete <- slopes(mod_complete)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"categories-and-contrasts-problem-and-solution","dir":"Articles","previous_headings":"","what":"Categories and Contrasts: Problem and Solution","title":"Multiple Imputation","text":"One particular problem arises cases contrasts categorical predictors. see , notice contrasts categorical predictors, tidy() method marginaleffects identifies unique estimates using two columns called term contrast: poses problems mice::pool function merges estimates based term column. means original procedure erroneously combine different contrast levels. example: One hack work around limitation assign custom class object create custom tidy method combines term contrast columns:","code":"mod <- lm(mpg ~ factor(cyl), data = dat) mfx <- slopes(mod) tidy(mfx) #> # A tibble: 2 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response cyl   mean(6) - mea…   -7.81    1.67   -4.67 2.96e- 6   -11.1   -4.54 #> 2 response cyl   mean(8) - mea…  -11.9     1.38   -8.64 5.55e-18   -14.6   -9.19 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high fit_reg <- function(dat) {     mod <- lm(mpg ~ factor(cyl), data = dat)     out <- slopes(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term          contrast   estimate std.error statistic       df      p.value #> 1  cyl mean(6) - mean(4)  -6.859481  1.729414 -3.966361 1911.708 7.566877e-05 #> 2  cyl mean(8) - mean(4) -11.384123  1.418551 -8.025178 3796.619 1.339264e-15 fit_reg <- function(dat) {     mod <- lm(mpg ~ factor(cyl), data = dat)     out <- slopes(mod, newdata = dat)     # the next line assigns a custom class     class(out) <- c(\"custom\", class(out))     return(out) }  # this custom method will be called automatically for all objects produced by fit_reg() tidy.custom <- function(x, ...) {     out <- marginaleffects:::tidy.slopes(x, ...)     out$term <- paste(out$term, out$contrast)     return(out) }  mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>                    term          contrast   estimate std.error statistic #> 1 cyl mean(6) - mean(4) mean(6) - mean(4)  -6.859481  1.729414 -3.966361 #> 2 cyl mean(8) - mean(4) mean(8) - mean(4) -11.384123  1.418551 -8.025178 #>         df      p.value #> 1 1911.708 7.566877e-05 #> 2 3796.619 1.339264e-15"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"logistic-regression-with-mice","dir":"Articles","previous_headings":"","what":"Logistic Regression with mice","title":"Multiple Imputation","text":"logistic regression, ’ll work dat_mice imputed data sets. ’ll update function run logistic regression want call fit_logistic. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. , can compare model looked like without missing data. estimates, , similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"fit_logistic <- function(dat) {     mod <- glm(am ~ mpg, data = dat, family = binomial)     out <- slopes(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_logistic) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term    contrast  estimate   std.error statistic       df      p.value #> 1  mpg mean(dY/dX) 0.0488378 0.009940313  4.913105 541.7302 1.189228e-06 mod_missing <- glm(am ~ mpg, data = dat, family = binomial) mod_complete <- glm(am ~ mpg, data = mtcars, family = binomial) mod_missing <- slopes(mod_missing) mod_complete <- slopes(mod_complete)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"multilevel-modeling-with-lme4","dir":"Articles","previous_headings":"","what":"Multilevel Modeling with lme4","title":"Multiple Imputation","text":"last example use data lme4 known sleepstudy. Let’s first set data. randomly create missing outcome variable known Reaction. , next steps use mice create imputed data sets. work list data sets, ’ll create function (case called fit_reg) fits model computes marginal effects. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. Like previous models, can compare model looked like without missing data. estimates similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"library(lme4) data(\"sleepstudy\")  set.seed(1234)  dat2 <- sleepstudy dat2$Reaction[sample(1:180, 10)] <- NA dat_mice2 <- mice(dat2, m = 20, printFlag = FALSE, .Random.seed = 1024) dat_mice2 <- complete(dat_mice2, \"all\") fit_mlm <- function(dat) {     mod <- lmer(Reaction ~ Days + (1 + Days|Subject), data = dat)     out <- slopes(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice2, fit_mlm) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term    contrast estimate std.error statistic       df      p.value #> 1 Days mean(dY/dX) 10.25971  1.563251  6.563063 172.3149 5.950207e-10 mod_complete <- lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) mod_missing <- lmer(Reaction ~ Days + (1 + Days|Subject), data = dat2) mod_complete <- slopes(mod_complete) mod_missing <- slopes(mod_missing)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/performance.html","id":"what-to-do-when-marginaleffects-is-slow","dir":"Articles","previous_headings":"","what":"What to do when marginaleffects is slow?","title":"Performance","text":"options: Compute marginal effects contrasts mean (representative value) instead observed rows original dataset: Use newdata argument datagrid() function. Compute marginal effects subset variables, paying special attention exclude factor variables can particularly costly process: Use variables argument. compute standard errors: Use vcov = FALSE argument. simulation illustrates computation time varies model 25 regressors 100,000 observations: benchmarks conducted using development version marginaleffects 2022-04-15.","code":"library(marginaleffects)  # simulate data and fit a large model N <- 1e5 dat <- data.frame(matrix(rnorm(N * 26), ncol = 26)) mod <- lm(X1 ~ ., dat)  results <- bench::mark(     # marginal effects at the mean; no standard error     slopes(mod, vcov = FALSE, newdata = \"mean\"),     # marginal effects at the mean     slopes(mod, newdata = datagrid()),     # 1 variable; no standard error     slopes(mod, vcov = FALSE, variables = \"X3\"),     # 1 variable     slopes(mod, variables = \"X3\"),     # 26 variables; no standard error     slopes(mod, vcov = FALSE),     # 26 variables     slopes(mod),     iterations = 1, check = FALSE)  results[, c(1, 3, 5)] #   <bch:expr>                                               <bch:tm> <bch:byt> # 1 slopes(mod, vcov = FALSE, newdata = \"mean\") 141.04ms  233.94MB # 2 slopes(mod, newdata = \"mean\")               276.61ms  236.18MB # 3 slopes(mod, vcov = FALSE, variables = \"X3\")     193.81ms  385.33MB # 4 slopes(mod, variables = \"X3\")                      2.85s    3.14GB # 5 slopes(mod, vcov = FALSE)                          4.32s    7.62GB # 6 slopes(mod)                                        1.15m   76.55GB"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/performance.html","id":"speed-comparison","dir":"Articles","previous_headings":"","what":"Speed comparison","title":"Performance","text":"slopes functions relatively fast. simulation conducted using development version package 2022-04-04: marginaleffects 6x faster margins unit-level standard errors computed: marginaleffects can nearly 600x times faster margins unit-level standard errors computed: Models estimated larger datasets (> 1000 observations) can difficult process using margins package, memory time constraints. contrast, marginaleffects can work well much larger datasets. cases, marginaleffects considerably slower packages like emmeans modmarg. packages make extensive use hard-coded analytical derivatives, reimplement fast prediction functions.","code":"library(margins)  N <- 1e3 dat <- data.frame(     y = sample(0:1, N, replace = TRUE),     x1 = rnorm(N),     x2 = rnorm(N),     x3 = rnorm(N),     x4 = factor(sample(letters[1:5], N, replace = TRUE))) mod <- glm(y ~ x1 + x2 + x3 + x4, data = dat, family = binomial) results <- bench::mark(     slopes(mod, vcov = FALSE),     margins(mod, unit_ses = FALSE),     check = FALSE, relative = TRUE) results[, c(1, 3, 5)]  #   expression                        median mem_alloc #   <bch:expr>                          <dbl>     <dbl> # 1 slopes(mod, vcov = FALSE)   1         1 # 2 margins(mod, unit_ses = FALSE)       6.15      4.17 results <- bench::mark(     slopes(mod, vcov = TRUE),     margins(mod, unit_ses = TRUE),     check = FALSE, relative = TRUE, iterations = 1) results[, c(1, 3, 5)]  #   expression                        median mem_alloc # 1 slopes(mod, vcov = TRUE)     1        1 # 2 margins(mod, unit_ses = TRUE)       581.      20.5"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"interactions-conditional-adjusted-predictions","dir":"Articles","previous_headings":"","what":"Interactions: Conditional Adjusted Predictions","title":"Plots: Interactions, Predictions, Comparisons, and Slopes","text":"Consider linear model interactions, relationship hp mpg conditional values wt cyl:  can show predicted values mpg different values different predictors:  can include 3rd conditioning variable, specify values want consider, use one several string shortcuts common reference values (“threenum”, “minmax”, “quartile”, etc.):","code":"mod <- lm(mpg ~ hp * wt * factor(cyl), data = mtcars)  plot_predictions(mod, condition = \"hp\") plot_predictions(mod, condition = c(\"hp\", \"cyl\")) plot_predictions(mod, condition = list(hp = 110:120, \"wt\" = \"threenum\")) /  plot_predictions(mod, condition = list(\"hp\", \"wt\" = \"minmax\")) /  plot_predictions(mod, condition = list(\"hp\", \"wt\" = fivenum)) /  plot_predictions(mod, condition = c(\"hp\", \"wt\", \"cyl\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"customizing-plots","dir":"Articles","previous_headings":"","what":"Customizing plots","title":"Plots: Interactions, Predictions, Comparisons, and Slopes","text":"useful feature plotting functions package produce normal ggplot2 objects. can customize heart’s content, using ggplot2 , one many packages designed augment functionalities:  plotting functions work model supported marginaleffects package, can plot output logistic regression model. plot shows probability survival aboard Titanic, different ages different ticket classes:  Thanks Andrew Heiss inspired plot.","code":"library(ggokabeito) library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp * factor(cyl), data = mt)  plot_predictions(mod, condition = c(\"hp\", \"cyl\"), vcov = FALSE) +     geom_point(aes(x = hp, y = mpg, color = factor(cyl)), data = mt) +     geom_rug(aes(x = hp, y = mpg), data = mt) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() +     scale_color_okabe_ito() library(ggdist)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat)  mod <- glm(Survived ~ Age * PClass, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"Age\", \"PClass\")) +     geom_dots(         alpha = .8,         scale = .3,         pch = 18,         data = dat, aes(         x = Age,         y = Survived,         side = ifelse(Survived == 1, \"bottom\", \"top\")))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"fits-and-smooths","dir":"Articles","previous_headings":"","what":"Fits and smooths","title":"Plots: Interactions, Predictions, Comparisons, and Slopes","text":"can compare model predictors fits smoothers using geom_smooth() function ggplot2 package:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) mod <- glm(Survived ~ Age * PClass, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"Age\", \"PClass\")) +     geom_smooth(data = dat, aes(Age, Survived), method = \"lm\", se = FALSE, color = \"black\") +     geom_smooth(data = dat, aes(Age, Survived), se = FALSE, color = \"black\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"extreme-customization","dir":"Articles","previous_headings":"","what":"Extreme customization","title":"Plots: Interactions, Predictions, Comparisons, and Slopes","text":"Designing effective data visualizations requires lot customization specific context data. plotting functions marginaleffects offer powerful way iterate quickly plots models, obviously support features users may want. Thankfully, easy use slopes functions generate datasets can used ggplot2 data visualization tool. Just use draw argument:","code":"p <- plot_predictions(mod, condition = c(\"Age\", \"PClass\"), draw = FALSE) head(p) #>   rowid     type  estimate  std.error statistic      p.value  conf.low #> 1     1 response 0.8717909 0.04858089 17.945140 5.237868e-72 0.7436448 #> 2     2 response 0.7632110 0.06638393 11.496924 1.367008e-30 0.6107369 #> 3     3 response 0.4079623 0.07663813  5.323228 1.019416e-07 0.2700636 #> 4     4 response 0.8594973 0.04914581 17.488719 1.746399e-68 0.7337014 #> 5     5 response 0.7360650 0.06490403 11.340821 8.236762e-30 0.5916568 #> 6     6 response 0.3859279 0.06737162  5.728346 1.014148e-08 0.2647067 #>   conf.high Survived     Age PClass #> 1 0.9409650        0 0.17000    1st #> 2 0.8687919        0 0.17000    2nd #> 3 0.5620556        0 0.17000    3rd #> 4 0.9314231        0 3.12125    1st #> 5 0.8429591        0 3.12125    2nd #> 6 0.5231643        0 3.12125    3rd"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-type-or-scale","dir":"Articles","previous_headings":"","what":"Prediction type (or scale)","title":"Predictions","text":"Using type argument predictions() function can specify “scale” make predictions. refers either scale used estimate model (.e., link scale) interpretable scale (e.g., response scale). example, fitting linear regression model using lm() function, link scale response scale identical. “Adjusted Prediction” computed either scale expressed mean value response variable given values predictor variables. hand, fitting binary logistic regression model using glm() function (uses binomial family logit link ), link scale response scale different: “Adjusted Prediction” computed link scale expressed log odds “successful” response given values predictor variables, whereas “Adjusted Prediction” computed response scale expressed probability response variable equals 1. default value type argument models “response”, means predictions() function compute predicted probabilities (binomial family), Poisson means (poisson family), etc.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-grid","dir":"Articles","previous_headings":"","what":"Prediction grid","title":"Predictions","text":"compute adjusted predictions must first specify values predictors consider: “reference grid.” example, model linear model fitted lm() function relates response variable Happiness predictor variables Age, Gender Income, reference grid data.frame values Age, Gender Income: Age = 40, Gender = Male, Income = 60000. “reference grid” may may correspond actual observations dataset used fit model; example values given match mean values variable, represent specific observed (hypothetical) individual. reference grid can include many different rows want make predictions different combinations predictors. default, predictions() function uses full original dataset reference grid, means compute adjusted predictions individuals observed dataset used fit model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"the-predictions-function","dir":"Articles","previous_headings":"","what":"The predictions() function","title":"Predictions","text":"default, predictions calculates regression-adjusted predicted values every observation original dataset: many cases, limiting, researchers want specify grid “typical” values compute adjusted predictions.","code":"library(marginaleffects)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  pred <- predictions(mod)  head(pred) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     26.41     0.9620 27.46 < 2.22e-16 24.53  28.30 #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     15.92     0.9925 16.04 < 2.22e-16 13.98  17.87 #>     20.16     1.2186 16.54 < 2.22e-16 17.77  22.55 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"adjusted-predictions-at-user-specified-values-aka-adjusted-predictions-at-representative-values-apr","dir":"Articles","previous_headings":"","what":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","title":"Predictions","text":"two main ways select reference grid want compute adjusted predictions. first using variables argument. second newdata argument datagrid() function already introduced marginal effects vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"variables-counterfactual-predictions","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"variables: Counterfactual predictions","title":"Predictions","text":"variables argument handy way create make predictions counterfactual datasets. example, dataset used fit model 32 rows. counterfactual dataset two distinct values hp 64 rows: original rows appears twice, , values specified variables argument:","code":"p <- predictions(mod, variables = list(hp = c(100, 120))) head(p) #>  #>  Estimate Std. Error      z   Pr(>|z|) 2.5 % 97.5 % #>     20.28     1.2378 16.383 < 2.22e-16 17.85  22.70 #>     20.28     1.2378 16.383 < 2.22e-16 17.85  22.70 #>     26.25     0.9856 26.629 < 2.22e-16 24.31  28.18 #>     20.28     1.2378 16.383 < 2.22e-16 17.85  22.70 #>     17.73     1.8812  9.423 < 2.22e-16 14.04  21.41 #>     20.28     1.2378 16.383 < 2.22e-16 17.85  22.70 #>  #> Prediction type:  response  #> Columns: rowid, rowidcf, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, cyl, hp nrow(p) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"newdata-and-datagrid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"newdata and datagrid","title":"Predictions","text":"second strategy construct grids predictors adjusted predictions combine newdata argument datagrid function. Recall function creates “typical” dataset variables means modes, except explicitly define: can also use datagrid function predictions call (omitting model argument): Users can change summary function used summarize type variables using FUN_numeric, FUN_factor, related arguments. example: data.frame produced predictions “tidy”, makes easy manipulate R packages functions: table Adjusted Predictions","code":"datagrid(cyl = c(4, 6, 8), model = mod) #>        mpg       hp cyl #> 1 20.09062 146.6875   4 #> 2 20.09062 146.6875   6 #> 3 20.09062 146.6875   8 predictions(mod, newdata = datagrid()) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>      16.6      1.279 12.98 < 2.22e-16  14.1  19.11 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, cyl  predictions(mod, newdata = datagrid(cyl = c(4, 6, 8))) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % cyl #>     25.12      1.369 18.35 < 2.22e-16 22.44  27.81   4 #>     19.16      1.247 15.36 < 2.22e-16 16.71  21.60   6 #>     16.60      1.279 12.98 < 2.22e-16 14.10  19.11   8 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, cyl m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     21.95      1.288 17.04 < 2.22e-16 19.43  24.48 #>     18.19      1.271 14.31 < 2.22e-16 15.70  20.68 #>     25.55      1.322 19.32 < 2.22e-16 22.96  28.14 #>     21.78      1.541 14.13 < 2.22e-16 18.76  24.81 #>     22.62      2.141 10.56 < 2.22e-16 18.42  26.81 #>     18.85      1.734 10.87 < 2.22e-16 15.45  22.25 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, drat, cyl, am library(kableExtra) library(tidyverse)  predictions(     mod,     newdata = datagrid(cyl = mtcars$cyl, hp = c(100, 110))) |>     select(hp, cyl, estimate) |>     pivot_wider(values_from = estimate, names_from = cyl) |>     kbl(caption = \"A table of Adjusted Predictions\") |>     kable_styling() |>     add_header_above(header = c(\" \" = 1, \"cyl\" = 3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"counterfactual-data-grid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"counterfactual data grid","title":"Predictions","text":"alternative approach construct grids predictors use grid_type = \"counterfactual\" argument value. duplicate whole dataset, different values specified user. example, mtcars dataset 32 rows. command produces new dataset 64 rows, row original dataset duplicated two values variable supplied (0 1): , can use dataset predictions function create interesting visualizations:  graph, dot represents predicted probability vs=1 one observation dataset, counterfactual worlds either 0 1.","code":"mod <- glm(vs ~ hp + am, data = mtcars, family = binomial)  nd <- datagrid(model = mod, am = 0:1, grid_type = \"counterfactual\")  dim(nd) #> [1] 64  4 pred <- predictions(mod, newdata = datagrid(am = 0:1, grid_type = \"counterfactual\")) |>     select(am, estimate, rowidcf) |>     pivot_wider(id_cols = rowidcf,                  names_from = am,                 values_from = estimate)  ggplot(pred, aes(x = `0`, y = `1`)) +     geom_point() +     geom_abline(intercept = 0, slope = 1) +     labs(x = \"Predicted Pr(vs=1), when am = 0\",          y = \"Predicted Pr(vs=1), when am = 1\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"adjusted-prediction-at-the-mean-apm","dir":"Articles","previous_headings":"","what":"Adjusted Prediction at the Mean (APM)","title":"Predictions","text":"analysts may want calculate “Adjusted Prediction Mean,” , predicted outcome regressors held mean (mode). achieve , use datagrid function. default, function produces grid data regressors means modes, need get APM : equivalent calling:","code":"predictions(mod, newdata = \"mean\") #>  #>  Estimate Std. Error      z Pr(>|z|)    2.5 % 97.5 % #>   0.06309    0.08663 0.7283  0.46644 0.003794 0.5435 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, vs, hp, am predictions(mod, newdata = datagrid()) #>  #>  Estimate Std. Error      z Pr(>|z|)    2.5 % 97.5 % #>   0.06309    0.08663 0.7283  0.46644 0.003794 0.5435 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, vs, hp, am"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"average-adjusted-predictions-aap","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions (AAP)","title":"Predictions","text":"“Average Adjusted Prediction” outcome two step process: Create new dataset original regressor values, fixing regressors values interest. Take average predicted values new dataset. can obtain AAPs applying avg_*() functions argument: equivalent :","code":"avg_predictions(mod) #>  #>  Estimate Std. Error    z   Pr(>|z|)  2.5 % 97.5 % #>    0.4375    0.04288 10.2 < 2.22e-16 0.3535 0.5215 #>  #> Prediction type:  response  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high pred <- predictions(mod) mean(pred$estimate) #> [1] 0.4375"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"average-adjusted-predictions-by-group","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions by Group","title":"Predictions","text":"can compute average adjusted predictions different subsets data argument. next example, create “counterfactual” data grid observation dataset repeated twice, different values variable, variables held observed values. also show equivalent results using dplyr:","code":"predictions(mod, by = \"am\") #>  #>  am Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>   1   0.5385    0.08476 6.352 2.1193e-10 0.3723 0.7046 #>   0   0.3684    0.04303 8.562 < 2.22e-16 0.2841 0.4528 #>  #> Prediction type:  response  #> Columns: type, am, estimate, std.error, statistic, p.value, conf.low, conf.high predictions(     mod,     by = \"am\",     newdata = datagridcf(am = 0:1)) #>  #>  am Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>   0   0.5261    0.03303 15.93 < 2.22e-16 0.4614 0.5909 #>   1   0.3302    0.06462  5.11 3.2272e-07 0.2035 0.4568 #>  #> Prediction type:  response  #> Columns: type, am, estimate, std.error, statistic, p.value, conf.low, conf.high  predictions(     mod,     newdata = datagridcf(am = 0:1)) |>     group_by(am) |>     summarize(AAP = mean(estimate)) #> # A tibble: 2 × 2 #>      am   AAP #>   <int> <dbl> #> 1     0 0.526 #> 2     1 0.330"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"multinomial-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Multinomial models","title":"Predictions","text":"One place particularly useful multinomial models different response levels. example, compute average predicted outcome outcome level multinomial logit model. Note response levels identified “group” column. can use custom aggregations supplying data frame argument. columns data frame must present output predictions(), data frame must also include column labels. example, “collapse” response groups: can useful combination hypothesis argument. example, compute difference average adjusted predictions 3 4 response levels, compared 5 response level: can also use complicated aggregations. , compute predicted probability outcome levels value cyl, collapsing “3” “4” outcome levels: can compare different groups using hypothesis argument:","code":"library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head() #>  #>  Group  Estimate Std. Error         z Pr(>|z|)      2.5 %    97.5 % #>      3 3.624e-05  2.002e-03   0.01810 0.985561 -3.889e-03 3.961e-03 #>      3 3.624e-05  2.002e-03   0.01810 0.985561 -3.889e-03 3.961e-03 #>      3 9.348e-08  6.912e-06   0.01352 0.989210 -1.345e-05 1.364e-05 #>      3 4.045e-01  1.965e-01   2.05788 0.039602  1.924e-02 7.897e-01 #>      3 1.000e+00  1.246e-03 802.40563  < 2e-16  9.975e-01 1.002e+00 #>      3 5.183e-01  2.898e-01   1.78858 0.073683 -4.967e-02 1.086e+00 #>  #> Prediction type:  probs  #> Columns: rowid, type, group, estimate, std.error, statistic, p.value, conf.low, conf.high, gear, mpg, am, vs  # average predictions avg_predictions(nom, type = \"probs\", by = \"group\") #>  #>  Group Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 % #>      3   0.4688    0.04043 11.595 < 2.22e-16 0.38952 0.5480 #>      4   0.3750    0.06142  6.106 1.0231e-09 0.25462 0.4954 #>      5   0.1562    0.04624  3.379  0.0007279 0.06561 0.2469 #>  #> Prediction type:  probs  #> Columns: type, group, estimate, std.error, statistic, p.value, conf.low, conf.high by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by) #>  #>  Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 %  By #>    0.4219    0.02312 18.246 < 2.22e-16 0.37656 0.4672 3,4 #>    0.1562    0.04624  3.379  0.0007279 0.06561 0.2469   5 #>  #> Prediction type:  probs  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high, by predictions(nom, type = \"probs\", by = by, hypothesis = \"sequential\") #>  #>     Term Estimate Std. Error     z  Pr(>|z|)   2.5 %  97.5 % #>  5 - 3,4  -0.2656    0.06936 -3.83 0.0001284 -0.4016 -0.1297 #>  #> Prediction type:  probs  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high nom <- multinom(factor(gear) ~ mpg + factor(cyl), data = mtcars, trace = FALSE)  by <- expand.grid(     group = 3:5,     cyl = c(4, 6, 8),     stringsAsFactors = TRUE) |>     # define labels     transform(by = ifelse(         group %in% 3:4,         sprintf(\"3/4 Gears & %s Cylinders\", cyl),         sprintf(\"5 Gears & %s Cylinders\", cyl)))  predictions(nom, by = by) #>  #>  Estimate Std. Error     z   Pr(>|z|)    2.5 % 97.5 %                      By #>    0.4286    0.06607 6.487 8.7561e-11  0.29908 0.5581 3/4 Gears & 6 Cylinders #>    0.4092    0.05798 7.059 1.6778e-12  0.29561 0.5229 3/4 Gears & 4 Cylinders #>    0.4285    0.04584 9.348 < 2.22e-16  0.33868 0.5184 3/4 Gears & 8 Cylinders #>    0.1429    0.13213 1.081    0.27957 -0.11610 0.4018   5 Gears & 6 Cylinders #>    0.1815    0.11595 1.565    0.11748 -0.04574 0.4088   5 Gears & 4 Cylinders #>    0.1429    0.09169 1.559    0.11903 -0.03678 0.3226   5 Gears & 8 Cylinders #>  #> Prediction type:  probs  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high, by predictions(nom, by = by, hypothesis = \"pairwise\") #>  #>                                               Term   Estimate Std. Error          z Pr(>|z|)     2.5 % 97.5 % #>  3/4 Gears & 6 Cylinders - 3/4 Gears & 4 Cylinders  1.932e-02    0.08789  0.2198282 0.826005 -0.152948 0.1916 #>  3/4 Gears & 6 Cylinders - 3/4 Gears & 8 Cylinders  2.839e-05    0.08041  0.0003531 0.999718 -0.157578 0.1576 #>    3/4 Gears & 6 Cylinders - 5 Gears & 6 Cylinders  2.857e-01    0.19820  1.4414783 0.149450 -0.102761 0.6742 #>    3/4 Gears & 6 Cylinders - 5 Gears & 4 Cylinders  2.471e-01    0.13345  1.8512226 0.064138 -0.014512 0.5086 #>    3/4 Gears & 6 Cylinders - 5 Gears & 8 Cylinders  2.856e-01    0.11301  2.5275282 0.011487  0.064141 0.5071 #>  3/4 Gears & 4 Cylinders - 3/4 Gears & 8 Cylinders -1.929e-02    0.07391 -0.2610381 0.794063 -0.164154 0.1256 #>    3/4 Gears & 4 Cylinders - 5 Gears & 6 Cylinders  2.664e-01    0.14429  1.8460694 0.064882 -0.016434 0.5492 #>    3/4 Gears & 4 Cylinders - 5 Gears & 4 Cylinders  2.277e-01    0.17393  1.3093505 0.190416 -0.113158 0.5686 #>    3/4 Gears & 4 Cylinders - 5 Gears & 8 Cylinders  2.663e-01    0.10848  2.4549566 0.014090  0.053697 0.4789 #>    3/4 Gears & 8 Cylinders - 5 Gears & 6 Cylinders  2.857e-01    0.13986  2.0425470 0.041097  0.011550 0.5598 #>    3/4 Gears & 8 Cylinders - 5 Gears & 4 Cylinders  2.470e-01    0.12469  1.9811682 0.047572  0.002644 0.4914 #>    3/4 Gears & 8 Cylinders - 5 Gears & 8 Cylinders  2.856e-01    0.13753  2.0766728 0.037832  0.016051 0.5552 #>      5 Gears & 6 Cylinders - 5 Gears & 4 Cylinders -3.864e-02    0.17579 -0.2198282 0.826005 -0.383183 0.3059 #>      5 Gears & 6 Cylinders - 5 Gears & 8 Cylinders -5.679e-05    0.16083 -0.0003531 0.999718 -0.315269 0.3152 #>      5 Gears & 4 Cylinders - 5 Gears & 8 Cylinders  3.859e-02    0.14782  0.2610381 0.794063 -0.251134 0.3283 #>  #> Prediction type:  probs  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"bayesian-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Bayesian models","title":"Predictions","text":"strategy works bayesian models: results show median posterior distribution group-wise means. Note take mean predicted values MCMC draw computing quantiles. equivalent :","code":"library(brms) mod <- brm(am ~ mpg * vs, data = mtcars, family = bernoulli) predictions(mod, by = \"vs\") #>  #>  vs Estimate  2.5 % 97.5 % #>   0   0.3272 0.1824 0.5072 #>   1   0.4993 0.3658 0.6721 #>  #> Prediction type:  response  #> Columns: type, vs, estimate, conf.low, conf.high draws <- posterior_epred(mod) quantile(rowMeans(draws[, mtcars$vs == 0]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.3271836 0.1824479 0.5072074 quantile(rowMeans(draws[, mtcars$vs == 1]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.4993250 0.3657956 0.6721267"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"conditional-adjusted-predictions-plot","dir":"Articles","previous_headings":"","what":"Conditional Adjusted Predictions (Plot)","title":"Predictions","text":"First, download ggplot2movies dataset RDatasets archive. , create variable called certified_fresh movies rating least 8. Finally, discard outliers fit logistic regression model: can plot adjusted predictions, conditional length variable using plot_predictions function:  can also introduce another condition display categorical variable like style different colors. can useful models interactions:  Since output plot_predictions() ggplot2 object, easy customize. example, can add points actual observations dataset like :  can also use plot_predictions() models multinomial outcomes grouped coefficients. example, notice call draw=FALSE, result includes group column: Now use group column:","code":"library(tidyverse) dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\") |>     mutate(style = case_when(Action == 1 ~ \"Action\",                              Comedy == 1 ~ \"Comedy\",                              Drama == 1 ~ \"Drama\",                              TRUE ~ \"Other\"),            style = factor(style),            certified_fresh = rating >= 8) |>     dplyr::filter(length < 240)  mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial) mod <- glm(certified_fresh ~ length, data = dat, family = binomial)  plot_predictions(mod, condition = \"length\") mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"length\", \"style\")) library(ggplot2) library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp, data = mt)  plot_predictions(mod, condition = \"hp\") +     geom_point(aes(x = hp, y = mpg), data = mt) +     geom_rug(aes(x = hp, y = mpg), data = mt) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() library(MASS) library(ggplot2)  mod <- nnet::multinom(factor(gear) ~ mpg, data = mtcars, trace = FALSE)  p <- plot_predictions(     mod,     type = \"probs\",     condition = \"mpg\",     draw = FALSE)  head(p) #>   rowid  type group  estimate  std.error statistic       p.value  conf.low conf.high gear      mpg #> 1     1 probs     3 0.9714990 0.03871641 25.092693 5.976078e-139 0.8956163  1.047382    3 10.40000 #> 2     2 probs     3 0.9583559 0.04985914 19.221268  2.456932e-82 0.8606338  1.056078    3 11.37917 #> 3     3 probs     3 0.9393514 0.06291986 14.929330  2.123901e-50 0.8160307  1.062672    3 12.35833 #> 4     4 probs     3 0.9122105 0.07727155 11.805256  3.666725e-32 0.7607610  1.063660    3 13.33750 #> 5     5 probs     3 0.8741884 0.09157738  9.545900  1.349314e-21 0.6947001  1.053677    3 14.31667 #> 6     6 probs     3 0.8224163 0.10383644  7.920305  2.369279e-15 0.6189006  1.025932    3 15.29583 plot_predictions(     mod,     type = \"probs\",     condition = \"mpg\") +     facet_wrap(~group)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Predictions","text":"predictions function computes model-adjusted means scale output predict(model) function. default, predict produces predictions \"response\" scale, adjusted predictions interpreted scale. However, users can pass string type argument, predictions consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation. can also plot predictions different outcome scales:","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) pred <- predictions(mod, type = \"response\") head(pred) #>  #>  Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>    0.4611    0.11584 3.980 6.8786e-05 0.2555 0.6809 #>    0.4611    0.11584 3.980 6.8786e-05 0.2555 0.6809 #>    0.5979    0.13240 4.516 6.3045e-06 0.3357 0.8140 #>    0.4917    0.11961 4.111 3.9406e-05 0.2747 0.7120 #>    0.2969    0.10052 2.954  0.0031403 0.1411 0.5204 #>    0.2599    0.09783 2.657  0.0078821 0.1148 0.4876 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, am, mpg  pred <- predictions(mod, type = \"link\") head(pred) #>  #>  Estimate Std. Error        z Pr(>|z|)   2.5 %   97.5 % #>  -0.15593     0.4662 -0.33449 0.738008 -1.0696  0.75777 #>  -0.15593     0.4662 -0.33449 0.738008 -1.0696  0.75777 #>   0.39672     0.5507  0.72038 0.471292 -0.6826  1.47608 #>  -0.03312     0.4786 -0.06921 0.944821 -0.9711  0.90488 #>  -0.86210     0.4815 -1.79034 0.073400 -1.8059  0.08168 #>  -1.04632     0.5085 -2.05749 0.039639 -2.0430 -0.04960 #>  #> Prediction type:  link  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, am, mpg plot_predictions(mod, condition = \"mpg\", type = \"response\") plot_predictions(mod, condition = \"mpg\", type = \"link\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/python.html","id":"fitting-a-numpyro-model","dir":"Articles","previous_headings":"","what":"Fitting a NumPyro model","title":"Python with `marginaleffects` and `reticulate`","text":"begin, load reticulate package allows us interact Python interpreter R session. , write NumPyro model load memory using source_python() function. important functions note Python code : load_df() downloads data pulmonary fibrosis. model() defines NumPyro model. fit_mcmc_model() fits model using Markov Chain Monte Carlo. predict_mcmc(): accepts data frame returns matrix draws posterior distribution adjusted predictions (fitted values).","code":"library(reticulate) library(marginaleffects)  model <- ' # Model code adapted from the NumPyro documtation under Apache License: # https://num.pyro.ai/en/latest/tutorials/bayesian_hierarchical_linear_regression.html  import pandas as pd import numpy as np import numpyro from numpyro.infer import SVI, Predictive, MCMC,NUTS, autoguide, TraceMeanField_ELBO import numpyro.distributions as dist from numpyro.infer.initialization import init_to_median, init_to_uniform,init_to_sample from jax import random from sklearn.preprocessing import LabelEncoder import pickle  def load_df():     train = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/osic_pulmonary_fibrosis.csv\")     return train   def model(data, predict = False):     FVC_obs = data[\"FVC\"].values  if predict == False else None     patient_encoder = LabelEncoder()     Age_obs = data[\"Age\"].values     patient_code = patient_encoder.fit_transform(data[\"Patient\"].values)     μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))     σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))      age = numpyro.sample(\"age\", dist.Normal(0.0, 500.0))      n_patients = len(np.unique(patient_code))      with numpyro.plate(\"plate_i\", n_patients):         α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))      σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))     FVC_est = α[patient_code] + age * Age_obs      with numpyro.plate(\"data\", len(patient_code)):         numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)   def fit_mcmc_model(train_df, samples = 1000):     numpyro.set_host_device_count(4)     rng_key = random.PRNGKey(0)     mcmc = MCMC(         NUTS(model),         num_samples=samples,         num_warmup=1000,         progress_bar=True,         num_chains = 4         )          mcmc.run(rng_key, train_df)      posterior_draws = mcmc.get_samples()      with open(\"mcmc_posterior_draws.pickle\", \"wb\") as handle:         pickle.dump(posterior_draws, handle, protocol=pickle.HIGHEST_PROTOCOL)  def predict_mcmc(data):      with open(\"mcmc_posterior_draws.pickle\", \"rb\") as handle:         posterior_draws = pickle.load(handle)      predictive = Predictive(model = model,posterior_samples=posterior_draws)     samples = predictive(random.PRNGKey(1), data, predict = True)     y_pred = samples[\"obs\"]     # transpose so that each column is a draw and each row is an observation     y_pred = np.transpose(np.array(y_pred))      return y_pred  '  # save python script to temp file tmp <- tempfile() cat(model, file = tmp)  # load functions source_python(tmp)  # download data df <- load_df()  # fit model fit_mcmc_model(df)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/python.html","id":"analyzing-the-results-in-marginaleffects","dir":"Articles","previous_headings":"","what":"Analyzing the results in marginaleffects","title":"Python with `marginaleffects` and `reticulate`","text":"functions marginaleffects package requires users supply model object function operate. estimating models outside R, model object. thus begin creating “fake” model object: empty data frame define class “custom”. , set global option tell marginaleffects “custom” class supported. Next, define get_predict method new custom class. method must accept three arguments: model, newdata, .... get_predict method must return data frame one row rows newdata, two columns (rowid estimate), attribute called posterior_draws hosts matrix posterior draws number rows newdata. method uses reticulate call predict_mcmc() function defined Python script . predict_mcmc() function accepts data frame returns matrix number rows. Now can use marginaleffects package functions analyze results. Since use “fake” model object, marginaleffects retrieve original data model object, always need supply newdata argument:","code":"mod <- data.frame() class(mod) <- \"custom\"  options(\"marginaleffects_model_classes\" = \"custom\") get_predict.custom <- function(model, newdata, ...) {     pred <- predict_mcmc(newdata)     out <- data.frame(         rowid = seq_len(nrow(newdata)),         predicted = apply(pred, 1, stats::median)     )     attr(out, \"posterior_draws\") <- pred     return(out) } # predictions on the original dataset predictions(mod, newdata = df) |> head()  # predictions for user-defined predictor values predictions(mod, newdata = datagrid(newdata = df, Age = c(60, 70)))  predictions(mod, newdata = datagrid(newdata = df, Age = range))  # average predictions by group predictions(mod, newdata = df, by = \"Sex\")  # contrasts (average) avg_comparisons(mod, variables = \"Age\", newdata = df)  avg_comparisons(mod, variables = list(\"Age\" = \"sd\"), newdata = df)  # slope (elasticity) avg_slopes(mod, variables = \"Age\", slope = \"eyex\", newdata = df)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"definition","dir":"Articles","previous_headings":"","what":"Definition","title":"Slopes","text":"Slopes defined : Partial derivatives regression equation respect regressor interest. .k.. Marginal effects, trends. vignette follows econometrics tradition referring “slopes” “marginal effects” interchangeably. context, word “marginal” refers idea “small change,” calculus sense. marginal effect measures association change regressor \\(x\\), change response \\(y\\). Put differently, differently, marginal effect slope prediction function, measured specific value regressor \\(x\\). Marginal effects extremely useful, intuitive easy interpret. often main quantity interest empirical analysis. scientific practice, “Marginal Effect” falls toolbox “Contrast.” try answer counterfactual question: happen \\(y\\) \\(x\\) different? allow us model “effect” change/difference regressor \\(x\\) response \\(y\\).1 illustrate concept, consider quadratic function: \\[y = -x^2\\] definition , know marginal effect partial derivative \\(y\\) respect \\(x\\): \\[\\frac{\\partial y}{\\partial x} = -2x\\] get intuition interpret quantity, consider response \\(y\\) \\(x\\). looks like :  \\(x\\) increases, \\(y\\) starts increase. , \\(x\\) increases , \\(y\\) creeps back negative territory. marginal effect slope response function certain value \\(x\\). next plot adds three tangent lines, highlighting slopes response function three values \\(x\\). slopes tangents tell us three things: \\(x<0\\), slope positive: increase \\(x\\) associated increase \\(y\\): marginal effect positive. \\(x=0\\), slope null: (small) change \\(x\\) associated change \\(y\\). marginal effect null. \\(x>0\\), slope negative: increase \\(x\\) associated decrease \\(y\\). marginal effect negative.  , show reach conclusions estimation context, simulated data slopes function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"slopes-function","dir":"Articles","previous_headings":"","what":"slopes function","title":"Slopes","text":"marginal effect unit-level measure association changes regressor changes response. Except simplest linear models, value marginal effect different individual individual, depend values covariates individual. slopes function thus produces distinct estimates marginal effect row data used fit model. output marginaleffects simple data.frame, can inspected usual R commands. show , load library, download Palmer Penguins data Rdatasets archive, estimate GLM model:","code":"library(marginaleffects)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") dat$large_penguin <- ifelse(dat$body_mass_g > median(dat$body_mass_g, na.rm = TRUE), 1, 0)  mod <- glm(large_penguin ~ bill_length_mm + flipper_length_mm + species,            data = dat, family = binomial) mfx <- slopes(mod) head(mfx) #>  #>            Term Contrast Estimate Std. Error     z   Pr(>|z|)    2.5 %  97.5 % #>  bill_length_mm    dY/dX  0.01763   0.007841 2.248 0.02455115 0.002262 0.03300 #>  bill_length_mm    dY/dX  0.03586   0.011923 3.008 0.00263339 0.012491 0.05923 #>  bill_length_mm    dY/dX  0.08444   0.021123 3.998 6.3953e-05 0.043044 0.12584 #>  bill_length_mm    dY/dX  0.03473   0.006509 5.336 9.5279e-08 0.021970 0.04748 #>  bill_length_mm    dY/dX  0.05089   0.013414 3.794 0.00014838 0.024599 0.07718 #>  bill_length_mm    dY/dX  0.01652   0.007257 2.276 0.02284980 0.002293 0.03074 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"the-marginal-effects-zoo","dir":"Articles","previous_headings":"","what":"The Marginal Effects Zoo","title":"Slopes","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. ways make information easier digest, computing various quantities interest. characteristically excellent blog post, Professor Andrew Heiss introduces many quantities: Average Marginal Effects Group-Average Marginal Effects Marginal Effects User-Specified Values (Representative Values) Marginal Effects Mean Counterfactual Marginal Effects Conditional Marginal Effects rest vignette defines quantities explains use slopes() plot_slopes() functions compute . main differences quantities pertain () regressor values estimate marginal effects, (b) way unit-level marginal effects aggregated. Heiss drew exceedingly helpful graph summarizes information rest vignette:","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"average-marginal-effect-ame","dir":"Articles","previous_headings":"","what":"Average Marginal Effect (AME)","title":"Slopes","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. Many analysts like report “Average Marginal Effect”, , average observation-specific marginal effects. easy compute based full data.frame shown , avg_slopes() function convenient: Note since marginal effects derivatives, properly defined continuous numeric variables. model also includes categorical regressors, summary function try display relevant (regression-adjusted) contrasts different categories, shown . can also extract average marginal effects using tidy glance methods conform broom package specification:","code":"avg_slopes(mod) #>  #>               Term           Contrast Estimate Std. Error       z   Pr(>|z|)     2.5 %   97.5 % #>     bill_length_mm              dY/dX  0.02757   0.005784  4.7675 1.8653e-06  0.016238  0.03891 #>  flipper_length_mm              dY/dX  0.01058   0.002357  4.4895 7.1390e-06  0.005963  0.01520 #>            species Chinstrap - Adelie -0.41479   0.056900 -7.2898 3.1032e-13 -0.526312 -0.30327 #>            species    Gentoo - Adelie  0.06170   0.106856  0.5774    0.56367 -0.147735  0.27113 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high tidy(mfx) #> # A tibble: 4 × 9 #>   type     term              contrast                       estimate std.error statistic  p.value conf.low conf.high #>   <chr>    <chr>             <chr>                             <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl> #> 1 response bill_length_mm    mean(dY/dX)                      0.0276   0.00578     4.77  1.87e- 6  0.0162     0.0389 #> 2 response flipper_length_mm mean(dY/dX)                      0.0106   0.00236     4.49  7.14e- 6  0.00596    0.0152 #> 3 response species           mean(Chinstrap) - mean(Adelie)  -0.415    0.0569     -7.29  3.10e-13 -0.526     -0.303  #> 4 response species           mean(Gentoo) - mean(Adelie)      0.0617   0.107       0.577 5.64e- 1 -0.148      0.271  glance(mfx) #> # A tibble: 1 × 7 #>     aic   bic r2.tjur  rmse  nobs     F logLik    #>   <dbl> <dbl>   <dbl> <dbl> <int> <dbl> <logLik>  #> 1  180.  199.   0.695 0.276   342  15.7 -84.92257"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"group-average-marginal-effect-g-ame","dir":"Articles","previous_headings":"","what":"Group-Average Marginal Effect (G-AME)","title":"Slopes","text":"can also use argument average marginal effects within different subgroups observed data, based values regressors. example, compute average marginal effects Bill Length Species, : equivalent manually taking mean observation-level marginal effect species sub-group: Note marginaleffects follows Stata margins package computing standard errors using group-wise averaged Jacobian.","code":"avg_slopes(   mod,   by = \"species\",   variables = \"bill_length_mm\") #>  #>            Term    Contrast Estimate Std. Error     z   Pr(>|z|)     2.5 %  97.5 %   species #>  bill_length_mm mean(dY/dX) 0.043540   0.008828 4.932 8.1365e-07  0.026237 0.06084    Adelie #>  bill_length_mm mean(dY/dX) 0.002872   0.002846 1.009 0.31299360 -0.002707 0.00845    Gentoo #>  bill_length_mm mean(dY/dX) 0.036801   0.009801 3.755 0.00017337  0.017592 0.05601 Chinstrap #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, species, predicted, predicted_hi, predicted_lo aggregate(   mfx$estimate,   by = list(mfx$species, mfx$term),   FUN = mean) #>     Group.1           Group.2            x #> 1    Adelie    bill_length_mm  0.043539914 #> 2 Chinstrap    bill_length_mm  0.036801185 #> 3    Gentoo    bill_length_mm  0.002871562 #> 4    Adelie flipper_length_mm  0.016710631 #> 5 Chinstrap flipper_length_mm  0.014124217 #> 6    Gentoo flipper_length_mm  0.001102231 #> 7    Adelie           species -0.054519623 #> 8 Chinstrap           species -0.313337522 #> 9    Gentoo           species -0.250726004"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"marginal-effect-at-user-specified-values","dir":"Articles","previous_headings":"","what":"Marginal Effect at User-Specified Values","title":"Slopes","text":"Sometimes, interested unit-specific marginal effects, rather look estimated marginal effects certain “typical” individuals, user-specified values regressors. datagrid function helps us build data grid full “typical” rows. example, generate artificial Adelies Gentoos 180mm flippers: command can used (omitting model argument) marginaleffects’s newdata argument compute marginal effects (fictional) individuals: variables omitted datagrid call, automatically set mean mode (depending variable type).","code":"datagrid(flipper_length_mm = 180,          species = c(\"Adelie\", \"Gentoo\"),          model = mod) #>   large_penguin bill_length_mm flipper_length_mm species #> 1     0.4853801       43.92193               180  Adelie #> 2     0.4853801       43.92193               180  Gentoo slopes(   mod,   newdata = datagrid(     flipper_length_mm = 180,     species = c(\"Adelie\", \"Gentoo\"))) #>  #>               Term           Contrast Estimate Std. Error       z   Pr(>|z|)     2.5 %    97.5 % flipper_length_mm species #>     bill_length_mm              dY/dX  0.06069   0.033264  1.8245 0.06807114 -0.004505  0.125889               180  Adelie #>     bill_length_mm              dY/dX  0.08467   0.040400  2.0959 0.03609126  0.005492  0.163856               180  Gentoo #>  flipper_length_mm              dY/dX  0.02329   0.005498  4.2367 2.2685e-05  0.012517  0.034069               180  Adelie #>  flipper_length_mm              dY/dX  0.03250   0.008610  3.7745 0.00016034  0.015623  0.049373               180  Gentoo #>            species Chinstrap - Adelie -0.21105   0.103178 -2.0455 0.04080661 -0.413276 -0.008824               180  Adelie #>            species Chinstrap - Adelie -0.21105   0.103178 -2.0455 0.04080661 -0.413276 -0.008824               180  Gentoo #>            species    Gentoo - Adelie  0.15912   0.303473  0.5243 0.60004695 -0.435676  0.753918               180  Adelie #>            species    Gentoo - Adelie  0.15912   0.303473  0.5243 0.60004695 -0.435676  0.753918               180  Gentoo #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"marginal-effect-at-the-mean-mem","dir":"Articles","previous_headings":"","what":"Marginal Effect at the Mean (MEM)","title":"Slopes","text":"“Marginal Effect Mean” marginal effect calculated hypothetical observation regressor set mean mode. default, datagrid function used previous section sets regressors means modes. calculate MEM, can set newdata argument, determines values predictors want compute marginal effects:","code":"slopes(mod, newdata = \"mean\") #>  #>               Term           Contrast Estimate Std. Error        z   Pr(>|z|)     2.5 %   97.5 % #>     bill_length_mm              dY/dX  0.05024    0.01199   4.1910  2.777e-05  0.026744  0.07373 #>  flipper_length_mm              dY/dX  0.01928    0.00556   3.4682 0.00052398  0.008386  0.03018 #>            species Chinstrap - Adelie -0.80704    0.07330 -11.0107 < 2.22e-16 -0.950693 -0.66338 #>            species    Gentoo - Adelie  0.08286    0.11354   0.7297 0.46554593 -0.139685  0.30540 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species, eps"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"","what":"Counterfactual Marginal Effects","title":"Slopes","text":"datagrid function allowed us look completely fictional individuals. Setting grid_type argument function \"counterfactual\" lets us compute marginal effects actual observations dataset, manipulated values. example, code create data.frame twice long original dat, observation repeated different values flipper_length_mm variable: see rows 1, 2, 3 original dataset replicated twice, different values flipper_length_mm variable: can use observation-level marginal effects compute average (median, anything else) marginal effects counterfactual individuals:","code":"nd <- datagrid(flipper_length_mm = c(160, 180),                model = mod,                grid_type = \"counterfactual\") nd[nd$rowid %in% 1:3,] #>     rowidcf large_penguin bill_length_mm species flipper_length_mm #> 1         1             0           39.1  Adelie               160 #> 2         2             0           39.5  Adelie               160 #> 3         3             0           40.3  Adelie               160 #> 343       1             0           39.1  Adelie               180 #> 344       2             0           39.5  Adelie               180 #> 345       3             0           40.3  Adelie               180 library(dplyr)  slopes(mod, newdata = nd) |>     group_by(term) |>     summarize(estimate = median(estimate)) #> # A tibble: 3 × 2 #>   term               estimate #>   <chr>                 <dbl> #> 1 bill_length_mm    0.00985   #> 2 flipper_length_mm 0.00378   #> 3 species           0.0000226"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"conditional-marginal-effects-plot","dir":"Articles","previous_headings":"","what":"Conditional Marginal Effects (Plot)","title":"Slopes","text":"plot_slopes function can used draw “Conditional Marginal Effects.” useful model includes interaction terms want plot marginal effect variable changes value “condition” (“moderator”) variable changes:  marginal effects plot computed values regressors – except effect condition – held means modes, depending variable type. Since plot_slopes() produces ggplot2 object, easy customize. example:","code":"mod <- lm(mpg ~ hp * wt + drat, data = mtcars)  plot_slopes(mod, effect = \"hp\", condition = \"wt\") plot_slopes(mod, effect = \"hp\", condition = \"wt\") +     geom_rug(aes(x = wt), data = mtcars) +     theme_classic()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"example-quadratic","dir":"Articles","previous_headings":"","what":"Example: Quadratic","title":"Slopes","text":"“Definition” section vignette, considered marginal effects can computed analytically simple quadratic equation context. can now use slopes function replicate analysis quadratic function regression application. Say estimate linear regression model quadratic term: \\[Y = \\beta_0 + \\beta_1 X^2 + \\varepsilon\\] obtain estimates \\(\\beta_0=1\\) \\(\\beta_1=2\\). Taking partial derivative respect \\(X\\) plugging estimates gives us marginal effect \\(X\\) \\(Y\\): \\[\\partial Y / \\partial X = \\beta_0 + 2 \\cdot \\beta_1 X\\] \\[\\partial Y / \\partial X = 1 + 4X\\] result suggests effect change \\(X\\) \\(Y\\) depends level \\(X\\). \\(X\\) large positive, increase \\(X\\) associated large increase \\(Y\\). \\(X\\) small positive, increase \\(X\\) associated small increase \\(Y\\). \\(X\\) large negative value, increase \\(X\\) associated decrease \\(Y\\). marginaleffects arrives conclusion simulated data: can plot conditional adjusted predictions plot_predictions function:  can plot conditional marginal effects plot_slopes function (see section ):  , conclusion . \\(x<0\\), increase \\(x\\) associated increase \\(y\\). \\(x=0\\), marginal effect equal 0. \\(x>0\\), increase \\(x\\) associated decrease \\(y\\).","code":"library(tidyverse) N <- 1e5 quad <- data.frame(x = rnorm(N)) quad$y <- 1 + 1 * quad$x + 2 * quad$x^2 + rnorm(N) mod <- lm(y ~ x + I(x^2), quad)  slopes(mod, newdata = datagrid(x = -2:2))  |>     mutate(truth = 1 + 4 * x) |>     select(estimate, truth) #>  #>  Estimate #>    -7.010 #>    -3.005 #>     1.000 #>     5.005 #>     9.010 #>  #> Prediction type:   #> Columns: estimate, truth plot_predictions(mod, condition = \"x\") plot_slopes(mod, effect = \"x\", condition = \"x\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Slopes","text":"marginaleffect function takes derivative fitted (predicted) values model, typically generated predict(model) function. default, predict produces predictions \"response\" scale, marginal effects interpreted scale. However, users can pass string vector strings type argument, marginaleffects consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation.","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) avg_slopes(mod, type = \"response\") #>  #>  Term Estimate Std. Error     z   Pr(>|z|)   2.5 %  97.5 % #>   mpg  0.04649   0.008857 5.249 1.5303e-07 0.02913 0.06385 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  avg_slopes(mod, type = \"link\") #>  #>  Term Estimate Std. Error     z  Pr(>|z|)   2.5 % 97.5 % #>   mpg    0.307     0.1148 2.673 0.0075066 0.08194 0.5321 #>  #> Prediction type:  link  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/supported_models.html","id":"adjusted-predictions-and-marginal-means","dir":"Articles","previous_headings":"","what":"Adjusted predictions and marginal means","title":"Supported Models","text":"hood, marginaleffects’s predictions marginal_means functions use insight package retrieve adjusted predictions wide variety models. Currently, insight supports many model types, work ---box predictions function. run problems, hesitate report Github via email.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/supported_models.html","id":"marginal-effects-and-contrasts","dir":"Articles","previous_headings":"","what":"Marginal effects and contrasts","title":"Supported Models","text":"table shows list 73 model types slopes() function can compute slopes contrasts. three main alternative software packages compute slopes (1) Stata’s margins command, (2) R’s margins::margins function, (3) R’s emmeans::emtrends function. test suite hosted Github compares numerical equivalence results produced marginaleffects produced 3 alternative software packages: ✓: green check means results least one model equal reasonable tolerance. ✖: red cross means results identical; extra caution warranted. U: grey U means computing slopes model type unsupported alternative packages, supported marginaleffects. empty cell means means comparison made yet. eager add support new models. Feel free file request submit code Github.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"marginal-effects","dir":"Articles","previous_headings":"","what":"Marginal effects","title":"Tables","text":"can summarize results comparisons() slopes() functions using modelsummary package. results can visualized modelplot():","code":"library(modelsummary) library(marginaleffects)  mod <- glm(am ~ wt + drat, family = binomial, data = mtcars) mfx <- slopes(mod)  modelsummary(mfx) modelplot(mfx)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"contrasts","dir":"Articles","previous_headings":"","what":"Contrasts","title":"Tables","text":"using comparisons() function (slopes() function categorical variables), output include two columns uniquely identify quantities interest: term contrast. can use group argument modelsummary function structure table properly: Cross-contrasts can bit trickier, since multiple simultaneous groups. Consider example: can see , two relevant grouping columns: contrast_gear contrast_cyl. can simply plug names shape argument:","code":"dat <- mtcars dat$gear <- as.factor(dat$gear) mod <- glm(vs ~ gear + mpg, data = dat, family = binomial)  cmp <- comparisons(mod) get_estimates(cmp) #> # A tibble: 3 × 9 #>   type     term  contrast          estimate std.error statistic    p.value conf.low conf.high #>   <chr>    <chr> <chr>                <dbl>     <dbl>     <dbl>      <dbl>    <dbl>     <dbl> #> 1 response gear  mean(4) - mean(3)   0.0372    0.137      0.272 0.785       -0.230     0.305  #> 2 response gear  mean(5) - mean(3)  -0.340     0.0988    -3.44  0.000588    -0.533    -0.146  #> 3 response mpg   mean(+1)            0.0608    0.0128     4.74  0.00000217   0.0356    0.0860 modelsummary(cmp, group = term + contrast ~ model) mod <- lm(mpg ~ factor(cyl) + factor(gear), data = mtcars) cmp <- comparisons(   mod,   variables = c(\"gear\", \"cyl\"),   cross = TRUE) get_estimates(cmp) #> # A tibble: 4 × 10 #>   type     term  contrast_gear     contrast_cyl      estimate std.error statistic p.value conf.low conf.high #>   <chr>    <chr> <chr>             <chr>                <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl> #> 1 response cross mean(4) - mean(3) mean(6) - mean(4)    -5.33      2.77     -1.93 0.0542     -10.8  0.0953   #> 2 response cross mean(4) - mean(3) mean(8) - mean(4)    -9.22      3.62     -2.55 0.0108     -16.3 -2.13     #> 3 response cross mean(5) - mean(3) mean(6) - mean(4)    -5.16      2.63     -1.96 0.0500     -10.3  0.000166 #> 4 response cross mean(5) - mean(3) mean(8) - mean(4)    -9.04      3.19     -2.84 0.00453    -15.3 -2.80 modelsummary(   cmp,   shape = contrast_gear + contrast_cyl ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal means","title":"Tables","text":"Estimated Marginal Means","code":"library(\"marginaleffects\") library(\"modelsummary\")  dat <- mtcars dat$cyl <- as.factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ hp + cyl + am, data = dat) mm <- marginal_means(mod)  modelsummary(mm,              title = \"Estimated Marginal Means\",              estimate = \"{estimate} ({std.error}){stars}\",              statistic = NULL,              group = term + value ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta Method","title":"Standard Errors and Confidence Intervals","text":"standard errors generated slopes(), comparisons(), hypotheses() functions package package estimated using delta method. Mathematical treatments method can found statistics textbooks Wikipedia. Roughly speaking, delta method allows us approximate distribution smooth function asymptotically normal estimator. Concretely, allows us generate standard errors around functions model’s coefficient estimates. Predictions, contrasts, marginal effects, marginal means functions coefficients, can use delta method estimate standard errors around quantities. Since lot mathematical treatments available elsewhere, vignette focuses “implementation” marginaleffects. Consider case marginal_means() function. user calls function, obtain vector marginal means. estimate standard errors around vector: Compute marginal means original model: \\(f(\\beta)\\) Increment first (first) coefficient held inside model object small amount, compute marginal means : \\(f(\\beta+\\varepsilon)\\) Calculate: \\(\\frac{f(\\beta+\\varepsilon) - f(\\beta)}{\\varepsilon}\\) Repeat step 1 every coefficient model construct \\(J\\) matrix. Extract variance-covariance matrix coefficient estimates: \\(V\\) Standard errors square root diagonal \\(JVJ'\\) main function used compute standard errors marginaleffects : https://github.com/vincentarelbundock/marginaleffects/blob/main/R/get_se_delta.R","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"standard-errors-and-intervals-for-slopes-and-comparisons","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for slopes() and comparisons()","title":"Standard Errors and Confidence Intervals","text":"standard errors slopes() comparisons() functions computed using delta method, described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"standard-errors-and-intervals-for-marginal_means","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for marginal_means()","title":"Standard Errors and Confidence Intervals","text":"marginal_means() function can compute confidence intervals two ways. following conditions hold: user set: type = \"response\" “link” type supported model class transform_post argument NULL marginal_means() first compute marginal means link scale, back transform using inverse link function supplied insight::link_inverse(model) function. cases, standard errors computed using delta method described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"standard-errors-and-intervals-for-predictions","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for predictions()","title":"Standard Errors and Confidence Intervals","text":"marginaleffects package handles calculations compute standard errors, t statistics, p values, confidence intervals contrasts (comparisons()), marginal effects (slopes()), marginal means (marginal_means()) functions. possible, however, calculation standard errors confidence intervals output predictions() outsourced insight package. benefit , many popular models, insight can compute confidence intervals via back-transformation, gives certain nice properties. example, ensures confidence intervals around predictions logistic regression model remain 0 1. insight support model, marginaleffects computes standard errors using delta method, described . cases, confidence intervals created automatically, users can easily compute manually, usual, multiplying standard error critical value. standard errors thus estimated desirable properties normal assumptions, since back-transformation, always advisable use construct symmetric confidence intervals around adjusted predictions. One special case compute average predictions, argument compute average predictions group. cases, may good idea compute predicted values link scale, average predictions, back transform. can done using transform_post transform_post arguments. example, use link_inverse argument insight package get inverse link function: Note simply add 1.96*SE predictions, upper bound confidence interval exceed logical limit 1. Instead, one possibility estimate predicted values link scale, transform results: Warning: order average transform matters, mean transformation always equal transformation mean:","code":"library(insight) library(marginaleffects)  # simulate data set.seed(1024) N <- 25 dat <- data.frame(     y = rbinom(N, 1, prob = .9),     x = rnorm(N),     groupid = rbinom(N, 1, prob = .5))  # estimate model mod <- glm(y ~ x + groupid, family = binomial, data = dat)  # average group-wise predictions predictions(mod, by = \"groupid\") #>  #>  groupid Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>        1   0.8889    0.10283  8.645 < 2.22e-16 0.6874  1.090 #>        0   0.8750    0.07697 11.368 < 2.22e-16 0.7241  1.026 #>  #> Prediction type:  response  #> Columns: type, groupid, estimate, std.error, statistic, p.value, conf.low, conf.high predictions(     mod,     by = \"groupid\",     type = \"link\",     transform_post = link_inverse(mod)) #>  #>  groupid Estimate Pr(>|z|)  2.5 % 97.5 % #>        1   0.9136 0.038094 0.5323 0.9899 #>        0   0.9229 0.024783 0.5781 0.9905 #>  #> Prediction type:  link  #> Post-transformation:  transform_post  #> Columns: type, groupid, estimate, p.value, conf.low, conf.high p <- predictions(     mod,     type = \"link\",     transform_post = link_inverse(mod)) aggregate(y ~ groupid, data = p, FUN = mean) #>   groupid         y #> 1       0 0.8750000 #> 2       1 0.8888889  # simple example x <- rnorm(100) mean(link_inverse(mod)(x)) #> [1] 0.4706487 link_inverse(mod)(mean(x)) #> [1] 0.4665151"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"robust-standard-errors","dir":"Articles","previous_headings":"","what":"Robust standard errors","title":"Standard Errors and Confidence Intervals","text":"functions marginaleffects package can compute robust standard errors fly model type supported sandwich package. vcov argument supports string shortcuts like \"HC3\", one-sided formula request clustered standard errors, variance-covariance matrices, functions return matrices. examples. Adjusted predictions classical heteroskedasticity-robust standard errors: Marginal effects cluster-robust standard errors: Comparing adjusted predictions classical robust standard errors:","code":"library(marginaleffects) library(patchwork) mod <- lm(mpg ~ hp, data = mtcars)  p <- predictions(mod) head(p, 2) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     22.59     0.7773 29.07 < 2.22e-16 21.07  24.12 #>     22.59     0.7773 29.07 < 2.22e-16 21.07  24.12 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp  p <- predictions(mod, vcov = \"HC3\") head(p, 2) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     22.59      0.863 26.18 < 2.22e-16  20.9  24.29 #>     22.59      0.863 26.18 < 2.22e-16  20.9  24.29 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp avg_slopes(mod, vcov = ~cyl) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)   2.5 %   97.5 % #>    hp -0.06823    0.01868 -3.653 0.00025909 -0.1048 -0.03162 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high p1 <- plot_predictions(mod, condition = \"hp\") p2 <- plot_predictions(mod, condition = \"hp\", vcov = \"HC3\") p1 + p2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"simulation-based-inference","dir":"Articles","previous_headings":"","what":"Simulation-based inference","title":"Standard Errors and Confidence Intervals","text":"marginaleffects offers experimental inferences function conduct simulation-based inference following strategy proposed Krinsky & Robb (1986): Draw iter sets simulated coefficients multivariate normal distribution mean equal original model’s estimated coefficients variance equal model’s variance-covariance matrix (classical, “HC3”, ). Use iter sets coefficients compute iter sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error. examples: Since simulation based inference generates iter estimates quantities interest, can treat similarly draws posterior distribution bayesian models. example, can extract draws using posterior_draws() function, plot distributions using packages likeggplot2 ggdist:","code":"library(marginaleffects) library(ggplot2) library(ggdist)  mod <- glm(vs ~ hp * wt + factor(gear), data = mtcars, family = binomial)  mod |> predictions() |> inferences() #>  #>   Estimate Std. Error     2.5 % 97.5 % #>  7.836e-01     0.2011 2.692e-01 0.9732 #>  7.836e-01     0.1687 3.537e-01 0.9628 #>  8.983e-01     0.1459 4.474e-01 0.9896 #>  8.742e-01     0.2182 2.194e-01 0.9961 #>  1.307e-02     0.1949 7.772e-05 0.7696 #> --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  #>  3.828e-01     0.2939 1.796e-02 0.9555 #>  1.211e-06     0.1256 4.108e-12 0.3768 #>  6.887e-03     0.1580 3.430e-05 0.6333 #>  8.071e-11     0.1562 2.220e-16 0.6899 #>  7.953e-01     0.1718 3.552e-01 0.9655  #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, conf.low, conf.high, vs, hp, wt, gear  mod |> avg_slopes(vcov = ~gear) |> inferences() #>  #>  Term Contrast  Estimate Std. Error    2.5 %   97.5 % #>  gear    4 - 3 -0.040453   0.054402 -0.09097 0.130651 #>  gear    5 - 3 -0.182995   0.261857 -0.48634 0.325185 #>    hp    dY/dX -0.004762   0.004451 -0.01158 0.005102 #>    wt    dY/dX  0.016483   0.306082 -0.62666 0.655082 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, conf.low, conf.high mod |>   avg_comparisons(variables = \"gear\") |>   inferences() |>   posterior_draws(\"rvar\") |>   ggplot(aes(y = contrast, xdist = rvar)) +   stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"bootstrap","dir":"Articles","previous_headings":"","what":"Bootstrap","title":"Standard Errors and Confidence Intervals","text":"easy use bootstrap alternative strategy compute standard errors confidence intervals. Several R packages can help us achieve , including long-established boot package: Note , code , set vcov=FALSE avoid computation delta method standard errors speed things . Compare delta method standard errors:","code":"library(boot) set.seed(123)  bootfun <- function(data, indices, ...) {     d <- data[indices, ]     mod <- lm(mpg ~ am + hp + factor(cyl), data = d)     cmp <- comparisons(mod, newdata = d, vcov = FALSE, variables = \"am\")     tidy(cmp)$estimate }  b <- boot(data = mtcars, statistic = bootfun, R = 1000)  b #>  #> ORDINARY NONPARAMETRIC BOOTSTRAP #>  #>  #> Call: #> boot(data = mtcars, statistic = bootfun, R = 1000) #>  #>  #> Bootstrap Statistics : #>     original     bias    std. error #> t1* 4.157856 0.01543426    1.003461 boot.ci(b, type = \"perc\") #> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS #> Based on 1000 bootstrap replicates #>  #> CALL :  #> boot.ci(boot.out = b, type = \"perc\") #>  #> Intervals :  #> Level     Percentile      #> 95%   ( 2.240,  6.277 )   #> Calculations and Intervals on Original Scale mod <- lm(mpg ~ am + hp + factor(cyl), data = mtcars) avg_comparisons(mod, variables = \"am\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>    am    1 - 0    4.158      1.257 3.309 0.00093648 1.695  6.621 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"mixed-effects-models-satterthwaite-and-kenward-roger-corrections","dir":"Articles","previous_headings":"","what":"Mixed effects models: Satterthwaite and Kenward-Roger corrections","title":"Standard Errors and Confidence Intervals","text":"linear mixed effects models can apply Satterthwaite Kenward-Roger corrections way : Marginal effects mean classical standard errors z-statistic: Marginal effects mean Kenward-Roger adjusted variance-covariance degrees freedom: can use option package’s core functions, including:","code":"library(marginaleffects) library(patchwork) library(lme4)  dat <- mtcars dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lmer(mpg ~ hp + am + (1 | cyl), data = dat) slopes(mod, newdata = \"mean\") #>  #>  Term     Contrast Estimate Std. Error      z   Pr(>|z|)    2.5 %   97.5 % #>    hp        dY/dX -0.05184    0.01146 -4.523 6.1031e-06 -0.07431 -0.02938 #>    am TRUE - FALSE  4.66614    1.13426  4.114 3.8914e-05  2.44304  6.88924 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, am, cyl, eps slopes(mod,                 newdata = \"mean\",                 vcov = \"kenward-roger\") #>  #>  Term     Contrast Estimate Std. Error      z Pr(>|z|)   2.5 %   97.5 % #>    hp        dY/dX -0.05184    0.01519 -3.413  0.09643 -0.1306  0.02687 #>    am TRUE - FALSE  4.66614    1.28244  3.638  0.08742 -1.9798 11.31212 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, df, predicted, predicted_hi, predicted_lo, mpg, hp, am, cyl, eps plot_predictions(mod, condition = \"hp\", vcov = \"satterthwaite\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Standard Errors and Confidence Intervals","text":"See brms vignette discussion bayesian estimates credible intervals.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vincent Arel-Bundock. Author, maintainer, copyright holder. Marcio Augusto Diniz. Contributor. Noah Greifer. Contributor.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Arel-Bundock V (2023). marginaleffects: Predictions, Contrasts, Slopes, Marginal Means, Hypothesis Tests. R package version 0.8.1.9125, https://vincentarelbundock.github.io/marginaleffects/.","code":"@Manual{,   title = {marginaleffects: Predictions, Contrasts, Slopes, Marginal Means, and Hypothesis Tests},   author = {Vincent Arel-Bundock},   year = {2023},   note = {R package version 0.8.1.9125},   url = {https://vincentarelbundock.github.io/marginaleffects/}, }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"the-marginaleffects-package-for-r-","dir":"","previous_headings":"","what":"Predictions, Contrasts, Slopes, Marginal Means, and Hypothesis Tests","title":"Predictions, Contrasts, Slopes, Marginal Means, and Hypothesis Tests","text":"Compute plot predictions, slopes, marginal means, comparisons (contrasts, risk ratios, odds ratios, etc.) 70 classes statistical models R. Conduct linear non-linear hypothesis tests, well equivalence tests using delta method. website includes “Get started” tutorial many vignettes, case studies, technical notes: CRAN release Development version","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Predictions, Contrasts, Slopes, Marginal Means, and Hypothesis Tests","text":"Install latest CRAN release: Install development version: Restart R completely moving .","code":"install.packages(\"marginaleffects\") install.packages(     c(\"marginaleffects\", \"insight\"),     repos = c(\"https://vincentarelbundock.r-universe.dev\", \"https://easystats.r-universe.dev\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"why-marginaleffects","dir":"","previous_headings":"","what":"Why marginaleffects?","title":"Predictions, Contrasts, Slopes, Marginal Means, and Hypothesis Tests","text":"Parameter estimates often hard interpret substantively, especially generated complex models non-linear components transformations. Many applied researchers rather focus simple quantities interest, straightforward scientific interpretations. Unfortunately, estimands (standard errors) tedious compute. Moreover, different modeling packages R often produce inconsistent objects require special treatment. marginaleffects offers single point entry easily interpret results 73 classes models, using simple consistent user interface. Benefits marginaleffects include: Powerful: can compute predictions, comparisons (contrasts, risk ratios, etc.), slopes, conduct hypothesis tests 73 different classes models R. Simple: functions share simple unified interface. Documented: function thoroughly documented abundant examples. website includes 20,000+ words vignettes case studies. Efficient: operations orders magnitude faster margins package, memory footprint much smaller. Valid: possible, numerical results checked alternative software like Stata R packages. Thin: dependencies. Standards-compliant: marginaleffects follows “tidy” principles returns objects work standard functions like plot, summary(), tidy(), glance(). objects easy program feed packages like modelsummary. Extensible: Adding support new models easy, often requiring less 10 lines new code. Please submit feature requests Github. Active development: Bugs fixed promptly. marginaleffects package allows R users compute plot three principal quantities interest: (1) predictions, (2) comparisons, (3) slopes. addition, package includes convenience function compute fourth estimand, “marginal means”, special case averaged predictions. marginaleffects can also average (“marginalize”) unit-level (“conditional”) estimates quantities, conduct hypothesis tests . Predictions: outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels. .k.. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions(). Comparisons: Compare predictions made model different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons(). Slopes: Partial derivative regression equation respect regressor interest. .k.. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes(). Marginal Means: Predictions model, averaged across “reference grid” categorical predictors. marginalmeans().","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"Predict outcome variable different regressor values (e.g., college graduates vs. others), compare predictions computing difference, ratio, function. comparisons() can return many quantities interest, contrasts, differences, risk ratios, changes log odds, slopes, elasticities, etc. comparisons(): unit-level (conditional) estimates. avg_comparisons(): average (marginal) estimates. newdata argument datagrid() function can used control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See comparisons vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/comparisons.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"","code":"comparisons(   model,   newdata = NULL,   variables = NULL,   type = NULL,   vcov = TRUE,   by = FALSE,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   cross = FALSE,   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )  avg_comparisons(   model,   newdata = NULL,   variables = NULL,   type = NULL,   vcov = TRUE,   by = TRUE,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   cross = FALSE,   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute contrasts. NULL (default): Unit-level contrasts observed value original dataset. data frame: Unit-level contrasts row newdata data frame. string: \"mean\": Contrasts Mean. Contrasts predictor held mean mode. \"median\": Contrasts Median. Contrasts predictor held median mode. \"marginalmeans\": Contrasts Marginal Means. \"tukey\": Contrasts Tukey's 5 numbers. \"grid\": Contrasts grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. newdata = datagrid(mpg = fivenum): mpg variable held Tukey's five numbers (using fivenum function), regressors fixed means modes. See Examples section datagrid documentation. variables NULL, character vector, named list. subset variables compute contrasts. NULL: compute contrasts variables model object (can slow). Character vector: subset variables (usually faster). Named list: names identify subset variables interest, values define type contrast compute. Acceptable values depend variable type: Factor character variables: \"reference\": factor level compared factor reference (base) level \"\": combinations observed levels \"sequential\": factor level compared previous factor level \"pairwise\": factor level compared levels Vector length 2 two values compare. Logical variables: NULL: contrast TRUE FALSE Numeric variables: Numeric length 1: Contrast gap x, computed observed value plus minus x / 2. example, estimating +1 contrast compares adjusted predictions regressor equal observed value minus 0.5 observed value plus 0.5. Numeric vector length 2: Contrast 2nd element 1st element x vector. Function accepts numeric vector returns data frame two columns \"low\" \"high\" values compare. See examples . \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. Examples: variables = list(gear = \"pairwise\", hp = 10) variables = list(gear = \"sequential\", hp = c(100, 120)) See Examples section . type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . conf_level numeric value 0 1. Confidence level use build confidence interval. transform_pre string function. pairs adjusted predictions contrasted? string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Transformations section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. transform_post string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" cross TRUE FALSE FALSE: Contrasts represent change adjusted predictions one predictor changes variables held constant. TRUE: Contrasts represent changes adjusted predictions predictors specified variables argument manipulated simultaneously (\"cross-contrast\"). wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"avg_comparisons(): Average comparisons","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"transformations","dir":"Reference","previous_headings":"","what":"Transformations","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"following transformations can applied supplying one shortcut strings transform_pre argument. hi vector adjusted predictions \"high\" side contrast. lo vector adjusted predictions \"low\" side contrast. y vector adjusted predictions original data. x predictor original data. eps step size use compute derivatives elasticities.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"","code":"library(marginaleffects)  # Linear model tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) comparisons(mod, variables = list(cyl = \"reference\")) |> tidy() #> Warning: The `cyl` variable is treated as a categorical (factor) variable, but #>   the original data is of class numeric. It is safer and faster to convert #>   such variables to factor before fitting the model and calling `slopes` #>   functions. #>    #>   This warning appears once per session. #> # A tibble: 2 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response cyl   mean(6) - mea…   -6.16    1.54   -4.01 6.11e- 5   -9.17   -3.15 #> 2 response cyl   mean(8) - mea…  -10.1     1.45   -6.93 4.11e-12  -12.9    -7.22 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, variables = list(cyl = \"sequential\")) |> tidy() #> # A tibble: 2 × 9 #>   type     term  contrast        estim…¹ std.e…² stati…³ p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>             <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 response cyl   mean(6) - mean…   -6.16    1.54   -4.01 6.11e-5   -9.17   -3.15 #> 2 response cyl   mean(8) - mean…   -3.91    1.47   -2.66 7.81e-3   -6.79   -1.03 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, variables = list(cyl = \"pairwise\")) |> tidy() #> # A tibble: 3 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response cyl   mean(6) - mea…   -6.16    1.54   -4.01 6.11e- 5   -9.17   -3.15 #> 2 response cyl   mean(8) - mea…  -10.1     1.45   -6.93 4.11e-12  -12.9    -7.22 #> 3 response cyl   mean(8) - mea…   -3.91    1.47   -2.66 7.81e- 3   -6.79   -1.03 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high  # GLM with different scale types mod <- glm(am ~ factor(gear), data = mtcars) comparisons(mod, type = \"response\") |> tidy() #> # A tibble: 2 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response gear  mean(4) - mea…   0.667   0.117    5.68 1.38e- 8   0.436   0.897 #> 2 response gear  mean(5) - mea…   1       0.157    6.39 1.70e-10   0.693   1.31  #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, type = \"link\") |> tidy() #> # A tibble: 2 × 9 #>   type  term  contrast          estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr> <chr> <chr>               <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 link  gear  mean(4) - mean(3)   0.667   0.117    5.68 1.38e- 8   0.436   0.897 #> 2 link  gear  mean(5) - mean(3)   1       0.157    6.39 1.70e-10   0.693   1.31  #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high  # Contrasts at the mean comparisons(mod, newdata = \"mean\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, gear  #>   # Contrasts between marginal means comparisons(mod, newdata = \"marginalmeans\") #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>   # Contrasts at user-specified values comparisons(mod, newdata = datagrid(am = 0, gear = tmp$gear)) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % am gear #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969  0    4 #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969  0    3 #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969  0    5 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069  0    4 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069  0    3 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069  0    5 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, gear  #>  comparisons(mod, newdata = datagrid(am = unique, gear = max)) #>  #>  Term Contrast Estimate Std. Error     z   Pr(>|z|)  2.5 % 97.5 % am gear #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969  1    5 #>  gear    4 - 3   0.6667     0.1174 5.676 1.3751e-08 0.4365 0.8969  0    5 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069  1    5 #>  gear    5 - 3   1.0000     0.1566 6.386 1.7026e-10 0.6931 1.3069  0    5 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, gear  #>   m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) comparisons(m, variables = \"hp\", newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)    2.5 %   97.5 % #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>    hp       +1 -0.04523    0.01489 -3.037 0.0023856 -0.07441 -0.01604 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, drat, cyl, am, eps  #>    # Numeric contrasts mod <- lm(mpg ~ hp, data = mtcars) comparisons(mod, variables = list(hp = 1)) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast estimate std.error statistic  p.value conf.low conf.…¹ #>   <chr>    <chr> <chr>       <dbl>     <dbl>     <dbl>    <dbl>    <dbl>   <dbl> #> 1 response hp    mean(+1)  -0.0682    0.0101     -6.74 1.56e-11  -0.0881 -0.0484 #> # … with abbreviated variable name ¹​conf.high comparisons(mod, variables = list(hp = 5)) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast estimate std.error statistic  p.value conf.low conf.…¹ #>   <chr>    <chr> <chr>       <dbl>     <dbl>     <dbl>    <dbl>    <dbl>   <dbl> #> 1 response hp    mean(+5)   -0.341    0.0506     -6.74 1.56e-11   -0.440  -0.242 #> # … with abbreviated variable name ¹​conf.high comparisons(mod, variables = list(hp = c(90, 100))) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response hp    mean(100) - m…  -0.682   0.101   -6.74 1.56e-11  -0.881  -0.484 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, variables = list(hp = \"iqr\")) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response hp    mean(Q3) - me…   -5.70   0.845   -6.74 1.56e-11   -7.35   -4.04 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, variables = list(hp = \"sd\")) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response hp    mean(x + sd/2…   -4.68   0.694   -6.74 1.56e-11   -6.04   -3.32 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high comparisons(mod, variables = list(hp = \"minmax\")) |> tidy() #> # A tibble: 1 × 9 #>   type     term  contrast       estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>            <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 response hp    mean(Max) - m…   -19.3    2.86   -6.74 1.56e-11   -24.9   -13.7 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high  # using a function to specify a custom difference in one regressor dat <- mtcars dat$new_hp <- 49 * (dat$hp - min(dat$hp)) / (max(dat$hp) - min(dat$hp)) + 1 modlog <- lm(mpg ~ log(new_hp) + factor(cyl), data = dat) fdiff <- \\(x) data.frame(x, x + 10) avg_comparisons(modlog, variables = list(new_hp = fdiff)) #>  #>    Term Contrast Estimate Std. Error      z  Pr(>|z|)  2.5 %  97.5 % #>  new_hp   custom   -1.974     0.7105 -2.778 0.0054696 -3.366 -0.5812 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Adjusted Risk Ratio: see the contrasts vignette mod <- glm(vs ~ mpg, data = mtcars, family = binomial) avg_comparisons(mod, transform_pre = \"lnratioavg\", transform_post = exp) #>  #>  Term Contrast Estimate   Pr(>|z|) 2.5 % 97.5 % #>   mpg mean(+1)    1.135 2.3808e-10 1.091   1.18 #>  #> Prediction type:  response  #> Post-transformation:  transform_post  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>   # Adjusted Risk Ratio: Manual specification of the `transform_pre` avg_comparisons(      mod,      transform_pre = function(hi, lo) log(mean(hi) / mean(lo)),      transform_post = exp) #>  #>  Term Contrast Estimate   Pr(>|z|) 2.5 % 97.5 % #>   mpg       +1    1.135 2.3808e-10 1.091   1.18 #>  #> Prediction type:  response  #> Pre-transformation:  transform_pre  #> Post-transformation:  transform_post  #> Columns: type, term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>  # cross contrasts mod <- lm(mpg ~ factor(cyl) * factor(gear) + hp, data = mtcars) avg_comparisons(mod, variables = c(\"cyl\", \"gear\"), cross = TRUE) #> Warning: Model matrix is rank deficient. Some variance-covariance parameters are #>   missing. #>  #>  C: cyl C: gear Estimate Std. Error       z Pr(>|z|)  2.5 % 97.5 % #>   6 - 4   4 - 3  -0.6306      3.405 -0.1852  0.85307 -7.303  6.042 #>   6 - 4   5 - 3   2.6778      4.617  0.5800  0.56193 -6.372 11.727 #>   8 - 4   4 - 3   3.3475      6.427  0.5208  0.60249 -9.250 15.945 #>   8 - 4   5 - 3   5.5250      5.868  0.9416  0.34642 -5.976 17.026 #>   6 - 4   4 - 3  -0.6306      3.405 -0.1852  0.85307 -7.303  6.042 #> --- 118 rows omitted. See ?print.marginaleffects ---  #>   8 - 4   5 - 3   5.5250      5.868  0.9416  0.34642 -5.976 17.026 #>   6 - 4   4 - 3  -0.6306      3.405 -0.1852  0.85307 -7.303  6.042 #>   6 - 4   5 - 3   2.6778      4.617  0.5800  0.56193 -6.372 11.727 #>   8 - 4   4 - 3   3.3475      6.427  0.5208  0.60249 -9.250 15.945 #>   8 - 4   5 - 3   5.5250      5.868  0.9416  0.34642 -5.976 17.026  #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast_cyl, contrast_gear, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>   # variable-specific contrasts avg_comparisons(mod, variables = list(gear = \"sequential\", hp = 10)) #> Warning: Model matrix is rank deficient. Some variance-covariance parameters are #>   missing. #>  #>  Term Contrast Estimate Std. Error       z Pr(>|z|)  2.5 %  97.5 % #>  gear    4 - 3   3.4095      2.587  1.3177 0.187591 -1.662  8.4806 #>  gear    5 - 4   2.6277      2.747  0.9566 0.338744 -2.756  8.0113 #>    hp      +10  -0.5741      0.225 -2.5518 0.010718 -1.015 -0.1331 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  comparisons(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>  #>     Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  wt=drat   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using row indices comparisons(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>  #>     Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  b1-b2=0   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using numeric vector of weights comparisons(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>  #>    Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  custom   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) comparisons(     mod,     newdata = \"mean\",     hypothesis = lc) #>  #>    Term Estimate Std. Error       z   Pr(>|z|)   2.5 % 97.5 % #>  custom   -6.225      1.052 -5.9190 3.2398e-09  -8.287 -4.164 #>  custom   -5.238      5.624 -0.9315    0.35162 -16.261  5.784 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>    # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) comparisons(mod, by = TRUE) #>  #>  Term Contrast Estimate Std. Error       z   Pr(>|z|)   2.5 %   97.5 % #>    hp       +1 -0.06878     0.0182 -3.7797 0.00015703 -0.1044 -0.03311 #>    am    1 - 0  4.69801     1.0601  4.4316 9.3531e-06  2.6202  6.77580 #>    vs    1 - 0 -0.29433     2.3379 -0.1259 0.89981407 -4.8766  4.28789 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   mod <- lm(mpg ~ hp * am * vs, data = mtcars) avg_comparisons(mod, variables = \"hp\", by = c(\"vs\", \"am\")) #>  #>  Term Contrast vs am Estimate Std. Error      z  Pr(>|z|)    2.5 %    97.5 % #>    hp mean(+1)  0  1 -0.03685    0.01240 -2.971 0.0029676 -0.06116 -0.012540 #>    hp mean(+1)  1  1 -0.11115    0.04634 -2.399 0.0164473 -0.20197 -0.020336 #>    hp mean(+1)  1  0 -0.09941    0.05345 -1.860 0.0628876 -0.20417  0.005344 #>    hp mean(+1)  0  0 -0.04215    0.02477 -1.702 0.0887904 -0.09070  0.006394 #>  #> Prediction type:  response  #> Columns: type, term, contrast, vs, am, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>   library(nnet) mod <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE) by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\")) comparisons(mod, type = \"probs\", by = by) #>  #>  Term  By   Estimate Std. Error        z  Pr(>|z|)    2.5 %   97.5 % #>   mpg 3,4  0.0004635   0.005796  0.07997 0.9362637 -0.01090  0.01182 #>    am 3,4 -0.2227925   0.079558 -2.80038 0.0051042 -0.37872 -0.06686 #>    vs 3,4  0.1021021   0.073236  1.39416 0.1632708 -0.04144  0.24564 #>   mpg   5 -0.0009270   0.011592 -0.07997 0.9362637 -0.02365  0.02179 #>    am   5  0.4455851   0.159116  2.80038 0.0051042  0.13372  0.75745 #>    vs   5 -0.2042041   0.146472 -1.39416 0.1632708 -0.49128  0.08287 #>  #> Prediction type:  probs  #> Columns: type, term, by, estimate, std.error, statistic, p.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/complete_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a data.frame with all factor or character levels — complete_levels","title":"Create a data.frame with all factor or character levels — complete_levels","text":"model.matrix get_predicted break newdata includes factor variable, levels present data. bad us often want get predictions one () rows, factor levels inevitably missing.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/complete_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a data.frame with all factor or character levels — complete_levels","text":"","code":"complete_levels(x, character_levels = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Data grids — datagrid","title":"Data grids — datagrid","text":"Generate data grid \"typical,\" \"counterfactual,\" user-specified values use newdata argument marginaleffects predictions functions. datagrid() generates data frames combinations \"typical\" user-supplied predictor values. datagridcf() generates \"counter-factual\" data frames, replicating entire dataset every combination predictor values supplied user.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data grids — datagrid","text":"","code":"datagrid(   ...,   model = NULL,   newdata = NULL,   grid_type = \"typical\",   FUN_character = get_mode,   FUN_factor = get_mode,   FUN_logical = get_mode,   FUN_numeric = function(x) mean(x, na.rm = TRUE),   FUN_integer = function(x) round(mean(x, na.rm = TRUE)),   FUN_other = function(x) mean(x, na.rm = TRUE) )  datagridcf(..., model = NULL, newdata = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data grids — datagrid","text":"... named arguments vectors values functions user-specified variables. Functions applied variable model dataset newdata, must return vector appropriate type. Character vectors automatically transformed factors necessary. +output include combinations variables (see Examples .) model Model object newdata data.frame (one one model newdata arguments grid_type character \"typical\": variables whose values explicitly specified user ... set mean mode, output functions supplied FUN_type arguments. \"counterfactual\": entire dataset duplicated combination variable values specified .... Variables explicitly supplied datagrid() set observed values original dataset. FUN_character function applied character variables. FUN_factor function applied factor variables. FUN_logical function applied factor variables. FUN_numeric function applied numeric variables. FUN_integer function applied integer variables. FUN_other function applied variable types.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data grids — datagrid","text":"data.frame row corresponds one combination named predictors supplied user via ... dots. Variables explicitly defined held mean mode.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data grids — datagrid","text":"datagrid used predictions(), comparisons(), slopes() call newdata argument, model automatically inserted model argument datagrid() call, users need specify either model newdata arguments. users supply model, data used fit model retrieved using insight::get_data function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Data grids — datagrid","text":"datagridcf(): Counterfactual data grid","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data grids — datagrid","text":"","code":"# The output only has 2 rows, and all the variables except `hp` are at their # mean or mode. datagrid(newdata = mtcars, hp = c(100, 110)) #>        mpg    cyl     disp     drat      wt     qsec     vs      am   gear #> 1 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #> 2 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #>     carb  hp #> 1 2.8125 100 #> 2 2.8125 110  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) datagrid(model = mod, hp = c(100, 110)) #>        mpg  hp #> 1 20.09062 100 #> 2 20.09062 110  # Use in `marginaleffects` to compute \"Typical Marginal Effects\". When used # in `slopes()` or `predictions()` we do not need to specify the #`model` or `newdata` arguments. slopes(mod, newdata = datagrid(hp = c(100, 110))) #>  #>  Term Estimate Std. Error      z  Pr(>|z|)    2.5 %   97.5 %  hp #>    hp -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 100 #>    hp -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 110 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, eps  #>   # datagrid accepts functions datagrid(hp = range, cyl = unique, newdata = mtcars) #>        mpg     disp     drat      wt     qsec     vs      am   gear   carb  hp #> 1 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 2 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 3 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 4 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 5 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 6 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #>   cyl #> 1   6 #> 2   4 #> 3   8 #> 4   6 #> 5   4 #> 6   8 comparisons(mod, newdata = datagrid(hp = fivenum)) #>  #>  Term Contrast Estimate Std. Error      z  Pr(>|z|)    2.5 %   97.5 %  hp #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839  52 #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839  96 #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 123 #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 180 #>    hp       +1 -0.06823    0.01012 -6.742 1.558e-11 -0.08806 -0.04839 335 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, eps  #>   # The full dataset is duplicated with each observation given counterfactual # values of 100 and 110 for the `hp` variable. The original `mtcars` includes # 32 rows, so the resulting dataset includes 64 rows. dg <- datagrid(newdata = mtcars, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) dg <- datagrid(model = mod, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/deltamethod.html","id":null,"dir":"Reference","previous_headings":"","what":"deltamethod() is an alias to hypotheses() — deltamethod","title":"deltamethod() is an alias to hypotheses() — deltamethod","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/deltamethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"deltamethod() is an alias to hypotheses() — deltamethod","text":"","code":"deltamethod(   model,   hypothesis = NULL,   vcov = NULL,   conf_level = 0.95,   df = Inf,   equivalence = NULL,   FUN = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_marginal_means.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_marginal_means","title":"tinytest helper — expect_marginal_means","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_marginal_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_marginal_means","text":"","code":"expect_marginal_means(object, se = TRUE, n_row = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_margins.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_margins","title":"tinytest helper — expect_margins","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_margins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_margins","text":"","code":"expect_margins(   results,   margins_object,   se = TRUE,   tolerance = 1e-05,   verbose = FALSE )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_predictions","title":"tinytest helper — expect_predictions","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_predictions","text":"","code":"expect_predictions(object, se = TRUE, n_row = NULL, n_col = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_slopes","title":"tinytest helper — expect_slopes","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_slopes","text":"","code":"expect_slopes(object, n_unique = NULL, pct_na = 5, se = TRUE, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":null,"dir":"Reference","previous_headings":"","what":"Average Estimates (aka ","title":"Average Estimates (aka ","text":"Calculate average estimates taking (group-wise) mean unit-level estimates computed predictions(), comparisons(), slopes() functions. Warning: generally faster safer use argument one three functions listed . Alternatively, one can call one step: avg_slopes(model) slopes(model, = TRUE) Proceeding two steps assigning unit-level estimates typically slower, estimates must computed twice. Note tidy() summary() methods slower wrappers around avg_*() functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average Estimates (aka ","text":"","code":"get_averages(x, by = TRUE, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average Estimates (aka ","text":"x Object produced predictions(), comparisons(), slopes() functions. Character vector variable names compute group-wise average estimates. =NULL, global average (per term) reported. ... additional arguments passed original fitting function override original call options: conf_level, transform_post, etc. See ?predictions, ?comparisons, ?slopes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average Estimates (aka ","text":"data.frame estimates uncertainty estimates","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Average Estimates (aka ","text":"Standard errors estimated using delta method. See marginaleffects website details. Bayesian models (e.g., brms), estimates aggregated applying median (mean) function twice. First, apply marginal effects posterior draw, thereby estimating one Average (Median) Marginal Effect per iteration MCMC chain. Second, calculate mean quantile function results Step 1 obtain Average Marginal Effect associated interval.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average Estimates (aka ","text":"","code":"mod <- lm(mpg ~ factor(gear), data = mtcars) contr <- comparisons(mod, variables = list(gear = \"sequential\")) tidy(contr) #> # A tibble: 2 × 9 #>   type     term  contrast        estim…¹ std.e…² stati…³ p.value conf.…⁴ conf.…⁵ #>   <chr>    <chr> <chr>             <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 response gear  mean(4) - mean…    8.43    1.82    4.62 3.81e-6    4.85   12.0  #> 2 response gear  mean(5) - mean…   -3.15    2.51   -1.26 2.08e-1   -8.07    1.76 #> # … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic, #> #   ⁴​conf.low, ⁵​conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named vector of coefficients from a model object (internal function) — get_coef","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"Get named vector coefficients model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"","code":"get_coef(model, ...)  # S3 method for default get_coef(model, ...)  # S3 method for polr get_coef(model, ...)  # S3 method for afex_aov get_coef(model, ...)  # S3 method for betareg get_coef(model, ...)  # S3 method for multinom get_coef(model, ...)  # S3 method for brmultinom get_coef(model, ...)  # S3 method for bracl get_coef(model, ...)  # S3 method for brmsfit get_coef(model, ...)  # S3 method for gamlss get_coef(model, ...)  # S3 method for glmmTMB get_coef(model, ...)  # S3 method for merMod get_coef(model, ...)  # S3 method for lmerModLmerTest get_coef(model, ...)  # S3 method for lmerMod get_coef(model, ...)  # S3 method for mblogit get_coef(model, ...)  # S3 method for gam get_coef(model, ...)  # S3 method for mlm get_coef(model, ...)  # S3 method for selection get_coef(model, ...)  # S3 method for scam get_coef(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"named vector coefficients. names must match variance matrix.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"Get levels outcome variable grouped multivariate models","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"","code":"get_group_names(model, ...)  # S3 method for default get_group_names(model, ...)  # S3 method for polr get_group_names(model, ...)  # S3 method for multinom get_group_names(model, ...)  # S3 method for bracl get_group_names(model, ...)  # S3 method for brmsfit get_group_names(model, ...)  # S3 method for mblogit get_group_names(model, type, ...)  # S3 method for mlm get_group_names(model, ...)  # S3 method for clm get_group_names(model, ...)  # S3 method for hurdle get_group_names(model, type = \"count\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"character vector","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Get predicted values from a model object (internal function) — get_predict","title":"Get predicted values from a model object (internal function) — get_predict","text":"Get predicted values model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get predicted values from a model object (internal function) — get_predict","text":"","code":"get_predict(model, newdata, vcov, conf_level, type, ...)  # S3 method for default get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for polr get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for glmmPQL get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for afex_aov get_predict(model, newdata = NULL, ...)  # S3 method for glimML get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for betareg get_predict(model, newdata, ...)  # S3 method for bife get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for biglm get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for multinom get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for brmultinom get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for brmsfit get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for crch get_predict(   model,   newdata = NULL,   vcov = FALSE,   conf_level = 0.95,   type = \"location\",   ... )  # S3 method for fixest get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for gamlss get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for glmmTMB get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for inferences_simulation get_predict(model, newdata, vcov = FALSE, ...)  # S3 method for merMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for lmerModLmerTest get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for lmerMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mblogit get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mhurdle get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mlogit get_predict(model, newdata, ...)  # S3 method for clm get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for rq get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = NULL,   ... )  # S3 method for rlmerMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for stanreg get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for coxph get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"lp\",   ... )  # S3 method for tobit1 get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = \"response\",   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get predicted values from a model object (internal function) — get_predict","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute slopes. NULL (default): Unit-level slopes observed value original dataset. data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get predicted values from a model object (internal function) — get_predict","text":"data.frame predicted values number rows equal number rows newdata columns \"rowid\" \"estimate\". \"group\" column added multivariate models models categorical outcomes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_varcov_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","title":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"Take summary() style vcov argument convert insight::get_varcov()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_varcov_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"","code":"get_varcov_args(model, vcov)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"Get named variance-covariance matrix model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"","code":"get_vcov(model, ...)  # S3 method for default get_vcov(model, vcov = NULL, ...)  # S3 method for afex_aov get_vcov(model, vcov = NULL, ...)  # S3 method for glimML get_vcov(model, vcov = NULL, ...)  # S3 method for biglm get_vcov(model, vcov = NULL, ...)  # S3 method for brmsfit get_vcov(model, vcov = NULL, ...)  # S3 method for gamlss get_vcov(model, ...)  # S3 method for inferences_simulation get_vcov(model, ...)  # S3 method for mhurdle get_vcov(model, vcov = NULL, ...)  # S3 method for orm get_vcov(model, vcov = NULL, ...)  # S3 method for scam get_vcov(model, vcov = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model))","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"named square matrix variance covariances. names must match coefficient names.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":null,"dir":"Reference","previous_headings":"","what":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","title":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"Uncertainty estimates calculated first-order approximate standard errors linear non-linear functions vector random variables known estimated covariance matrix. sense, hypotheses emulates behavior excellent well-established car::deltaMethod car::linearHypothesis functions, supports models; requires fewer dependencies; expands range tests equivalence superiority/inferiority; offers convenience features like robust standard errors. learn , read hypothesis tests vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html https://vincentarelbundock.github.io/marginaleffects/ Warning #1: Tests conducted directly scale defined type argument. models, can make sense conduct hypothesis equivalence tests \"link\" scale instead \"response\" scale often default. Warning #2: hypothesis tests objects produced marginaleffects package, safer use hypothesis argument original function.  Using hypotheses() may work certain environments, called programmatically.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"","code":"hypotheses(   model,   hypothesis = NULL,   vcov = NULL,   conf_level = 0.95,   df = Inf,   equivalence = NULL,   FUN = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"model Model object object generated comparisons(), slopes(), predictions(), marginal_means() functions. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . FUN NULL function. NULL (default): hypothesis test model's coefficients, quantities estimated one marginaleffects package functions. Function accepts model object returns numeric vector data.frame two columns called term estimate. argument can useful users want conduct hypothesis test arbitrary function quantities held model object. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Non-)Linear Tests for Null Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)  # When `FUN` and `hypotheses` are `NULL`, `hypotheses()` returns a data.frame of parameters hypotheses(mod) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)    2.5 %     97.5 % #>    b1 35.84600    2.04102 17.563 < 2.22e-16 31.84567 39.8463192 #>    b2 -0.02312    0.01195 -1.934   0.053069 -0.04655  0.0003061 #>    b3 -3.18140    0.71960 -4.421 9.8215e-06 -4.59180 -1.7710120 #>    b4 -3.35902    1.40167 -2.396   0.016555 -6.10625 -0.6118027 #>    b5 -3.18588    2.17048 -1.468   0.142151 -7.43994  1.0681690 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Test of equality between coefficients hypotheses(mod, hypothesis = \"hp = wt\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  hp = wt    3.158     0.7199 4.387 1.1489e-05 1.747  4.569 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Non-linear function hypotheses(mod, hypothesis = \"exp(hp + wt) = 0.1\") #>  #>                Term Estimate Std. Error      z Pr(>|z|)   2.5 %    97.5 % #>  exp(hp + wt) = 0.1 -0.05942     0.0292 -2.035 0.041832 -0.1166 -0.002196 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Robust standard errors hypotheses(mod, hypothesis = \"hp = wt\", vcov = \"HC3\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  hp = wt    3.158     0.8052 3.922 8.7673e-05  1.58  4.736 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # b1, b2, ... shortcuts can be used to identify the position of the # parameters of interest in the output of FUN hypotheses(mod, hypothesis = \"b2 = b3\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  b2 = b3    3.158     0.7199 4.387 1.1489e-05 1.747  4.569 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # term names with special characters have to be enclosed in backticks hypotheses(mod, hypothesis = \"`factor(cyl)6` = `factor(cyl)8`\") #>  #>                             Term Estimate Std. Error       z Pr(>|z|)  2.5 % #>  `factor(cyl)6` = `factor(cyl)8`  -0.1731      1.654 -0.1047  0.91663 -3.415 #>  97.5 % #>   3.068 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   mod2 <- lm(mpg ~ hp * drat, data = mtcars) hypotheses(mod2, hypothesis = \"`hp:drat` = drat\") #>  #>              Term Estimate Std. Error    z Pr(>|z|)  2.5 %  97.5 % #>  `hp:drat` = drat   -6.079      2.895 -2.1 0.035732 -11.75 -0.4053 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # predictions(), comparisons(), and slopes() mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial) cmp <- comparisons(mod, newdata = \"mean\") hypotheses(cmp, hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   2.5 %   97.5 % #>  b1=b2  -0.2878     0.1202 -2.394 0.016646 -0.5235 -0.05223 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   mfx <- slopes(mod, newdata = \"mean\") hypotheses(cmp, hypothesis = \"b2 = 0.2\") #>  #>    Term Estimate Std. Error      z Pr(>|z|)   2.5 % 97.5 % #>  b2=0.2   0.1014     0.1264 0.8028  0.42211 -0.1462 0.3491 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   pre <- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35))) hypotheses(pre, hypothesis = \"b1 = b2\") #>  #>   Term   Estimate Std. Error      z Pr(>|z|)      2.5 %    97.5 % #>  b1=b2 -3.571e-05  0.0001709 -0.209  0.83445 -0.0003706 0.0002992 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # The `FUN` argument can be used to compute standard errors for fitted values mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error       z Pr(>|z|)  2.5 %  97.5 % #>    b1  -1.0984     0.7160 -1.5339 0.125046 -2.502  0.3051 #>    b2  -1.0984     0.7160 -1.5339 0.125046 -2.502  0.3051 #>    b3   0.2332     0.7808  0.2986 0.765211 -1.297  1.7636 #>    b4  -0.5945     0.6471 -0.9187 0.358234 -1.863  0.6738 #>    b5  -0.4176     0.6475 -0.6449 0.518965 -1.687  0.8514 #>    b6  -5.0265     2.1949 -2.2901 0.022018 -9.328 -0.7245 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   f <- function(x) predict(x, type = \"response\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error      z  Pr(>|z|)    2.5 % 97.5 % #>    b1 0.250047    0.13294 1.8810 0.0599787 -0.01050 0.5106 #>    b2 0.250047    0.13294 1.8810 0.0599787 -0.01050 0.5106 #>    b3 0.558034    0.19240 2.9005 0.0037262  0.18095 0.9351 #>    b4 0.355600    0.14786 2.4050 0.0161710  0.06581 0.6454 #>    b5 0.397097    0.15541 2.5551 0.0106156  0.09249 0.7017 #>    b6 0.006519    0.01407 0.4632 0.6432064 -0.02106 0.0341 #>  #> Prediction type:   #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Equivalence, non-inferiority, and non-superiority tests mod <- lm(mpg ~ hp + factor(gear), data = mtcars) p <- predictions(mod, newdata = \"median\") hypotheses(p, equivalence = c(17, 18)) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 %     p (Inf)   p (Sup) #>     19.66      1.004 19.59 < 2.22e-16 17.69  21.63 0.004037228 0.9508009 #>     p (Eq) #>  0.9508009 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, gear, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>   mfx <- avg_slopes(mod, variables = \"hp\") hypotheses(mfx, equivalence = c(-.1, .1)) #>  #>  Term Estimate Std. Error      z   Pr(>|z|)   2.5 %  97.5 %    p (Inf) #>    hp -0.06685    0.01105 -6.052 1.4269e-09 -0.0885 -0.0452 0.00134666 #>       p (Sup)     p (Eq) #>  7.442542e-52 0.00134666 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>   cmp <- avg_comparisons(mod, variables = \"gear\", hypothesis = \"pairwise\") hypotheses(cmp, equivalence = c(0, 10)) #>  #>               Term Estimate Std. Error      z Pr(>|z|)  2.5 %  97.5 %   p (Inf) #>  (4 - 3) - (5 - 3)    -3.94      2.047 -1.924   0.0543 -7.953 0.07273 0.9728501 #>       p (Sup)    p (Eq) #>  4.916887e-12 0.9728501 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":null,"dir":"Reference","previous_headings":"","what":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"Warning: function experimental. may renamed, user interface may change, functionality may migrate arguments marginaleffects functions. Apply function marginaleffects object change inferential method used compute uncertainty estimates.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"","code":"inferences(x, method = \"simulation\", R = 1000, conf_type = \"perc\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"x Object produced one core marginaleffects functions. method String \"delta\": delta method standard errors \"boot\" package \"rsample\" package \"simulation\" multivariate normal distribution (Krinsky & Robb, 1986) R Number resamples simulations. conf_type String: type bootstrap interval construct. boot: \"perc\", \"norm\", \"basic\", \"bca\" rsample: \"perc\" \"bca\" simulation: argument ignored. ... method=\"boot\", additional arguments passed boot::boot(). method=\"rsample\", additional arguments passed rsample::bootstraps(). method=\"simulation\", additional arguments ignored.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"marginaleffects object simulation bootstrap resamples objects attached.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"method=\"simulation\", conduct simulation-based inference following method discussed Krinsky & Robb (1986): Draw R sets simulated coefficients multivariate normal distribution mean equal original model's estimated coefficients variance equal model's variance-covariance matrix (classical, \"HC3\", ). Use R sets coefficients compute R sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"Krinsky, ., . L. Robb. 1986. “Approximating Statistical Properties Elasticities.” Review Economics Statistics 68 (4): 715–9. King, Gary, Michael Tomz, Jason Wittenberg. \"Making statistical analyses: Improving interpretation presentation.\" American journal political science (2000): 347-361 Dowd, Bryan E., William H. Greene, Edward C. Norton. \"Computation standard errors.\" Health services research 49.2 (2014): 731-750.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EXPERIMENTAL Uncertainty Estimates for marginaleffects Objects — inferences","text":"","code":"library(marginaleffects) library(magrittr) mod <- glm(vs ~ hp * wt + factor(gear), data = mtcars, family = binomial)  avg_predictions(mod, by = \"gear\") %>%   inferences() #>  #>  gear Estimate Std. Error   2.5 % 97.5 % #>     3   0.2059     0.1414 0.08366 0.7220 #>     4   0.8003     0.1067 0.53816 0.9457 #>     5   0.2078     0.1243 0.03500 0.5080 #>  #> Prediction type:  response  #> Columns: type, gear, estimate, std.error, conf.low, conf.high  #>   slopes(mod) %>%   inferences() %>%   head() #>  #>  Term Contrast   Estimate Std. Error    2.5 %   97.5 % #>    hp    dY/dX -0.0094303   0.009782 -0.03276 0.001569 #>    hp    dY/dX -0.0106234   0.009558 -0.03409 0.001422 #>    hp    dY/dX -0.0040303   0.008279 -0.02895 0.002914 #>    hp    dY/dX -0.0061942   0.007324 -0.02498 0.001482 #>    hp    dY/dX -0.0008854   0.003248 -0.01167 0.000828 #>    hp    dY/dX -0.0047266   0.006320 -0.02255 0.001061 #>  #> Prediction type:  response  #> Columns: rowid, type, term, contrast, estimate, std.error, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, wt, gear, eps  #>   avg_slopes(mod) %>%   inferences() %>%   posterior_draws(\"rvar\") #>  #>  Term Contrast  Estimate Std. Error    2.5 %   97.5 % #>  gear    4 - 3 -0.044068   0.137967 -0.24937 0.295332 #>  gear    5 - 3 -0.168639   0.229973 -0.54921 0.350494 #>    hp    dY/dX -0.004767   0.002982 -0.01018 0.001923 #>    wt    dY/dX  0.020223   0.176263 -0.30200 0.372916 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, conf.low, conf.high, rvar  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Means — marginal_means","title":"Marginal Means — marginal_means","text":"Marginal means adjusted predictions, averaged across grid categorical predictors, holding numeric predictors means. learn , read marginal means vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Means — marginal_means","text":"","code":"marginal_means(   model,   variables = NULL,   variables_grid = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   transform_post = NULL,   cross = FALSE,   hypothesis = NULL,   df = Inf,   wts = \"equal\",   by = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Means — marginal_means","text":"model Model object variables character vector Categorical predictors compute marginal means. NULL calculates marginal means logical, character, factor variables dataset used fit model. Set cross=TRUE compute marginal means combinations predictors specified variables argument. variables_grid character vector Categorical predictors used construct prediction grid adjusted predictions averaged (character vector). NULL creates grid combinations categorical predictors. grid can large many variables many response levels, advisable select limited number variables variables variables_grid arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. type NULL default value \"response\", function tries compute marginal means link scale backtransforming using inverse link function. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. cross TRUE FALSE FALSE (default): Marginal means computed predictor individually. TRUE: Marginal means computed combination predictors specified variables argument. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) wts character value. Weights use averaging. \"equal\": combination variables variables_grid gets equal weight. \"cells\": combination values variables variables_grid gets weight proportional frequency original data. \"proportional\": combination values variables variables_grid -- except variables argument -- gets weight proportional frequency original data. Collapse marginal means categories. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Means — marginal_means","text":"Data frame marginal means one row per variable-value combination.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Means — marginal_means","text":"function begins calling predictions function obtain grid predictors, adjusted predictions cell. grid includes combinations categorical variables listed variables variables_grid arguments, combinations categorical variables used fit model variables_grid NULL. prediction grid, numeric variables held means. constructing grid filling grid adjusted predictions, marginal_means computes marginal means variables listed variables argument, average across categories grid. marginal_means can compute standard errors linear models, predictions link scale, , type argument set \"link\". marginaleffects website compares output function popular emmeans package, provides similar advanced functionality: https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Marginal Means — marginal_means","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Marginal Means — marginal_means","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Means — marginal_means","text":"","code":"library(marginaleffects)  # simple marginal means for each level of `cyl` dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ carb + cyl + am, dat)  marginal_means(   mod,   variables = \"cyl\") #>  #>  Term Value  Mean Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   cyl     4 23.11      1.658 13.94 < 2.22e-16 19.86  26.36 #>   cyl     6 20.38      1.337 15.25 < 2.22e-16 17.76  23.01 #>   cyl     8 16.21      1.073 15.11 < 2.22e-16 14.11  18.31 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: type, term, value, cyl, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # collapse levels of cyl by averaging by <- data.frame(   cyl = c(4, 6, 8),   by = c(\"4 & 6\", \"4 & 6\", \"8\")) marginal_means(mod,   variables = \"cyl\",   by = by) #>  #>     By  Mean Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  4 & 6 21.75      1.132 19.21 < 2.22e-16 19.53  23.97 #>      8 16.21      1.073 15.11 < 2.22e-16 14.11  18.31 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: by, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # pairwise differences between collapsed levels marginal_means(mod,   variables = \"cyl\",   by = by,   hypothesis = \"pairwise\") #>  #>       Term  Mean Std. Error    z   Pr(>|z|) 2.5 % 97.5 % #>  4 & 6 - 8 5.538      1.513 3.66 0.00025192 2.573  8.504 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # cross marginal_means(mod,   variables = c(\"cyl\", \"carb\"),   cross = TRUE) #>  #>   Mean Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  25.82      1.264 20.426 < 2.22e-16 23.340  28.29 #>  25.59      1.167 21.932 < 2.22e-16 23.302  27.88 #>  25.34      2.365 10.714 < 2.22e-16 20.704  29.97 #>  21.88      1.901 11.508 < 2.22e-16 18.152  25.60 #>  20.29      3.766  5.388 7.1424e-08 12.910  27.67 #>  19.77      3.814  5.182 2.1948e-07 12.290  27.24 #>  23.09      1.765 13.079 < 2.22e-16 19.629  26.55 #>  22.86      1.867 12.241 < 2.22e-16 19.200  26.52 #>  22.61      2.365  9.560 < 2.22e-16 17.975  27.25 #>  19.15      1.338 14.307 < 2.22e-16 16.526  21.77 #>  17.56      3.004  5.847 5.0001e-09 11.676  23.45 #>  17.04      3.481  4.894 9.8786e-07 10.214  23.86 #>  18.91      1.942  9.740 < 2.22e-16 15.108  22.72 #>  18.69      1.571 11.898 < 2.22e-16 15.608  21.76 #>  18.44      1.831 10.069 < 2.22e-16 14.848  22.03 #>  14.98      1.195 12.528 < 2.22e-16 12.632  17.32 #>  13.39      3.356  3.989 6.6223e-05  6.811  19.97 #>  12.86      3.004  4.282 1.8486e-05  6.976  18.75 #>  #> Prediction type:  response  #> Results averaged over levels of: am  #> Columns: type, cyl, carb, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # collapsed cross by <- expand.grid(   cyl = unique(mtcars$cyl),   carb = unique(mtcars$carb)) by$by <- ifelse(   by$cyl == 4,   paste(\"Control:\", by$carb),   paste(\"Treatment:\", by$carb))   # Convert numeric variables to categorical before fitting the model dat <- mtcars dat$am <- as.logical(dat$am) dat$carb <- as.factor(dat$carb) mod <- lm(mpg ~ hp + am + carb, data = dat)  # Compute and summarize marginal means marginal_means(mod) #>  #>  Term Value  Mean Std. Error      z   Pr(>|z|) 2.5 % 97.5 % #>  carb     1 21.99      1.345 16.350 < 2.22e-16 19.35  24.63 #>  carb     2 21.48      1.025 20.955 < 2.22e-16 19.47  23.49 #>  carb     3 20.55      1.780 11.549 < 2.22e-16 17.06  24.04 #>  carb     4 18.82      1.042 18.065 < 2.22e-16 16.77  20.86 #>  carb     6 18.47      3.019  6.118 9.4743e-10 12.55  24.39 #>  carb     8 21.62      4.055  5.332 9.6936e-08 13.68  29.57 #>    am FALSE 17.87      1.244 14.366 < 2.22e-16 15.43  20.31 #>    am  TRUE 23.11      0.974 23.724 < 2.22e-16 21.20  25.02 #>  #> Prediction type:  response  #> Results averaged over levels of: am, carb  #> Columns: type, term, value, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Contrast between marginal means (carb2 - carb1), or \"is the 1st marginal means equal to the 2nd?\" # see the vignette on \"Hypothesis Tests and Custom Contrasts\" on the `marginaleffects` website. lc <- c(-1, 1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = \"b2 = b1\") #>  #>   Term    Mean Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  b2=b1 -0.5143      1.478 -0.348  0.72786 -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term    Mean Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  custom -0.5143      1.478 -0.348  0.72786 -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Multiple custom contrasts lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     -1, 1, 0, 0, 0, 0     ),   ncol = 2,   dimnames = list(NULL, c(\"A\", \"B\"))) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>  Term    Mean Std. Error      z Pr(>|z|)   2.5 % 97.5 % #>     A  1.1989      6.150  0.195  0.84542 -10.854 13.252 #>     B -0.5143      1.478 -0.348  0.72786  -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"marginaleffects() is an alias to slopes() — marginaleffects","title":"marginaleffects() is an alias to slopes() — marginaleffects","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"marginaleffects() is an alias to slopes() — marginaleffects","text":"","code":"marginaleffects(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"marginal_means() is an alias to marginal_means() — marginalmeans","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"","code":"marginalmeans(   model,   variables = NULL,   variables_grid = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   transform_post = NULL,   cross = FALSE,   hypothesis = NULL,   df = Inf,   wts = \"equal\",   by = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"model Model object variables character vector Categorical predictors compute marginal means. NULL calculates marginal means logical, character, factor variables dataset used fit model. Set cross=TRUE compute marginal means combinations predictors specified variables argument. variables_grid character vector Categorical predictors used construct prediction grid adjusted predictions averaged (character vector). NULL creates grid combinations categorical predictors. grid can large many variables many response levels, advisable select limited number variables variables variables_grid arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. type NULL default value \"response\", function tries compute marginal means link scale backtransforming using inverse link function. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. cross TRUE FALSE FALSE (default): Marginal means computed predictor individually. TRUE: Marginal means computed combination predictors specified variables argument. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) wts character value. Weights use averaging. \"equal\": combination variables variables_grid gets equal weight. \"cells\": combination values variables variables_grid gets weight proportional frequency original data. \"proportional\": combination values variables variables_grid -- except variables argument -- gets weight proportional frequency original data. Collapse marginal means categories. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"Data frame marginal means one row per variable-value combination.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"function begins calling predictions function obtain grid predictors, adjusted predictions cell. grid includes combinations categorical variables listed variables variables_grid arguments, combinations categorical variables used fit model variables_grid NULL. prediction grid, numeric variables held means. constructing grid filling grid adjusted predictions, marginal_means computes marginal means variables listed variables argument, average across categories grid. marginal_means can compute standard errors linear models, predictions link scale, , type argument set \"link\". marginaleffects website compares output function popular emmeans package, provides similar advanced functionality: https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"","code":"library(marginaleffects)  # simple marginal means for each level of `cyl` dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ carb + cyl + am, dat)  marginal_means(   mod,   variables = \"cyl\") #>  #>  Term Value  Mean Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   cyl     4 23.11      1.658 13.94 < 2.22e-16 19.86  26.36 #>   cyl     6 20.38      1.337 15.25 < 2.22e-16 17.76  23.01 #>   cyl     8 16.21      1.073 15.11 < 2.22e-16 14.11  18.31 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: type, term, value, cyl, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # collapse levels of cyl by averaging by <- data.frame(   cyl = c(4, 6, 8),   by = c(\"4 & 6\", \"4 & 6\", \"8\")) marginal_means(mod,   variables = \"cyl\",   by = by) #>  #>     By  Mean Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  4 & 6 21.75      1.132 19.21 < 2.22e-16 19.53  23.97 #>      8 16.21      1.073 15.11 < 2.22e-16 14.11  18.31 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: by, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # pairwise differences between collapsed levels marginal_means(mod,   variables = \"cyl\",   by = by,   hypothesis = \"pairwise\") #>  #>       Term  Mean Std. Error    z   Pr(>|z|) 2.5 % 97.5 % #>  4 & 6 - 8 5.538      1.513 3.66 0.00025192 2.573  8.504 #>  #> Prediction type:  response  #> Results averaged over levels of: cyl, carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # cross marginal_means(mod,   variables = c(\"cyl\", \"carb\"),   cross = TRUE) #>  #>   Mean Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  25.82      1.264 20.426 < 2.22e-16 23.340  28.29 #>  25.59      1.167 21.932 < 2.22e-16 23.302  27.88 #>  25.34      2.365 10.714 < 2.22e-16 20.704  29.97 #>  21.88      1.901 11.508 < 2.22e-16 18.152  25.60 #>  20.29      3.766  5.388 7.1424e-08 12.910  27.67 #>  19.77      3.814  5.182 2.1948e-07 12.290  27.24 #>  23.09      1.765 13.079 < 2.22e-16 19.629  26.55 #>  22.86      1.867 12.241 < 2.22e-16 19.200  26.52 #>  22.61      2.365  9.560 < 2.22e-16 17.975  27.25 #>  19.15      1.338 14.307 < 2.22e-16 16.526  21.77 #>  17.56      3.004  5.847 5.0001e-09 11.676  23.45 #>  17.04      3.481  4.894 9.8786e-07 10.214  23.86 #>  18.91      1.942  9.740 < 2.22e-16 15.108  22.72 #>  18.69      1.571 11.898 < 2.22e-16 15.608  21.76 #>  18.44      1.831 10.069 < 2.22e-16 14.848  22.03 #>  14.98      1.195 12.528 < 2.22e-16 12.632  17.32 #>  13.39      3.356  3.989 6.6223e-05  6.811  19.97 #>  12.86      3.004  4.282 1.8486e-05  6.976  18.75 #>  #> Prediction type:  response  #> Results averaged over levels of: am  #> Columns: type, cyl, carb, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # collapsed cross by <- expand.grid(   cyl = unique(mtcars$cyl),   carb = unique(mtcars$carb)) by$by <- ifelse(   by$cyl == 4,   paste(\"Control:\", by$carb),   paste(\"Treatment:\", by$carb))   # Convert numeric variables to categorical before fitting the model dat <- mtcars dat$am <- as.logical(dat$am) dat$carb <- as.factor(dat$carb) mod <- lm(mpg ~ hp + am + carb, data = dat)  # Compute and summarize marginal means marginal_means(mod) #>  #>  Term Value  Mean Std. Error      z   Pr(>|z|) 2.5 % 97.5 % #>  carb     1 21.99      1.345 16.350 < 2.22e-16 19.35  24.63 #>  carb     2 21.48      1.025 20.955 < 2.22e-16 19.47  23.49 #>  carb     3 20.55      1.780 11.549 < 2.22e-16 17.06  24.04 #>  carb     4 18.82      1.042 18.065 < 2.22e-16 16.77  20.86 #>  carb     6 18.47      3.019  6.118 9.4743e-10 12.55  24.39 #>  carb     8 21.62      4.055  5.332 9.6936e-08 13.68  29.57 #>    am FALSE 17.87      1.244 14.366 < 2.22e-16 15.43  20.31 #>    am  TRUE 23.11      0.974 23.724 < 2.22e-16 21.20  25.02 #>  #> Prediction type:  response  #> Results averaged over levels of: am, carb  #> Columns: type, term, value, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Contrast between marginal means (carb2 - carb1), or \"is the 1st marginal means equal to the 2nd?\" # see the vignette on \"Hypothesis Tests and Custom Contrasts\" on the `marginaleffects` website. lc <- c(-1, 1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = \"b2 = b1\") #>  #>   Term    Mean Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  b2=b1 -0.5143      1.478 -0.348  0.72786 -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term    Mean Std. Error      z Pr(>|z|)  2.5 % 97.5 % #>  custom -0.5143      1.478 -0.348  0.72786 -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Multiple custom contrasts lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     -1, 1, 0, 0, 0, 0     ),   ncol = 2,   dimnames = list(NULL, c(\"A\", \"B\"))) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>  Term    Mean Std. Error      z Pr(>|z|)   2.5 % 97.5 % #>     A  1.1989      6.150  0.195  0.84542 -10.854 13.252 #>     B -0.5143      1.478 -0.348  0.72786  -3.411  2.382 #>  #> Prediction type:  response  #> Results averaged over levels of: carb, am  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/meffects.html","id":null,"dir":"Reference","previous_headings":"","what":"meffects() is an alias to slopes() — meffects","title":"meffects() is an alias to slopes() — meffects","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/meffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meffects() is an alias to slopes() — meffects","text":"","code":"meffects(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_predictions() is an alias to plot_predictions() — plot_cap","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"","code":"plot_cap(   model,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"model Model object condition character vector named list length smaller 4. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. variables held means modes. Lists can include types values: Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"","code":"plot_cco(   x,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"condition character vector named list length smaller 4. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. variables held means modes. Lists can include types values: Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_slopes() is an alias to plot_slopes() — plot_cme","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"","code":"plot_cme(   x,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"condition character vector named list length smaller 4. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. variables held means modes. Lists can include types values: Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Comparisons — plot_comparisons","title":"Plot Comparisons — plot_comparisons","text":"function plots average comparisons, conditional comparisons. Conditional comparisons present comparisons (y-axis) values predictor(s) variable(s) (x-axis colors). especially useful models interactions, values contrasts depend values \"condition\" variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Comparisons — plot_comparisons","text":"","code":"plot_comparisons(   x,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Comparisons — plot_comparisons","text":"x model object produced slopes() comparisons() functions. effect Name variable whose contrast want plot y-axis. NULL, plot average comparisons returned. condition character vector named list length smaller 3. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. Unspecified variables held means modes. Lists can include types values (see Examples section ): Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_pre string function. pairs adjusted predictions contrasted? string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Transformations section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. transform_post string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Comparisons — plot_comparisons","text":"ggplot2 object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Comparisons — plot_comparisons","text":"","code":"mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_comparisons(mod, effect = \"hp\", condition = \"drat\")   plot_comparisons(mod, effect = \"hp\", condition = c(\"drat\", \"am\"))   plot_comparisons(mod, effect = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_comparisons(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Predictions — plot_predictions","title":"Plot Predictions — plot_predictions","text":"function plots adjusted predictions (y-axis) values one predictors (x-axis colors).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Predictions — plot_predictions","text":"","code":"plot_predictions(   model,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Predictions — plot_predictions","text":"model Model object condition character vector named list length smaller 4. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. variables held means modes. Lists can include types values: Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Predictions — plot_predictions","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Predictions — plot_predictions","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Slopes — plot_slopes","title":"Plot Slopes — plot_slopes","text":"function plots marginal effects (y-axis) values predictor(s) variable(s) (x-axis colors). especially useful models interactions, values marginal effects depend values \"condition\" variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Slopes — plot_slopes","text":"","code":"plot_slopes(   x,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Slopes — plot_slopes","text":"x model object produced slopes() comparisons() functions. effect Name variable whose contrast want plot y-axis. NULL, plot average slopes returned. condition character vector named list length smaller 3. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. Unspecified variables held means modes. Lists can include types values (see Examples section ): Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Slopes — plot_slopes","text":"ggplot2 object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Slopes — plot_slopes","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_slopes(mod, effect = \"hp\", condition = \"drat\")   plot_slopes(mod, effect = \"hp\", condition = c(\"drat\", \"am\"))   plot_slopes(mod, effect = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_slopes(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = range))   plot_slopes(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Posterior Draws From marginaleffects Objects — posterior_draws","title":"Extract Posterior Draws From marginaleffects Objects — posterior_draws","text":"Extract Posterior Draws marginaleffects Objects","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Posterior Draws From marginaleffects Objects — posterior_draws","text":"","code":"posterior_draws(x, shape = \"long\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Posterior Draws From marginaleffects Objects — posterior_draws","text":"x object produced marginaleffects package function, predictions(), avg_slopes(), hypotheses(), etc. shape string indicating shape output format: \"long\": long format data frame \"DxP\": Matrix draws rows parameters columns \"PxD\": Matrix draws rows parameters columns \"rvar\": Random variable datatype (see posterior package documentation).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Posterior Draws From marginaleffects Objects — posterior_draws","text":"data.frame drawid draw columns.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":null,"dir":"Reference","previous_headings":"","what":"posteriordraws() is an alias to posterior_draws() — posteriordraws","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"","code":"posteriordraws(x, shape = \"long\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"x object produced marginaleffects package function, predictions(), avg_slopes(), hypotheses(), etc. shape string indicating shape output format: \"long\": long format data frame \"DxP\": Matrix draws rows parameters columns \"PxD\": Matrix draws rows parameters columns \"rvar\": Random variable datatype (see posterior package documentation).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"data.frame drawid draw columns.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions — predictions","title":"Predictions — predictions","text":"Outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels (.k.. \"reference grid\"). predictions(): unit-level (conditional) estimates. avg_predictions(): average (marginal) estimates. newdata argument datagrid() function can used control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See predictions vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions — predictions","text":"","code":"predictions(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   by = FALSE,   byfun = NULL,   wts = NULL,   transform_post = NULL,   hypothesis = NULL,   df = Inf,   ... )  avg_predictions(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   by = TRUE,   byfun = NULL,   wts = NULL,   transform_post = NULL,   hypothesis = NULL,   df = Inf,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions — predictions","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute slopes. NULL (default): Unit-level slopes observed value original dataset. data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). variables NULL, character vector, named list. subset variables use creating counterfactual grid predictions. entire dataset replicated unique combination variables list. See Examples section . Warning: can use lot memory many variables values, dataset large. NULL: computes one prediction per row newdata Named list: names identify subset variables interest values. numeric variables, variables argument supports functions string shortcuts: function returns numeric value Numeric vector: Contrast 2nd element 1st element x vector. \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. \"threenum\": mean 1 standard deviation sides \"fivenum\": Tukey's five numbers #' @param newdata NULL, data frame, string, datagrid() call. Determines grid predictors make predictions. NULL (default): Predictions observed value original dataset. data frame: Predictions row newdata data frame. string: \"mean\": Predictions Mean. Predictions predictor held mean mode. \"median\": Predictions Median. Predictions predictor held median mode. \"marginalmeans\": Predictions Marginal Means. See Details section . \"tukey\": Predictions Tukey's 5 numbers. \"grid\": Predictions grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . byfun function mean() sum() used aggregate estimates within subgroups defined argument. NULL uses mean() function. Must accept numeric vector return single numeric value. sometimes used take sum mean predicted probabilities across outcome predictor levels. See examples section. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions — predictions","text":"data.frame one row per observation several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) estimate: predicted outcome std.error: standard errors computed insight::get_predicted function , unavailable, via marginaleffects delta method functionality. conf.low: lower bound confidence interval (equal-tailed interval bayesian models) conf.high: upper bound confidence interval (equal-tailed interval bayesian models)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions — predictions","text":"newdata argument, tidy() function, datagrid() function can used control kind predictions report: Average Predictions Predictions Mean Predictions User-Specified values (aka Predictions Representative values). possible, predictions() delegates computation confidence intervals insight::get_predicted() function, uses back transformation produce adequate confidence intervals scale specified type argument. possible, predictions() uses Delta Method compute standard errors around adjusted predictions, builds symmetric confidence intervals. naive symmetric intervals may always appropriate. instance, may stretch beyond bounds binary response variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Predictions — predictions","text":"avg_predictions(): Average predictions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Predictions — predictions","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Predictions — predictions","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions — predictions","text":"","code":"# Adjusted Prediction for every row of the original dataset mod <- lm(mpg ~ hp + factor(cyl), data = mtcars) pred <- predictions(mod) head(pred) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     26.41     0.9620 27.46 < 2.22e-16 24.53  28.30 #>     20.04     1.2041 16.64 < 2.22e-16 17.68  22.40 #>     15.92     0.9925 16.04 < 2.22e-16 13.98  17.87 #>     20.16     1.2186 16.54 < 2.22e-16 17.77  22.55 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, cyl  #>   # Adjusted Predictions at User-Specified Values of the Regressors predictions(mod, newdata = datagrid(hp = c(100, 120), cyl = 4)) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 %  hp cyl #>     26.25     0.9856 26.63 < 2.22e-16 24.31  28.18 100   4 #>     25.77     1.1096 23.22 < 2.22e-16 23.59  27.94 120   4 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, cyl  #>   m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     21.95      1.288 17.04 < 2.22e-16 19.43  24.48 #>     18.19      1.271 14.31 < 2.22e-16 15.70  20.68 #>     25.55      1.322 19.32 < 2.22e-16 22.96  28.14 #>     21.78      1.541 14.13 < 2.22e-16 18.76  24.81 #>     22.62      2.141 10.56 < 2.22e-16 18.42  26.81 #>     18.85      1.734 10.87 < 2.22e-16 15.45  22.25 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, drat, cyl, am  #>   # Average Adjusted Predictions (AAP) library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union mod <- lm(mpg ~ hp * am * vs, mtcars)  avg_predictions(mod) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     20.09     0.4844 41.47 < 2.22e-16 19.14  21.04 #>  #> Prediction type:  response  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   predictions(mod, by = \"am\") #>  #>  am Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   1    24.39     0.7601 32.09 < 2.22e-16 22.90  25.88 #>   0    17.15     0.6287 27.27 < 2.22e-16 15.92  18.38 #>  #> Prediction type:  response  #> Columns: type, am, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # Conditional Adjusted Predictions plot_predictions(mod, condition = \"hp\")   # Counterfactual predictions with the `variables` argument # the `mtcars` dataset has 32 rows  mod <- lm(mpg ~ hp + am, data = mtcars) p <- predictions(mod) head(p) #>  #>  Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>     25.38     0.8176 31.05 < 2.22e-16 23.78  26.99 #>     25.38     0.8176 31.05 < 2.22e-16 23.78  26.99 #>     26.39     0.8496 31.06 < 2.22e-16 24.72  28.05 #>     20.11     0.7755 25.93 < 2.22e-16 18.59  21.63 #>     16.28     0.6774 24.03 < 2.22e-16 14.95  17.61 #>     20.40     0.7962 25.62 < 2.22e-16 18.84  21.96 #>  #> Prediction type:  response  #> Columns: rowid, type, estimate, std.error, statistic, p.value, conf.low, conf.high, mpg, hp, am  #>  nrow(p) #> [1] 32  # counterfactual predictions obtained by replicating the entire for different # values of the predictors p <- predictions(mod, variables = list(hp = c(90, 110))) nrow(p) #> [1] 64   # hypothesis test: is the prediction in the 1st row equal to the prediction in the 2nd row mod <- lm(mpg ~ wt + drat, data = mtcars)  predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  b1=b2    4.783      0.797 6.001 1.9629e-09 3.221  6.345 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using row indices predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 - b2 = 0\") #>  #>     Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  b1-b2=0    4.783      0.797 6.001 1.9629e-09 3.221  6.345 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using numeric vector of weights predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = c(1, -1)) #>  #>    Term Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>  custom    4.783      0.797 6.001 1.9629e-09 3.221  6.345 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = lc) #>  #>    Term Estimate Std. Error      z   Pr(>|z|)   2.5 %  97.5 % #>  custom    4.783      0.797  6.001 1.9629e-09   3.221   6.345 #>  custom  115.214      3.647 31.587 < 2.22e-16 108.065 122.363 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>    # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) predictions(mod, by = c(\"am\", \"vs\"))  #>  #>  am vs Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   1  0    19.75     1.1188 17.65 < 2.22e-16 17.56  21.94 #>   1  1    28.37     1.0358 27.39 < 2.22e-16 26.34  30.40 #>   0  1    20.74     1.0358 20.03 < 2.22e-16 18.71  22.77 #>   0  0    15.05     0.7911 19.02 < 2.22e-16 13.50  16.60 #>  #> Prediction type:  response  #> Columns: type, am, vs, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head() #>  #>  Group  Estimate Std. Error         z Pr(>|z|)      2.5 %    97.5 % #>      3 3.624e-05  2.002e-03   0.01810 0.985561 -3.889e-03 3.961e-03 #>      3 3.624e-05  2.002e-03   0.01810 0.985561 -3.889e-03 3.961e-03 #>      3 9.348e-08  6.912e-06   0.01352 0.989210 -1.345e-05 1.364e-05 #>      3 4.045e-01  1.965e-01   2.05788 0.039602  1.924e-02 7.897e-01 #>      3 1.000e+00  1.246e-03 802.40563  < 2e-16  9.975e-01 1.002e+00 #>      3 5.183e-01  2.898e-01   1.78858 0.073683 -4.967e-02 1.086e+00 #>  #> Prediction type:  probs  #> Columns: rowid, type, group, estimate, std.error, statistic, p.value, conf.low, conf.high, gear, mpg, am, vs  #>   # average predictions avg_predictions(nom, type = \"probs\", by = \"group\") #>  #>  Group Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 % #>      3   0.4688    0.04043 11.595 < 2.22e-16 0.38952 0.5480 #>      4   0.3750    0.06142  6.106 1.0231e-09 0.25462 0.4954 #>      5   0.1562    0.04624  3.379  0.0007279 0.06561 0.2469 #>  #> Prediction type:  probs  #> Columns: type, group, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by) #>  #>  Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 %  By #>    0.4219    0.02312 18.246 < 2.22e-16 0.37656 0.4672 3,4 #>    0.1562    0.04624  3.379  0.0007279 0.06561 0.2469   5 #>  #> Prediction type:  probs  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high, by  #>   # sum of predicted probabilities for combined response levels mod <- multinom(factor(cyl) ~ mpg + am, data = mtcars, trace = FALSE) by <- data.frame(     by = c(\"4,6\", \"4,6\", \"8\"),     group = as.character(c(4, 6, 8))) predictions(mod, newdata = \"mean\", byfun = sum, by = by) #>  #>  Estimate Std. Error      z   Pr(>|z|)   2.5 % 97.5 %  By #>   0.91584     0.1218 7.5188 5.5296e-14  0.6771 1.1546 4,6 #>   0.08416     0.1218 0.6909    0.48963 -0.1546 0.3229   8 #>  #> Prediction type:  probs  #> Columns: type, estimate, std.error, statistic, p.value, conf.low, conf.high, by  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Print marginaleffects objects — print.marginaleffects","title":"Print marginaleffects objects — print.marginaleffects","text":"function controls text printed console one core marginalefffects functions called object returned: predictions(), comparisons(), slopes(), marginal_means(), hypotheses(), avg_predictions(), avg_comparisons(), avg_slopes(). functions return standard data frames. Columns can extracted name, predictions(model)$estimate, usual data manipulation functions work ---box:  colnames(), head(), subset(), dplyr::filter(), dplyr::arrange(), etc. data columns printed default. can disable pretty printing print full results standard data frame using style argument applying .data.frame() object. See examples .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print marginaleffects objects — print.marginaleffects","text":"","code":"# S3 method for marginaleffects print(   x,   digits = max(3L, getOption(\"digits\") - 3L),   topn = getOption(\"marginaleffects_print_topn\", default = 5),   nrows = getOption(\"marginaleffects_print_nrows\", default = 30),   ncols = getOption(\"marginaleffects_print_ncols\", default = 30),   style = getOption(\"marginaleffects_print_style\", default = \"summary\"),   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print marginaleffects objects — print.marginaleffects","text":"x object produced one marginaleffects package functions. digits number digits display. topn number rows printed beginning end tables nrows rows. nrows number rows printed truncation. ncols maximum number column names display bottom printed output. style \"summary\" \"data.frame\" ... arguments currently ignored.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print marginaleffects objects — print.marginaleffects","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp + am + factor(gear), data = mtcars) p <- predictions(mod, by = c(\"am\", \"gear\")) p #>  #>  am gear Estimate Std. Error     z   Pr(>|z|) 2.5 % 97.5 % #>   1    4    26.27      1.039 25.28 < 2.22e-16 24.24  28.31 #>   0    3    16.11      0.759 21.22 < 2.22e-16 14.62  17.59 #>   0    4    21.05      1.470 14.32 < 2.22e-16 18.17  23.93 #>   1    5    21.38      1.315 16.26 < 2.22e-16 18.80  23.96 #>  #> Prediction type:  response  #> Columns: type, am, gear, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   subset(p, am == 1) #>  #>  Estimate Std. Error     z   Pr(>|z|) CI low CI high #>     26.27      1.039 25.28 < 2.22e-16  24.24   28.31 #>     21.38      1.315 16.26 < 2.22e-16  18.80   23.96 #>  #> Prediction type:   #> Columns: type, am, gear, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   print(p, style = \"data.frame\") #>       type am gear estimate std.error statistic       p.value conf.low #> 1 response  1    4 26.27500 1.0392746  25.28206 5.032215e-141 24.23806 #> 2 response  0    3 16.10667 0.7589789  21.22150 6.047009e-100 14.61910 #> 3 response  0    4 21.05000 1.4697563  14.32210  1.592320e-46 18.16933 #> 4 response  1    5 21.38000 1.3145900  16.26363  1.788333e-59 18.80345 #>   conf.high #> 1  28.31194 #> 2  17.59424 #> 3  23.93067 #> 4  23.95655  data.frame(p) #>       type am gear estimate std.error statistic       p.value conf.low #> 1 response  1    4 26.27500 1.0392746  25.28206 5.032215e-141 24.23806 #> 2 response  0    3 16.10667 0.7589789  21.22150 6.047009e-100 14.61910 #> 3 response  0    4 21.05000 1.4697563  14.32210  1.592320e-46 18.16933 #> 4 response  1    5 21.38000 1.3145900  16.26363  1.788333e-59 18.80345 #>   conf.high #> 1  28.31194 #> 2  17.59424 #> 3  23.93067 #> 4  23.95655"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":null,"dir":"Reference","previous_headings":"","what":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"Method raise model-specific warnings errors","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"","code":"# S3 method for glimML sanitize_model_specific(model, ...)  # S3 method for betareg sanitize_model_specific(model, ...)  sanitize_model_specific(model, calling_function = \"marginaleffects\", ...)  # S3 method for default sanitize_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for brmsfit sanitize_model_specific(model, ...)  # S3 method for glmmTMB sanitize_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for inferences_simulation sanitize_model_specific(model, vcov = FALSE, ...)  # S3 method for mblogit sanitize_model_specific(model, calling_function = \"marginaleffects\", ...)  # S3 method for mlogit sanitize_model_specific(model, newdata, ...)  # S3 method for clm sanitize_model_specific(model, ...)  # S3 method for plm sanitize_model_specific(model, ...)  # S3 method for plm sanitize_model_specific(model, ...)  # S3 method for rqs sanitize_model_specific(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) newdata NULL, data frame, string, datagrid() call. Determines predictor values compute slopes. NULL (default): Unit-level slopes observed value original dataset. data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"warning, error, nothing","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to set coefficients — set_coef","title":"Internal function to set coefficients — set_coef","text":"Set coefficients model different values return modified object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to set coefficients — set_coef","text":"","code":"set_coef(model, coefs, ...)  # S3 method for default set_coef(model, coefs, ...)  # S3 method for polr set_coef(model, coefs, ...)  # S3 method for glmmPQL set_coef(model, coefs, ...)  # S3 method for afex_aov set_coef(model, coefs, ...)  # S3 method for glimML set_coef(model, coefs, ...)  # S3 method for betareg set_coef(model, coefs, ...)  # S3 method for multinom set_coef(model, coefs, ...)  # S3 method for crch set_coef(model, coefs, ...)  # S3 method for hxlr set_coef(model, coefs, ...)  # S3 method for gamlss set_coef(model, coefs, ...)  # S3 method for glmmTMB set_coef(model, coefs, ...)  # S3 method for glmx set_coef(model, coefs, ...)  # S3 method for merMod set_coef(model, coefs, ...)  # S3 method for lmerModLmerTest set_coef(model, coefs, ...)  # S3 method for lmerMod set_coef(model, coefs, ...)  # S3 method for mlm set_coef(model, coefs, ...)  # S3 method for hurdle set_coef(model, coefs, ...)  # S3 method for zeroinfl set_coef(model, coefs, ...)  # S3 method for rlmerMod set_coef(model, coefs, ...)  # S3 method for selection set_coef(model, coefs, ...)  # S3 method for scam set_coef(model, coefs, ...)  # S3 method for glm set_coef(model, coefs, ...)  # S3 method for lm set_coef(model, coefs, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to set coefficients — set_coef","text":"model object modify coefs vector coefficients insert model object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to set coefficients — set_coef","text":"Model object class model argument, different stored coefficients.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal function to set coefficients — set_coef","text":"compute variance marginal effects need take Jacobian ","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"Partial derivative regression equation respect regressor interest. slopes(): unit-level (conditional) estimates. avg_slopes(): average (marginal) estimates. newdata argument datagrid() function can used control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See slopes vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/slopes.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"","code":"slopes(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )  avg_slopes(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = TRUE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute slopes. NULL (default): Unit-level slopes observed value original dataset. data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). variables NULL character vector. subset variables compute slopes. NULL: compute contrasts variables model object (can slow). Character vector: subset variables (usually faster). type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. slope string indicates type slope (semi-)elasticity compute: \"dydx\": dY/dX \"eyex\": dY/dX * Y / X \"eydx\": dY/dX * Y \"dyex\": dY/dX / X wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform_post). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"data.frame one row per observation (per term/group) several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) term: variable whose marginal effect computed dydx: slope outcome respect term, given combination predictor values std.error: standard errors computed via delta method.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"\"slope\" \"marginal effect\" partial derivative regression equation respect variable model. function uses automatic differentiation compute slopes vast array models, including non-linear models transformations (e.g., polynomials). Uncertainty estimates computed using delta method. Numerical derivatives slopes function calculated using simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon) - f(X)) / \\varepsilon\\), f predict() method associated model class, \\(\\varepsilon\\) determined eps argument. Warning: models particularly sensitive eps, good practice try different values argument. Standard errors slopes obtained using Delta method. See \"Standard Errors\" vignette package website details (link ).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"avg_slopes(): Average slopes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"","code":"if (FALSE) { # interactive() }  # Unit-level (conditional) Marginal Effects mod <- glm(am ~ hp * wt, data = mtcars, family = binomial) mfx <- slopes(mod) head(mfx) #>  #>  Term  Estimate Std. Error      z Pr(>|z|)      2.5 %    97.5 % #>    hp 0.0069832  0.0058794 1.1877  0.23493 -0.0045401 0.0185066 #>    hp 0.0164041  0.0133881 1.2253  0.22047 -0.0098360 0.0426442 #>    hp 0.0028285  0.0037507 0.7541  0.45078 -0.0045227 0.0101796 #>    hp 0.0019349  0.0024509 0.7895  0.42985 -0.0028688 0.0067385 #>    hp 0.0029929  0.0033775 0.8861  0.37556 -0.0036269 0.0096127 #>    hp 0.0001476  0.0003453 0.4276  0.66893 -0.0005291 0.0008244 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt, eps  #>   # Average Marginal Effect (AME) avg_slopes(mod, by = TRUE) #>  #>  Term  Estimate Std. Error      z   Pr(>|z|)     2.5 %    97.5 % #>    hp  0.002653   0.001939  1.368    0.17121 -0.001147  0.006452 #>    wt -0.435783   0.102063 -4.270 1.9568e-05 -0.635822 -0.235744 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>    # Marginal Effect at the Mean (MEM) slopes(mod, newdata = datagrid()) #>  #>  Term  Estimate Std. Error      z Pr(>|z|)     2.5 %  97.5 % #>    hp  0.008527    0.00785  1.086  0.27736 -0.006858 0.02391 #>    wt -1.744527    1.58631 -1.100  0.27144 -4.853630 1.36458 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt, eps  #>   # Marginal Effect at User-Specified Values # Variables not explicitly included in `datagrid()` are held at their means slopes(mod, newdata = datagrid(hp = c(100, 110))) #>  #>  Term  Estimate Std. Error       z Pr(>|z|)     2.5 %   97.5 %  hp #>    hp  0.001167   0.001754  0.6651  0.50599 -0.002271 0.004605 100 #>    hp  0.001895   0.002416  0.7845  0.43276 -0.002840 0.006631 110 #>    wt -0.194678   0.307228 -0.6337  0.52630 -0.796833 0.407478 100 #>    wt -0.331536   0.436074 -0.7603  0.44709 -1.186226 0.523154 110 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, wt, hp, eps  #>   # Group-Average Marginal Effects (G-AME) # Calculate marginal effects for each observation, and then take the average # marginal effect within each subset of observations with different observed # values for the `cyl` variable: mod2 <- lm(mpg ~ hp * cyl, data = mtcars) avg_slopes(mod2, variables = \"hp\", by = \"cyl\") #>  #>  Term    Contrast Estimate Std. Error       z  Pr(>|z|)    2.5 %   97.5 % cyl #>    hp mean(dY/dX) -0.05226    0.02041 -2.5608 0.0104442 -0.09225 -0.01226   6 #>    hp mean(dY/dX) -0.09173    0.03533 -2.5964 0.0094216 -0.16098 -0.02248   4 #>    hp mean(dY/dX) -0.01278    0.01434 -0.8912 0.3727993 -0.04089  0.01533   8 #>  #> Prediction type:  response  #> Columns: type, term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high, cyl, predicted, predicted_hi, predicted_lo  #>   # Marginal Effects at User-Specified Values (counterfactual) # Variables not explicitly included in `datagrid()` are held at their # original values, and the whole dataset is duplicated once for each # combination of the values in `datagrid()` mfx <- slopes(mod,               newdata = datagrid(hp = c(100, 110),               grid_type = \"counterfactual\")) head(mfx) #>  #>  Term  Estimate Std. Error      z Pr(>|z|)      2.5 %    97.5 %  hp #>    hp 0.0120345  0.0099872 1.2050  0.22820 -0.0075399 0.0316090 100 #>    hp 0.0141605  0.0108084 1.3101  0.19015 -0.0070235 0.0353446 100 #>    hp 0.0015642  0.0022025 0.7102  0.47758 -0.0027526 0.0058810 100 #>    hp 0.0011906  0.0017805 0.6687  0.50367 -0.0022990 0.0046803 100 #>    hp 0.0001455  0.0003411 0.4265  0.66971 -0.0005230 0.0008140 100 #>    hp 0.0001201  0.0002911 0.4127  0.67985 -0.0004504 0.0006907 100 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, rowidcf, predicted, predicted_hi, predicted_lo, am, wt, hp, eps  #>   # Heteroskedasticity robust standard errors mfx <- slopes(mod, vcov = sandwich::vcovHC(mod)) head(mfx) #>  #>  Term  Estimate Std. Error      z Pr(>|z|)      2.5 %    97.5 % #>    hp 0.0069832  0.0091871 0.7601  0.44719 -0.0110232 0.0249897 #>    hp 0.0164041  0.0134025 1.2240  0.22097 -0.0098642 0.0426725 #>    hp 0.0028285  0.0049129 0.5757  0.56481 -0.0068008 0.0124577 #>    hp 0.0019349  0.0018435 1.0496  0.29392 -0.0016783 0.0055481 #>    hp 0.0029929  0.0027827 1.0755  0.28213 -0.0024611 0.0084468 #>    hp 0.0001476  0.0002545 0.5800  0.56188 -0.0003512 0.0006465 #>  #> Prediction type:  response  #> Columns: rowid, type, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt, eps  #>   # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  slopes(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>  #>     Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  wt=drat   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using row indices slopes(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>  #>     Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  b1-b2=0   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # same hypothesis test using numeric vector of weights slopes(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>  #>    Term Estimate Std. Error      z   Pr(>|z|)  2.5 % 97.5 % #>  custom   -6.225      1.052 -5.919 3.2398e-09 -8.287 -4.164 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>   # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") slopes(     mod,     newdata = \"mean\",     hypothesis = lc) #>  #>        Term Estimate Std. Error       z   Pr(>|z|)   2.5 % 97.5 % #>  Contrast A   -6.225      1.052 -5.9190 3.2398e-09  -8.287 -4.164 #>  Contrast B   -5.238      5.624 -0.9315    0.35162 -16.261  5.784 #>  #> Prediction type:  response  #> Columns: type, term, estimate, std.error, statistic, p.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0819001","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.1.9001","title":"marginaleffects 0.8.1.9001","text":"Breaking changes: functions return estimate column instead function-specific predicted, comparisons, dydx, etc. change affects unit-level estimates, average estimates, already used estimate column name. transform_avg argument tidy() deprecated. Use transform_post instead. plot_*() now return actual variable names supplied condition argument, rather opaque “condition1”, “condition2”, etc. New models supported: blme package. New features: New functions: avg_predictions(), avg_comparisons(), avg_slopes() Equivalence, non-inferiority, non-superiority tests hypotheses() function equivalence argument. New experimental inferences() function. New df argument set degrees freedom manually p CI. Pretty print() objects. TRUE returns average (marginal) predictions, comparisons, slopes. Supports bayesian models. Numeric value sets null used calculating Z p. Example: comparisons(mod, transform_pre = \"ratio\", hypothesis = 1) arguments main functions now available tidy(), summary(): conf_level, transform_post, etc. options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") options(\"marginaleffects_posterior_center\" = median) options(\"marginaleffects_posterior_center\" = mean) Renamed functions (backward-compatibility maintained): marginaleffects() -> slopes() posteriordraws() -> posterior_draws() marginalmeans() -> marginal_means() plot_cap() -> plot_predictions() plot_cme() -> plot_slopes() plot_cco() -> plot_comparisons() Bug fixes: Incorrect results: 0.8.1, plot_c*() threenum minmax labels correspond correct numeric values. Fix corner case slopes dataset includes infinite values. mlogit error factors. vcov argument accepts functions models. : Removed major performance bottleneck slopes()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-081","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.1","title":"marginaleffects 0.8.1","text":"CRAN release: 2022-11-23 deltamethod() can run hypothesis tests objects produced comparisons(), marginaleffects(), predictions(), marginalmeans() functions. feature relies match.call(), means may always work used programmatically, inside functions nested environments. generally safer efficient use hypothesis argument. plot_cme() plot_cco() accept lists user-specified values regressors, can display nice labels shortcut string-functions like “threenum” “quartile”. posterior_draws: new shape argument return MCMC draws various formats, including new rvar structure posterior package. transform_avg function gets printed summary() output. transform_post transform_avg support string shortcuts: “exp” “ln” Added support mlm models lm(). Thanks Noah Greifer. Bug fixes: hypothesis argument bayesian models tidy() used raise error. Missing values regressors comparisons() output brms models.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-080","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.0","title":"marginaleffects 0.8.0","text":"CRAN release: 2022-11-02 Breaking change: interaction argument deprecated replaced cross argument. reduce ambiguity respect interaction argument emmeans, something completely different, akin difference--differences illustrated Interactions vignette. 71 classes models supported, including new: rms::ols rms::lrm rms::orm New features: Plots: plot_cme(), plot_cap(), plot_cco() now much flexible specifying comparisons display. condition argument accepts lists, functions, shortcuts common reference values, “minmax”, “threenum”, etc. Accepts functions specify custom differences numeric variables (e.g., forward backward differencing). Can specify pairs factors compare variables argument comparisons function. Accepts shortcut strings, functions, vectors arbitrary length. Integrate random effects bayesian brms models (see Bayesian analysis vignette) New vignettes: Experiments Extending marginal effects Integrating random effects bayesian models Bug fixes minor improvements: default value conf_level summary() tidy() now NULL, inherits conf_level value original comparisons/marginaleffects/predictions calls. Fix typo function names missing “lnratioavgwts” Interactions fixest::() parsed properly categorical variables betareg objects, inference can now done coefficients using deltamethod(). previously location coefficients available. objects crch package, number bugs fixed; standard errors now correct deltamethod(), marginaleffects(), etc. Fixed bug tidy() function glmmTMB models without random effects, caused t statistics identical.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-071","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.1","title":"marginaleffects 0.7.1","text":"CRAN release: 2022-09-25 New supported model class: gamlss. Thanks Marcio Augusto Diniz. marginalmeans() accepts wts argument values: “equal”, “proportional”, “cells”. accepts data frames complex groupings. marginalmeans accepts data frames. accepts “group” group response level. works bayesian models. byfun argument predictions() function aggregate using different functions. matrix column names used labels hypothesis tests. Better labels “sequential”, “reference”, “pairwise”. new shortcuts “revpairwise”, “revsequential”, “revreference” wts argument respected argument *avg shortcuts transform_pre argument. tidy.predictions() tidy.marginalmeans() get new transform_avg argument. Unit-level contrasts logistic regressions. Thanks @arthur-albuquerque. Python Numpy models marginaleffects. Thanks @timpipeseek. Bootstrap example standard errors vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-070","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.0","title":"marginaleffects 0.7.0","text":"CRAN release: 2022-08-06 Breaking changes: deprecated summary() tidy(). Use argument main functions instead: comparisons(), marginaleffects(), predictions() Character vectors longer supported variables argument predictions() function. Use newdata=\"fivenum\" “grid”, “mean”, “median” instead. Critical bug fix: Contrasts interactions incorrect version 0.6.0. error obvious analysts cases (weird-looking alignment). Thanks @vmikk. New supported packages models: survival::clogit biglm: main quantities can computed, delta method standard errors. See https://github.com/vincentarelbundock/marginaleffects/issues/387 New vignette: Elasticity Frequently Asked Questions New features: Elasticity semi-elasticity using new slope argument marginaleffects(): eyex, dyex, eydx datagrid() accepts functions: datagrid(newdata = mtcars, hp = range, mpg = fivenum, wt = sd) New datagridcf() function create counterfactual datasets. shortcut datagrid() function default grid_type = \"counterfactual\" New arguments predictions(), comparisons(), marginaleffects() New newdata shortcuts: “tukey”, “grid” New string shortcuts transform_pre comparisons() marginalmeans() now back transforms confidence intervals possible. vcov argument string shortcuts now case-insensitive default contrast comparisons() binary predictors now difference 1 0, rather +1 relative baseline. documentation improvements","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-060","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.6.0","title":"marginaleffects 0.6.0","text":"CRAN release: 2022-06-20 New supported packages models: tidymodels objects class tidy_model supported fit engine supported marginaleffects. New function: deltamethod(): Hypothesis tests functions parameters plot_cco(): Plot conditional contrasts New arguments: hypothesis hypothesis tests custom contrasts transform_post predictions() wts argument predictions() affects average predictions tidy() summary(). New improved vignettes: Hypothesis Tests Custom Contrasts using Delta Method: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html Multiple Imputation: https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html Causal Inference g-Formula: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html (Thanks Rohan Kapre idea) Deprecated renamed arguments: contrast_factor contrast_numeric arguments deprecated comparisons(). Use named list variables argument instead. Backward compatibility maintained. transform_post argument tidy() summary() renamed transform_avg disambiguate argument name comparisons(). Backward compatibility preserved. Misc: tidy.predictions() computes standard errors using delta method average predictions Support gam models matrix columns. eps marginaleffects() now “adaptive” default: equals 0.0001 multiplied range predictor variable comparisons() now supports “log marginal odds ratio” transform_pre argument. Thanks Noah Greifer. New transform_pre shortcuts: dydx, expdydx tidy.predictions() computes standard errors confidence intervals linear models GLM link scale.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-050","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.5.0","title":"marginaleffects 0.5.0","text":"CRAN release: 2022-05-17 Breaking changes: type longer accepts character vector. Must single string. conf.int argument deprecated. Use vcov = FALSE instead. New supported packages models: mlogit mhurdle tobit1 glmmTMB New features: interaction argument comparisons() compute interactions contrasts (cross-contrasts). argument tidy() summary() computes group-average marginal effects comparisons. transform_pre argument can define custom contrasts adjusted predictions (e.g., log adjusted risk ratios). Available comparisons(). transform_post argument allows back transformation returning final results. Available comparisons(), marginalmeans(), summary(), tidy(). variables argument comparisons() function accepts named list specify variable-specific contrast types. sandwich package shortcuts: vcov = \"HC3\", \"HC2\", \"NeweyWest\", . Mixed effects models: vcov = \"satterthwaite\" \"kenward-roger\" One-sided formula clusters: vcov = ~cluster_variable Variance-covariance matrix Function returns named squared matrix marginalmeans() allows interactions Bayesian Model Averaging brms models using type = \"average\". See vignette marginaleffects website. eps argument step size numerical derivative marginaleffects comparisons now report confidence intervals default. New dependency data.table package yields substantial performance improvements. informative error messages warnings Bug fixes performance improvements New pages marginaleffects website: https://vincentarelbundock.github.io/marginaleffects/ Alternative software packages Robust standard errors () Performance tips Tables plots Multinomial Logit Discrete Choice Models Generalized Additive Models Mixed effects models (Bayesian Frequentist) Transformations Custom Contrasts: Adjusted Risk Ratio Example Argument name changes (backward compatibility preserved: conf.level -> conf_level FUN.factor -> FUN_factor (related arguments) grid.type -> grid_type","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-041","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.1","title":"marginaleffects 0.4.1","text":"CRAN release: 2022-03-27 New supported packages models: stats::loess sampleSelection::selection sampleSelection::heckit Misc: mgcv::bam models allow exclude argument. Gam models allow include_smooth argument. New tests Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-040","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.0","title":"marginaleffects 0.4.0","text":"CRAN release: 2022-03-13 New function: comparisons() computes contrasts Misc: Speed optimizations predictions() plot_cap() include confidence intervals linear models robust handling -formula functions: factor(), strata(), mo() overwrite user’s ggplot2::theme_set() call","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-034","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.4","title":"marginaleffects 0.3.4","text":"CRAN release: 2022-03-03 Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-033","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.3","title":"marginaleffects 0.3.3","text":"CRAN release: 2022-01-26 New supported models: mclogit::mclogit robust::lmRob robustlmm::rlmer fixest confidence intervals predictions Misc: Support modelbased::visualisation_matrix newdata without specify x explicitly. tidy.predictions() summary.predictions() methods. Documentation improvements. CRAN test fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-032","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.2","title":"marginaleffects 0.3.2","text":"CRAN release: 2022-01-18 Support new models packages: brglm2::bracl mclogit::mblogit scam::scam lmerTest::lmer Misc: Drop numDeriv dependency, make available via global option: options(“marginaleffects_numDeriv” = list(method = “Richardson”, method.args = list(eps = 1e-5, d = 0.0001))) Bugfixes Documentation improvements CRAN tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-031","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.1","title":"marginaleffects 0.3.1","text":"CRAN release: 2022-01-09 documentation bugfix","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-030","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.0","title":"marginaleffects 0.3.0","text":"CRAN release: 2022-01-08 Breaking changes: predictions returns predictions every observation original dataset instead newdata=datagrid(). marginalmeans objects new column names, corresponding tidy summary outputs. New supported packages models: brms::brm rstanarm::stanglm brglm2::brmultinom MASS::glmmPQL aod::betabin Misc: datagrid function supersedes typical counterfactual grid.type argument. typical counterfactual functions remain available exported, use encouraged. posterior_draws function can applied predictions marginaleffects object extract draws posterior distribution. marginalmeans standard errors now computed using delta method. predictions standard errors now computed using delta method available insight::get_predicted. New vignette Bayesian models brms New vignette Mixed effects models lme4 data.table package installed, marginaleffects automatically use speed things . Contrast definition reported separate column marginaleffects output. Safer handling type argument. Comprehensive list supported tests models website. Many bug fixes Many new tests, including several emmeans","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-020","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.2.0","title":"marginaleffects 0.2.0","text":"CRAN release: 2021-10-18 Breaking change: data argument becomes newdata functions. New supported packages models: lme4:glmer.nb mgcv::gam ordinal::clm mgcv marginalmeans: New variables_grid argument predictions: Support mgcv plot_cap New type argument Misc: New validity checks tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-010","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.1.0","title":"marginaleffects 0.1.0","text":"CRAN release: 2021-09-29 First release. Bravo! Thanks Marco Avina Mendoza, Resul Umit, offered comments suggestions.","code":""}]
